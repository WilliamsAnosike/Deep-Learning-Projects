{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DATA 690 Practical Deep Learning Final Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNTfh2FD5O76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "8e6ba561-3100-4ca0-b54f-fa450795a383"
      },
      "source": [
        "#loading necessary modules...\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision \n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random\n",
        "import torchtext.data as data\n",
        "import csv\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import string\n",
        "import nltk\n",
        "import torchtext\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "import re\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "import time\n",
        "import sys, os"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOBr9-I4G4Bj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a987901-d0be-4002-84f2-3ff0c1e09aec"
      },
      "source": [
        "#Mount Google Drive where files are housed.\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylswTafjI6HB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ccc520c-90ba-48b9-b0cd-06cc6cea8927"
      },
      "source": [
        "%cd /content/gdrive/My\\ Drive/Colab Notebooks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5Lc2ri55R_B"
      },
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1pM8Ovj5X6b"
      },
      "source": [
        "#For randomization.\n",
        "seed = 1997\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "#Use 1 value to set up new process train/test files.\n",
        "process_new_data = 1\n",
        "#Use 1 value to train a new model. Set to 0 to load previously saved model.\n",
        "train_new_data = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0MB0DoA5leb"
      },
      "source": [
        "#paths for the saved files. Set to a variable for reproducibility on other datasets.\n",
        "train_dir = \"train.csv\"\n",
        "process_train = \"process_train.csv\"\n",
        "test_dir = \"test.csv\"\n",
        "process_test = \"process_test.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5_gCp8gGNo5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8deda970-3448-4f05-e6b1-041dcd336b09"
      },
      "source": [
        "traindata = pd.read_csv(train_dir)\n",
        "traindata.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  0000997932d777bf  ...             0\n",
              "1  000103f0d9cfb60f  ...             0\n",
              "2  000113f07ec002fd  ...             0\n",
              "3  0001b41b1c6bb37e  ...             0\n",
              "4  0001d958c54c6e35  ...             0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3q9-bsWHFYc"
      },
      "source": [
        "#Inspiration for this function gotten from https://www.kaggle.com/prabhatkumarsahu/toxic-comment-classification-thecaffeinedev\n",
        "#Used to clean text data into form that can be input into vocabulary.\n",
        "punctuations = string.punctuation\n",
        "stopwords_list = stopwords.words(\"english\")\n",
        "spacy_tokenizer = torchtext.data.utils.get_tokenizer('spacy')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def processing(text):\n",
        "  \n",
        "    def tokenizer(text):\n",
        "        text = str.split(text)\n",
        "        return text\n",
        "    \n",
        "    def remove_punctuations(sentence):\n",
        "        result = \"\".join([i if i not in punctuations and not i.isdigit() else \" \" for i in sentence])\n",
        "        return result\n",
        "    \n",
        "    def word_lemmatizer(sentence):\n",
        "        result = lemmatizer.lemmatize(sentence)\n",
        "        return result\n",
        "    \n",
        "    def word_lowercase(sentence):\n",
        "        return sentence.lower()\n",
        "    \n",
        "    def remove_URL(text):\n",
        "        url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "        html = re.compile(r'<.*?>')\n",
        "        text = html.sub(r'',text)\n",
        "        text = url.sub(r'',str(text))\n",
        "        return text\n",
        "  \n",
        "    def remove_newline(text):\n",
        "        return text.rstrip(\"\\n\")\n",
        "    \n",
        "    def clean_comment(sentence):\n",
        "        result = []\n",
        "        sentence = remove_newline(sentence)\n",
        "        sentence = remove_URL(sentence)\n",
        "        sentence = word_lowercase(sentence)\n",
        "        sentence = word_lemmatizer(sentence)\n",
        "        sentence = remove_punctuations(sentence)\n",
        "        sentence = tokenizer(sentence)\n",
        "\n",
        "        result = \" \".join(sentence)\n",
        "        return result\n",
        "     \n",
        "    text = clean_comment(text)\n",
        "    if text == \"\":\n",
        "        text = \"None\"\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnSyc8EJHRR-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f657b2b4-c550-4df7-81ab-0ff7a5743021"
      },
      "source": [
        "#new file where cleaned comments from test files will be written to.\n",
        "if process_new_data:\n",
        "    with open(test_dir, \"r\", encoding=\"utf8\") as in_csv, open(process_test, \"w\", newline=\"\", encoding=\"utf8\") as out_csv:\n",
        "        read = csv.reader(in_csv)\n",
        "        write = csv.writer(out_csv)\n",
        "        next(read, None) \n",
        "        for i in tqdm(read):\n",
        "            i[1] = processing(i[1])\n",
        "            try:\n",
        "                write.writerow(i)\n",
        "            except Exception as e:\n",
        "               print(e)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "153164it [00:14, 10248.39it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOG48ZH7KUV1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52ed31c4-f6bc-4e70-9def-77e6d57fcaa4"
      },
      "source": [
        "#new file where cleaned comments from train files will be written to.\n",
        "if process_new_data:\n",
        "    with open(train_dir, \"r\", encoding=\"utf8\") as in_csv, open(process_train, \"w\", newline=\"\", encoding=\"utf8\") as out_csv:\n",
        "        read = csv.reader(in_csv)\n",
        "        write = csv.writer(out_csv)\n",
        "        next(read, None) # Skip header\n",
        "        for i in tqdm(read):\n",
        "            i[1] = processing(i[1])\n",
        "            try:\n",
        "                write.writerow(i)\n",
        "            except Exception as e:\n",
        "               print(e)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "159571it [00:15, 10449.32it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czn99pSOHT0F"
      },
      "source": [
        "def token_words(sentence):\n",
        "    tokens = str.split(sentence)\n",
        "    return tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huJP6pd4HV6w"
      },
      "source": [
        "#https://towardsdatascience.com/use-torchtext-to-load-nlp-datasets-part-i-5da6f1c89d84\n",
        "TEXT = data.Field(batch_first = True,\n",
        "                  tokenize = token_words,\n",
        "                  stop_words=stopwords_list)\n",
        "LABEL = data.LabelField(dtype = torch.float)\n",
        "ID = data.LabelField()\n",
        "ID2 = data.Field(sequential=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtWsyYhyHYDN"
      },
      "source": [
        "#https://towardsdatascience.com/use-torchtext-to-load-nlp-datasets-part-i-5da6f1c89d84\n",
        "features = [[\"id\",ID], [\"text\", TEXT], [\"toxic\",LABEL],[\"s_toxic\",LABEL],\n",
        "          [\"obscene\",LABEL],[\"threat\",LABEL],[\"insult\",LABEL],[\"id_hate\",LABEL]]\n",
        "test_features = [[\"id\",ID2], [\"text\", TEXT]]\n",
        "\n",
        "data_train = data.TabularDataset(process_train,\n",
        "                              format = \"csv\",\n",
        "                              fields=features,\n",
        "                              skip_header=True)\n",
        "\n",
        "data_test = data.TabularDataset(process_test,\n",
        "                              format= \"csv\",\n",
        "                              fields=test_features,\n",
        "                             skip_header=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LA6ifh34LZcf"
      },
      "source": [
        "#Randomizing the datasets.\n",
        "import random\n",
        "\n",
        "data_train, data_val = data_train.split(split_ratio=0.8, random_state=random.seed(seed))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuqF5wYwHayt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9f32f8b2-7f8a-471c-b76c-5e1b0a9f8a4b"
      },
      "source": [
        "#Building the corpus vocabulary.\n",
        "vocab_size = 40000\n",
        "TEXT.build_vocab(data_train,\n",
        "                 min_freq = 3,\n",
        "                 max_size = vocab_size, \n",
        "                 vectors = \"glove.6B.100d\", \n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "LABEL.build_vocab(data_train)\n",
        "ID.build_vocab(data_train)\n",
        "ID2.build_vocab(data_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique words in training set: 40002\n",
            "Unique labels in training set: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuICOSW6Hl-k"
      },
      "source": [
        "#Set up for the Batch iterator.\n",
        "BATCH_SIZE = 64\n",
        "train_iterator, val_iterator = data.BucketIterator.splits((data_train, data_val),\n",
        "                                                  batch_size=BATCH_SIZE,\n",
        "                                                  device = device)\n",
        "test_iterator = data.BucketIterator(data_test,\n",
        "                                batch_size=BATCH_SIZE,\n",
        "                                shuffle=False,\n",
        "                                device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgA9B9dnQPpq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f76e93ec-7eaa-4f96-dca4-b2846c13f151"
      },
      "source": [
        "data_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torchtext.data.dataset.Dataset at 0x7fc4309e2128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8IxKuapHpvk"
      },
      "source": [
        "#Set up of Convolutional Model used to solve problem.\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
        "                 dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "                \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "        self.convs = nn.ModuleList([\n",
        "                                    nn.Conv2d(in_channels = 1, \n",
        "                                              out_channels = n_filters, \n",
        "                                              kernel_size = (i, embedding_dim)) \n",
        "                                    for i in filter_sizes\n",
        "                                    ])\n",
        "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "                \n",
        "        embedded = self.embedding(text)\n",
        "        embedded = embedded.unsqueeze(1)\n",
        "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]        \n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
        "            \n",
        "        return self.fc(cat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAC8e9v7HrsR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "04842730-ed32-4af7-a83c-0a2605807e9d"
      },
      "source": [
        "#Hyperparameters for model.\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "N_FILTERS = 100\n",
        "FILTER_SIZES = [3,4,5]\n",
        "OUTPUT_DIM = 6\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n",
        "\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 3e-5,weight_decay=2e-5)\n",
        "criterion = nn.BCEWithLogitsLoss().to(device)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN(\n",
            "  (embedding): Embedding(40002, 100, padding_idx=1)\n",
            "  (convs): ModuleList(\n",
            "    (0): Conv2d(1, 100, kernel_size=(3, 100), stride=(1, 1))\n",
            "    (1): Conv2d(1, 100, kernel_size=(4, 100), stride=(1, 1))\n",
            "    (2): Conv2d(1, 100, kernel_size=(5, 100), stride=(1, 1))\n",
            "  )\n",
            "  (fc): Linear(in_features=300, out_features=6, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bslWadUHHw4Q"
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKMi6ziAHyGR"
      },
      "source": [
        "#Function to reach into batch and for each label, return a (batch_size, 1) dimension tensor.\n",
        "def get_labels(batch):\n",
        "    toxic = batch.toxic.unsqueeze(1)\n",
        "    s_toxic = batch.s_toxic.unsqueeze(1)\n",
        "    obscene = batch.obscene.unsqueeze(1)\n",
        "    threat = batch.threat.unsqueeze(1)\n",
        "    insult = batch.insult.unsqueeze(1)\n",
        "    id_hate = batch.id_hate.unsqueeze(1)\n",
        "    labels = torch.cat((toxic,s_toxic,obscene,\n",
        "                        threat,insult,id_hate),dim=1)\n",
        "    return labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Wx6gTbwH2F4"
      },
      "source": [
        "#training step by step function.\n",
        "def train_pace(model, optimizer, criterion, batch):\n",
        "    batch_size = len(batch)\n",
        "    model.train()\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    text = batch.text.view(batch_size, -1)\n",
        "    labels = get_labels(batch)\n",
        "\n",
        "    outputs = model(text)\n",
        "    loss = criterion(outputs,labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wORWGQMrH4NV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6cb25ee2-e00f-4e0b-f1dd-1b3cfc819b36"
      },
      "source": [
        "#Training function that runs if train_new_data is set to 1. \n",
        "if train_new_data:\n",
        "    epochs = 2\n",
        "    loss_list = []\n",
        "    print(\"Training starting!\")\n",
        "    for epoch in range(epochs):\n",
        "        for i, batch in enumerate(train_iterator):\n",
        "            train_loss = train_pace(model,optimizer, criterion, batch)\n",
        "            loss_list.append(train_loss)\n",
        "            print(f\"Epoch: [{epoch+1}/{epochs}] | Iterations: [{i+1}/{len(train_iterator)}] | Training loss: {train_loss:.3f}\")\n",
        "    torch.save(model.state_dict(), \"model.pt\")\n",
        "          \n",
        "        \n",
        "    print(\"Training Done!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training starting!\n",
            "Epoch: [1/2] | Iterations: [1/1995] | Training loss: 0.625\n",
            "Epoch: [1/2] | Iterations: [2/1995] | Training loss: 0.631\n",
            "Epoch: [1/2] | Iterations: [3/1995] | Training loss: 0.603\n",
            "Epoch: [1/2] | Iterations: [4/1995] | Training loss: 0.621\n",
            "Epoch: [1/2] | Iterations: [5/1995] | Training loss: 0.621\n",
            "Epoch: [1/2] | Iterations: [6/1995] | Training loss: 0.608\n",
            "Epoch: [1/2] | Iterations: [7/1995] | Training loss: 0.612\n",
            "Epoch: [1/2] | Iterations: [8/1995] | Training loss: 0.612\n",
            "Epoch: [1/2] | Iterations: [9/1995] | Training loss: 0.611\n",
            "Epoch: [1/2] | Iterations: [10/1995] | Training loss: 0.602\n",
            "Epoch: [1/2] | Iterations: [11/1995] | Training loss: 0.584\n",
            "Epoch: [1/2] | Iterations: [12/1995] | Training loss: 0.594\n",
            "Epoch: [1/2] | Iterations: [13/1995] | Training loss: 0.575\n",
            "Epoch: [1/2] | Iterations: [14/1995] | Training loss: 0.562\n",
            "Epoch: [1/2] | Iterations: [15/1995] | Training loss: 0.575\n",
            "Epoch: [1/2] | Iterations: [16/1995] | Training loss: 0.584\n",
            "Epoch: [1/2] | Iterations: [17/1995] | Training loss: 0.576\n",
            "Epoch: [1/2] | Iterations: [18/1995] | Training loss: 0.572\n",
            "Epoch: [1/2] | Iterations: [19/1995] | Training loss: 0.573\n",
            "Epoch: [1/2] | Iterations: [20/1995] | Training loss: 0.569\n",
            "Epoch: [1/2] | Iterations: [21/1995] | Training loss: 0.545\n",
            "Epoch: [1/2] | Iterations: [22/1995] | Training loss: 0.563\n",
            "Epoch: [1/2] | Iterations: [23/1995] | Training loss: 0.541\n",
            "Epoch: [1/2] | Iterations: [24/1995] | Training loss: 0.551\n",
            "Epoch: [1/2] | Iterations: [25/1995] | Training loss: 0.544\n",
            "Epoch: [1/2] | Iterations: [26/1995] | Training loss: 0.545\n",
            "Epoch: [1/2] | Iterations: [27/1995] | Training loss: 0.547\n",
            "Epoch: [1/2] | Iterations: [28/1995] | Training loss: 0.529\n",
            "Epoch: [1/2] | Iterations: [29/1995] | Training loss: 0.543\n",
            "Epoch: [1/2] | Iterations: [30/1995] | Training loss: 0.534\n",
            "Epoch: [1/2] | Iterations: [31/1995] | Training loss: 0.541\n",
            "Epoch: [1/2] | Iterations: [32/1995] | Training loss: 0.521\n",
            "Epoch: [1/2] | Iterations: [33/1995] | Training loss: 0.526\n",
            "Epoch: [1/2] | Iterations: [34/1995] | Training loss: 0.542\n",
            "Epoch: [1/2] | Iterations: [35/1995] | Training loss: 0.524\n",
            "Epoch: [1/2] | Iterations: [36/1995] | Training loss: 0.531\n",
            "Epoch: [1/2] | Iterations: [37/1995] | Training loss: 0.523\n",
            "Epoch: [1/2] | Iterations: [38/1995] | Training loss: 0.504\n",
            "Epoch: [1/2] | Iterations: [39/1995] | Training loss: 0.509\n",
            "Epoch: [1/2] | Iterations: [40/1995] | Training loss: 0.515\n",
            "Epoch: [1/2] | Iterations: [41/1995] | Training loss: 0.509\n",
            "Epoch: [1/2] | Iterations: [42/1995] | Training loss: 0.491\n",
            "Epoch: [1/2] | Iterations: [43/1995] | Training loss: 0.480\n",
            "Epoch: [1/2] | Iterations: [44/1995] | Training loss: 0.483\n",
            "Epoch: [1/2] | Iterations: [45/1995] | Training loss: 0.500\n",
            "Epoch: [1/2] | Iterations: [46/1995] | Training loss: 0.494\n",
            "Epoch: [1/2] | Iterations: [47/1995] | Training loss: 0.491\n",
            "Epoch: [1/2] | Iterations: [48/1995] | Training loss: 0.482\n",
            "Epoch: [1/2] | Iterations: [49/1995] | Training loss: 0.464\n",
            "Epoch: [1/2] | Iterations: [50/1995] | Training loss: 0.502\n",
            "Epoch: [1/2] | Iterations: [51/1995] | Training loss: 0.471\n",
            "Epoch: [1/2] | Iterations: [52/1995] | Training loss: 0.470\n",
            "Epoch: [1/2] | Iterations: [53/1995] | Training loss: 0.489\n",
            "Epoch: [1/2] | Iterations: [54/1995] | Training loss: 0.468\n",
            "Epoch: [1/2] | Iterations: [55/1995] | Training loss: 0.462\n",
            "Epoch: [1/2] | Iterations: [56/1995] | Training loss: 0.469\n",
            "Epoch: [1/2] | Iterations: [57/1995] | Training loss: 0.438\n",
            "Epoch: [1/2] | Iterations: [58/1995] | Training loss: 0.466\n",
            "Epoch: [1/2] | Iterations: [59/1995] | Training loss: 0.465\n",
            "Epoch: [1/2] | Iterations: [60/1995] | Training loss: 0.476\n",
            "Epoch: [1/2] | Iterations: [61/1995] | Training loss: 0.454\n",
            "Epoch: [1/2] | Iterations: [62/1995] | Training loss: 0.470\n",
            "Epoch: [1/2] | Iterations: [63/1995] | Training loss: 0.483\n",
            "Epoch: [1/2] | Iterations: [64/1995] | Training loss: 0.426\n",
            "Epoch: [1/2] | Iterations: [65/1995] | Training loss: 0.427\n",
            "Epoch: [1/2] | Iterations: [66/1995] | Training loss: 0.440\n",
            "Epoch: [1/2] | Iterations: [67/1995] | Training loss: 0.445\n",
            "Epoch: [1/2] | Iterations: [68/1995] | Training loss: 0.416\n",
            "Epoch: [1/2] | Iterations: [69/1995] | Training loss: 0.466\n",
            "Epoch: [1/2] | Iterations: [70/1995] | Training loss: 0.453\n",
            "Epoch: [1/2] | Iterations: [71/1995] | Training loss: 0.424\n",
            "Epoch: [1/2] | Iterations: [72/1995] | Training loss: 0.433\n",
            "Epoch: [1/2] | Iterations: [73/1995] | Training loss: 0.423\n",
            "Epoch: [1/2] | Iterations: [74/1995] | Training loss: 0.416\n",
            "Epoch: [1/2] | Iterations: [75/1995] | Training loss: 0.414\n",
            "Epoch: [1/2] | Iterations: [76/1995] | Training loss: 0.420\n",
            "Epoch: [1/2] | Iterations: [77/1995] | Training loss: 0.422\n",
            "Epoch: [1/2] | Iterations: [78/1995] | Training loss: 0.409\n",
            "Epoch: [1/2] | Iterations: [79/1995] | Training loss: 0.418\n",
            "Epoch: [1/2] | Iterations: [80/1995] | Training loss: 0.418\n",
            "Epoch: [1/2] | Iterations: [81/1995] | Training loss: 0.407\n",
            "Epoch: [1/2] | Iterations: [82/1995] | Training loss: 0.421\n",
            "Epoch: [1/2] | Iterations: [83/1995] | Training loss: 0.398\n",
            "Epoch: [1/2] | Iterations: [84/1995] | Training loss: 0.387\n",
            "Epoch: [1/2] | Iterations: [85/1995] | Training loss: 0.420\n",
            "Epoch: [1/2] | Iterations: [86/1995] | Training loss: 0.402\n",
            "Epoch: [1/2] | Iterations: [87/1995] | Training loss: 0.408\n",
            "Epoch: [1/2] | Iterations: [88/1995] | Training loss: 0.409\n",
            "Epoch: [1/2] | Iterations: [89/1995] | Training loss: 0.400\n",
            "Epoch: [1/2] | Iterations: [90/1995] | Training loss: 0.382\n",
            "Epoch: [1/2] | Iterations: [91/1995] | Training loss: 0.388\n",
            "Epoch: [1/2] | Iterations: [92/1995] | Training loss: 0.390\n",
            "Epoch: [1/2] | Iterations: [93/1995] | Training loss: 0.379\n",
            "Epoch: [1/2] | Iterations: [94/1995] | Training loss: 0.369\n",
            "Epoch: [1/2] | Iterations: [95/1995] | Training loss: 0.352\n",
            "Epoch: [1/2] | Iterations: [96/1995] | Training loss: 0.390\n",
            "Epoch: [1/2] | Iterations: [97/1995] | Training loss: 0.361\n",
            "Epoch: [1/2] | Iterations: [98/1995] | Training loss: 0.398\n",
            "Epoch: [1/2] | Iterations: [99/1995] | Training loss: 0.348\n",
            "Epoch: [1/2] | Iterations: [100/1995] | Training loss: 0.403\n",
            "Epoch: [1/2] | Iterations: [101/1995] | Training loss: 0.360\n",
            "Epoch: [1/2] | Iterations: [102/1995] | Training loss: 0.402\n",
            "Epoch: [1/2] | Iterations: [103/1995] | Training loss: 0.365\n",
            "Epoch: [1/2] | Iterations: [104/1995] | Training loss: 0.355\n",
            "Epoch: [1/2] | Iterations: [105/1995] | Training loss: 0.384\n",
            "Epoch: [1/2] | Iterations: [106/1995] | Training loss: 0.337\n",
            "Epoch: [1/2] | Iterations: [107/1995] | Training loss: 0.367\n",
            "Epoch: [1/2] | Iterations: [108/1995] | Training loss: 0.367\n",
            "Epoch: [1/2] | Iterations: [109/1995] | Training loss: 0.343\n",
            "Epoch: [1/2] | Iterations: [110/1995] | Training loss: 0.367\n",
            "Epoch: [1/2] | Iterations: [111/1995] | Training loss: 0.332\n",
            "Epoch: [1/2] | Iterations: [112/1995] | Training loss: 0.363\n",
            "Epoch: [1/2] | Iterations: [113/1995] | Training loss: 0.323\n",
            "Epoch: [1/2] | Iterations: [114/1995] | Training loss: 0.334\n",
            "Epoch: [1/2] | Iterations: [115/1995] | Training loss: 0.340\n",
            "Epoch: [1/2] | Iterations: [116/1995] | Training loss: 0.366\n",
            "Epoch: [1/2] | Iterations: [117/1995] | Training loss: 0.352\n",
            "Epoch: [1/2] | Iterations: [118/1995] | Training loss: 0.348\n",
            "Epoch: [1/2] | Iterations: [119/1995] | Training loss: 0.332\n",
            "Epoch: [1/2] | Iterations: [120/1995] | Training loss: 0.312\n",
            "Epoch: [1/2] | Iterations: [121/1995] | Training loss: 0.329\n",
            "Epoch: [1/2] | Iterations: [122/1995] | Training loss: 0.347\n",
            "Epoch: [1/2] | Iterations: [123/1995] | Training loss: 0.299\n",
            "Epoch: [1/2] | Iterations: [124/1995] | Training loss: 0.353\n",
            "Epoch: [1/2] | Iterations: [125/1995] | Training loss: 0.376\n",
            "Epoch: [1/2] | Iterations: [126/1995] | Training loss: 0.306\n",
            "Epoch: [1/2] | Iterations: [127/1995] | Training loss: 0.326\n",
            "Epoch: [1/2] | Iterations: [128/1995] | Training loss: 0.342\n",
            "Epoch: [1/2] | Iterations: [129/1995] | Training loss: 0.326\n",
            "Epoch: [1/2] | Iterations: [130/1995] | Training loss: 0.316\n",
            "Epoch: [1/2] | Iterations: [131/1995] | Training loss: 0.305\n",
            "Epoch: [1/2] | Iterations: [132/1995] | Training loss: 0.310\n",
            "Epoch: [1/2] | Iterations: [133/1995] | Training loss: 0.327\n",
            "Epoch: [1/2] | Iterations: [134/1995] | Training loss: 0.353\n",
            "Epoch: [1/2] | Iterations: [135/1995] | Training loss: 0.353\n",
            "Epoch: [1/2] | Iterations: [136/1995] | Training loss: 0.352\n",
            "Epoch: [1/2] | Iterations: [137/1995] | Training loss: 0.321\n",
            "Epoch: [1/2] | Iterations: [138/1995] | Training loss: 0.327\n",
            "Epoch: [1/2] | Iterations: [139/1995] | Training loss: 0.331\n",
            "Epoch: [1/2] | Iterations: [140/1995] | Training loss: 0.326\n",
            "Epoch: [1/2] | Iterations: [141/1995] | Training loss: 0.314\n",
            "Epoch: [1/2] | Iterations: [142/1995] | Training loss: 0.320\n",
            "Epoch: [1/2] | Iterations: [143/1995] | Training loss: 0.282\n",
            "Epoch: [1/2] | Iterations: [144/1995] | Training loss: 0.350\n",
            "Epoch: [1/2] | Iterations: [145/1995] | Training loss: 0.325\n",
            "Epoch: [1/2] | Iterations: [146/1995] | Training loss: 0.307\n",
            "Epoch: [1/2] | Iterations: [147/1995] | Training loss: 0.287\n",
            "Epoch: [1/2] | Iterations: [148/1995] | Training loss: 0.318\n",
            "Epoch: [1/2] | Iterations: [149/1995] | Training loss: 0.288\n",
            "Epoch: [1/2] | Iterations: [150/1995] | Training loss: 0.356\n",
            "Epoch: [1/2] | Iterations: [151/1995] | Training loss: 0.277\n",
            "Epoch: [1/2] | Iterations: [152/1995] | Training loss: 0.363\n",
            "Epoch: [1/2] | Iterations: [153/1995] | Training loss: 0.271\n",
            "Epoch: [1/2] | Iterations: [154/1995] | Training loss: 0.323\n",
            "Epoch: [1/2] | Iterations: [155/1995] | Training loss: 0.307\n",
            "Epoch: [1/2] | Iterations: [156/1995] | Training loss: 0.291\n",
            "Epoch: [1/2] | Iterations: [157/1995] | Training loss: 0.302\n",
            "Epoch: [1/2] | Iterations: [158/1995] | Training loss: 0.302\n",
            "Epoch: [1/2] | Iterations: [159/1995] | Training loss: 0.299\n",
            "Epoch: [1/2] | Iterations: [160/1995] | Training loss: 0.256\n",
            "Epoch: [1/2] | Iterations: [161/1995] | Training loss: 0.324\n",
            "Epoch: [1/2] | Iterations: [162/1995] | Training loss: 0.251\n",
            "Epoch: [1/2] | Iterations: [163/1995] | Training loss: 0.248\n",
            "Epoch: [1/2] | Iterations: [164/1995] | Training loss: 0.295\n",
            "Epoch: [1/2] | Iterations: [165/1995] | Training loss: 0.322\n",
            "Epoch: [1/2] | Iterations: [166/1995] | Training loss: 0.285\n",
            "Epoch: [1/2] | Iterations: [167/1995] | Training loss: 0.303\n",
            "Epoch: [1/2] | Iterations: [168/1995] | Training loss: 0.260\n",
            "Epoch: [1/2] | Iterations: [169/1995] | Training loss: 0.277\n",
            "Epoch: [1/2] | Iterations: [170/1995] | Training loss: 0.323\n",
            "Epoch: [1/2] | Iterations: [171/1995] | Training loss: 0.279\n",
            "Epoch: [1/2] | Iterations: [172/1995] | Training loss: 0.280\n",
            "Epoch: [1/2] | Iterations: [173/1995] | Training loss: 0.308\n",
            "Epoch: [1/2] | Iterations: [174/1995] | Training loss: 0.261\n",
            "Epoch: [1/2] | Iterations: [175/1995] | Training loss: 0.276\n",
            "Epoch: [1/2] | Iterations: [176/1995] | Training loss: 0.226\n",
            "Epoch: [1/2] | Iterations: [177/1995] | Training loss: 0.280\n",
            "Epoch: [1/2] | Iterations: [178/1995] | Training loss: 0.263\n",
            "Epoch: [1/2] | Iterations: [179/1995] | Training loss: 0.260\n",
            "Epoch: [1/2] | Iterations: [180/1995] | Training loss: 0.271\n",
            "Epoch: [1/2] | Iterations: [181/1995] | Training loss: 0.245\n",
            "Epoch: [1/2] | Iterations: [182/1995] | Training loss: 0.276\n",
            "Epoch: [1/2] | Iterations: [183/1995] | Training loss: 0.272\n",
            "Epoch: [1/2] | Iterations: [184/1995] | Training loss: 0.285\n",
            "Epoch: [1/2] | Iterations: [185/1995] | Training loss: 0.247\n",
            "Epoch: [1/2] | Iterations: [186/1995] | Training loss: 0.279\n",
            "Epoch: [1/2] | Iterations: [187/1995] | Training loss: 0.274\n",
            "Epoch: [1/2] | Iterations: [188/1995] | Training loss: 0.257\n",
            "Epoch: [1/2] | Iterations: [189/1995] | Training loss: 0.247\n",
            "Epoch: [1/2] | Iterations: [190/1995] | Training loss: 0.273\n",
            "Epoch: [1/2] | Iterations: [191/1995] | Training loss: 0.254\n",
            "Epoch: [1/2] | Iterations: [192/1995] | Training loss: 0.252\n",
            "Epoch: [1/2] | Iterations: [193/1995] | Training loss: 0.238\n",
            "Epoch: [1/2] | Iterations: [194/1995] | Training loss: 0.238\n",
            "Epoch: [1/2] | Iterations: [195/1995] | Training loss: 0.326\n",
            "Epoch: [1/2] | Iterations: [196/1995] | Training loss: 0.254\n",
            "Epoch: [1/2] | Iterations: [197/1995] | Training loss: 0.238\n",
            "Epoch: [1/2] | Iterations: [198/1995] | Training loss: 0.241\n",
            "Epoch: [1/2] | Iterations: [199/1995] | Training loss: 0.274\n",
            "Epoch: [1/2] | Iterations: [200/1995] | Training loss: 0.300\n",
            "Epoch: [1/2] | Iterations: [201/1995] | Training loss: 0.283\n",
            "Epoch: [1/2] | Iterations: [202/1995] | Training loss: 0.248\n",
            "Epoch: [1/2] | Iterations: [203/1995] | Training loss: 0.222\n",
            "Epoch: [1/2] | Iterations: [204/1995] | Training loss: 0.245\n",
            "Epoch: [1/2] | Iterations: [205/1995] | Training loss: 0.249\n",
            "Epoch: [1/2] | Iterations: [206/1995] | Training loss: 0.226\n",
            "Epoch: [1/2] | Iterations: [207/1995] | Training loss: 0.245\n",
            "Epoch: [1/2] | Iterations: [208/1995] | Training loss: 0.282\n",
            "Epoch: [1/2] | Iterations: [209/1995] | Training loss: 0.203\n",
            "Epoch: [1/2] | Iterations: [210/1995] | Training loss: 0.250\n",
            "Epoch: [1/2] | Iterations: [211/1995] | Training loss: 0.263\n",
            "Epoch: [1/2] | Iterations: [212/1995] | Training loss: 0.224\n",
            "Epoch: [1/2] | Iterations: [213/1995] | Training loss: 0.208\n",
            "Epoch: [1/2] | Iterations: [214/1995] | Training loss: 0.255\n",
            "Epoch: [1/2] | Iterations: [215/1995] | Training loss: 0.270\n",
            "Epoch: [1/2] | Iterations: [216/1995] | Training loss: 0.256\n",
            "Epoch: [1/2] | Iterations: [217/1995] | Training loss: 0.236\n",
            "Epoch: [1/2] | Iterations: [218/1995] | Training loss: 0.265\n",
            "Epoch: [1/2] | Iterations: [219/1995] | Training loss: 0.226\n",
            "Epoch: [1/2] | Iterations: [220/1995] | Training loss: 0.234\n",
            "Epoch: [1/2] | Iterations: [221/1995] | Training loss: 0.273\n",
            "Epoch: [1/2] | Iterations: [222/1995] | Training loss: 0.235\n",
            "Epoch: [1/2] | Iterations: [223/1995] | Training loss: 0.242\n",
            "Epoch: [1/2] | Iterations: [224/1995] | Training loss: 0.215\n",
            "Epoch: [1/2] | Iterations: [225/1995] | Training loss: 0.241\n",
            "Epoch: [1/2] | Iterations: [226/1995] | Training loss: 0.279\n",
            "Epoch: [1/2] | Iterations: [227/1995] | Training loss: 0.274\n",
            "Epoch: [1/2] | Iterations: [228/1995] | Training loss: 0.247\n",
            "Epoch: [1/2] | Iterations: [229/1995] | Training loss: 0.263\n",
            "Epoch: [1/2] | Iterations: [230/1995] | Training loss: 0.207\n",
            "Epoch: [1/2] | Iterations: [231/1995] | Training loss: 0.268\n",
            "Epoch: [1/2] | Iterations: [232/1995] | Training loss: 0.230\n",
            "Epoch: [1/2] | Iterations: [233/1995] | Training loss: 0.229\n",
            "Epoch: [1/2] | Iterations: [234/1995] | Training loss: 0.198\n",
            "Epoch: [1/2] | Iterations: [235/1995] | Training loss: 0.255\n",
            "Epoch: [1/2] | Iterations: [236/1995] | Training loss: 0.271\n",
            "Epoch: [1/2] | Iterations: [237/1995] | Training loss: 0.226\n",
            "Epoch: [1/2] | Iterations: [238/1995] | Training loss: 0.274\n",
            "Epoch: [1/2] | Iterations: [239/1995] | Training loss: 0.238\n",
            "Epoch: [1/2] | Iterations: [240/1995] | Training loss: 0.221\n",
            "Epoch: [1/2] | Iterations: [241/1995] | Training loss: 0.261\n",
            "Epoch: [1/2] | Iterations: [242/1995] | Training loss: 0.238\n",
            "Epoch: [1/2] | Iterations: [243/1995] | Training loss: 0.193\n",
            "Epoch: [1/2] | Iterations: [244/1995] | Training loss: 0.226\n",
            "Epoch: [1/2] | Iterations: [245/1995] | Training loss: 0.184\n",
            "Epoch: [1/2] | Iterations: [246/1995] | Training loss: 0.241\n",
            "Epoch: [1/2] | Iterations: [247/1995] | Training loss: 0.203\n",
            "Epoch: [1/2] | Iterations: [248/1995] | Training loss: 0.201\n",
            "Epoch: [1/2] | Iterations: [249/1995] | Training loss: 0.247\n",
            "Epoch: [1/2] | Iterations: [250/1995] | Training loss: 0.210\n",
            "Epoch: [1/2] | Iterations: [251/1995] | Training loss: 0.253\n",
            "Epoch: [1/2] | Iterations: [252/1995] | Training loss: 0.165\n",
            "Epoch: [1/2] | Iterations: [253/1995] | Training loss: 0.202\n",
            "Epoch: [1/2] | Iterations: [254/1995] | Training loss: 0.217\n",
            "Epoch: [1/2] | Iterations: [255/1995] | Training loss: 0.213\n",
            "Epoch: [1/2] | Iterations: [256/1995] | Training loss: 0.225\n",
            "Epoch: [1/2] | Iterations: [257/1995] | Training loss: 0.207\n",
            "Epoch: [1/2] | Iterations: [258/1995] | Training loss: 0.206\n",
            "Epoch: [1/2] | Iterations: [259/1995] | Training loss: 0.189\n",
            "Epoch: [1/2] | Iterations: [260/1995] | Training loss: 0.180\n",
            "Epoch: [1/2] | Iterations: [261/1995] | Training loss: 0.193\n",
            "Epoch: [1/2] | Iterations: [262/1995] | Training loss: 0.229\n",
            "Epoch: [1/2] | Iterations: [263/1995] | Training loss: 0.219\n",
            "Epoch: [1/2] | Iterations: [264/1995] | Training loss: 0.186\n",
            "Epoch: [1/2] | Iterations: [265/1995] | Training loss: 0.209\n",
            "Epoch: [1/2] | Iterations: [266/1995] | Training loss: 0.183\n",
            "Epoch: [1/2] | Iterations: [267/1995] | Training loss: 0.209\n",
            "Epoch: [1/2] | Iterations: [268/1995] | Training loss: 0.259\n",
            "Epoch: [1/2] | Iterations: [269/1995] | Training loss: 0.202\n",
            "Epoch: [1/2] | Iterations: [270/1995] | Training loss: 0.174\n",
            "Epoch: [1/2] | Iterations: [271/1995] | Training loss: 0.216\n",
            "Epoch: [1/2] | Iterations: [272/1995] | Training loss: 0.241\n",
            "Epoch: [1/2] | Iterations: [273/1995] | Training loss: 0.185\n",
            "Epoch: [1/2] | Iterations: [274/1995] | Training loss: 0.157\n",
            "Epoch: [1/2] | Iterations: [275/1995] | Training loss: 0.253\n",
            "Epoch: [1/2] | Iterations: [276/1995] | Training loss: 0.180\n",
            "Epoch: [1/2] | Iterations: [277/1995] | Training loss: 0.207\n",
            "Epoch: [1/2] | Iterations: [278/1995] | Training loss: 0.207\n",
            "Epoch: [1/2] | Iterations: [279/1995] | Training loss: 0.203\n",
            "Epoch: [1/2] | Iterations: [280/1995] | Training loss: 0.187\n",
            "Epoch: [1/2] | Iterations: [281/1995] | Training loss: 0.195\n",
            "Epoch: [1/2] | Iterations: [282/1995] | Training loss: 0.207\n",
            "Epoch: [1/2] | Iterations: [283/1995] | Training loss: 0.152\n",
            "Epoch: [1/2] | Iterations: [284/1995] | Training loss: 0.257\n",
            "Epoch: [1/2] | Iterations: [285/1995] | Training loss: 0.210\n",
            "Epoch: [1/2] | Iterations: [286/1995] | Training loss: 0.218\n",
            "Epoch: [1/2] | Iterations: [287/1995] | Training loss: 0.146\n",
            "Epoch: [1/2] | Iterations: [288/1995] | Training loss: 0.184\n",
            "Epoch: [1/2] | Iterations: [289/1995] | Training loss: 0.176\n",
            "Epoch: [1/2] | Iterations: [290/1995] | Training loss: 0.174\n",
            "Epoch: [1/2] | Iterations: [291/1995] | Training loss: 0.185\n",
            "Epoch: [1/2] | Iterations: [292/1995] | Training loss: 0.194\n",
            "Epoch: [1/2] | Iterations: [293/1995] | Training loss: 0.159\n",
            "Epoch: [1/2] | Iterations: [294/1995] | Training loss: 0.228\n",
            "Epoch: [1/2] | Iterations: [295/1995] | Training loss: 0.178\n",
            "Epoch: [1/2] | Iterations: [296/1995] | Training loss: 0.193\n",
            "Epoch: [1/2] | Iterations: [297/1995] | Training loss: 0.196\n",
            "Epoch: [1/2] | Iterations: [298/1995] | Training loss: 0.188\n",
            "Epoch: [1/2] | Iterations: [299/1995] | Training loss: 0.228\n",
            "Epoch: [1/2] | Iterations: [300/1995] | Training loss: 0.197\n",
            "Epoch: [1/2] | Iterations: [301/1995] | Training loss: 0.204\n",
            "Epoch: [1/2] | Iterations: [302/1995] | Training loss: 0.145\n",
            "Epoch: [1/2] | Iterations: [303/1995] | Training loss: 0.223\n",
            "Epoch: [1/2] | Iterations: [304/1995] | Training loss: 0.188\n",
            "Epoch: [1/2] | Iterations: [305/1995] | Training loss: 0.162\n",
            "Epoch: [1/2] | Iterations: [306/1995] | Training loss: 0.218\n",
            "Epoch: [1/2] | Iterations: [307/1995] | Training loss: 0.213\n",
            "Epoch: [1/2] | Iterations: [308/1995] | Training loss: 0.173\n",
            "Epoch: [1/2] | Iterations: [309/1995] | Training loss: 0.177\n",
            "Epoch: [1/2] | Iterations: [310/1995] | Training loss: 0.194\n",
            "Epoch: [1/2] | Iterations: [311/1995] | Training loss: 0.166\n",
            "Epoch: [1/2] | Iterations: [312/1995] | Training loss: 0.228\n",
            "Epoch: [1/2] | Iterations: [313/1995] | Training loss: 0.189\n",
            "Epoch: [1/2] | Iterations: [314/1995] | Training loss: 0.153\n",
            "Epoch: [1/2] | Iterations: [315/1995] | Training loss: 0.187\n",
            "Epoch: [1/2] | Iterations: [316/1995] | Training loss: 0.174\n",
            "Epoch: [1/2] | Iterations: [317/1995] | Training loss: 0.169\n",
            "Epoch: [1/2] | Iterations: [318/1995] | Training loss: 0.190\n",
            "Epoch: [1/2] | Iterations: [319/1995] | Training loss: 0.194\n",
            "Epoch: [1/2] | Iterations: [320/1995] | Training loss: 0.155\n",
            "Epoch: [1/2] | Iterations: [321/1995] | Training loss: 0.140\n",
            "Epoch: [1/2] | Iterations: [322/1995] | Training loss: 0.167\n",
            "Epoch: [1/2] | Iterations: [323/1995] | Training loss: 0.194\n",
            "Epoch: [1/2] | Iterations: [324/1995] | Training loss: 0.224\n",
            "Epoch: [1/2] | Iterations: [325/1995] | Training loss: 0.197\n",
            "Epoch: [1/2] | Iterations: [326/1995] | Training loss: 0.186\n",
            "Epoch: [1/2] | Iterations: [327/1995] | Training loss: 0.244\n",
            "Epoch: [1/2] | Iterations: [328/1995] | Training loss: 0.190\n",
            "Epoch: [1/2] | Iterations: [329/1995] | Training loss: 0.187\n",
            "Epoch: [1/2] | Iterations: [330/1995] | Training loss: 0.205\n",
            "Epoch: [1/2] | Iterations: [331/1995] | Training loss: 0.177\n",
            "Epoch: [1/2] | Iterations: [332/1995] | Training loss: 0.181\n",
            "Epoch: [1/2] | Iterations: [333/1995] | Training loss: 0.139\n",
            "Epoch: [1/2] | Iterations: [334/1995] | Training loss: 0.224\n",
            "Epoch: [1/2] | Iterations: [335/1995] | Training loss: 0.179\n",
            "Epoch: [1/2] | Iterations: [336/1995] | Training loss: 0.163\n",
            "Epoch: [1/2] | Iterations: [337/1995] | Training loss: 0.152\n",
            "Epoch: [1/2] | Iterations: [338/1995] | Training loss: 0.196\n",
            "Epoch: [1/2] | Iterations: [339/1995] | Training loss: 0.167\n",
            "Epoch: [1/2] | Iterations: [340/1995] | Training loss: 0.188\n",
            "Epoch: [1/2] | Iterations: [341/1995] | Training loss: 0.168\n",
            "Epoch: [1/2] | Iterations: [342/1995] | Training loss: 0.141\n",
            "Epoch: [1/2] | Iterations: [343/1995] | Training loss: 0.203\n",
            "Epoch: [1/2] | Iterations: [344/1995] | Training loss: 0.147\n",
            "Epoch: [1/2] | Iterations: [345/1995] | Training loss: 0.204\n",
            "Epoch: [1/2] | Iterations: [346/1995] | Training loss: 0.193\n",
            "Epoch: [1/2] | Iterations: [347/1995] | Training loss: 0.166\n",
            "Epoch: [1/2] | Iterations: [348/1995] | Training loss: 0.205\n",
            "Epoch: [1/2] | Iterations: [349/1995] | Training loss: 0.186\n",
            "Epoch: [1/2] | Iterations: [350/1995] | Training loss: 0.141\n",
            "Epoch: [1/2] | Iterations: [351/1995] | Training loss: 0.228\n",
            "Epoch: [1/2] | Iterations: [352/1995] | Training loss: 0.158\n",
            "Epoch: [1/2] | Iterations: [353/1995] | Training loss: 0.129\n",
            "Epoch: [1/2] | Iterations: [354/1995] | Training loss: 0.211\n",
            "Epoch: [1/2] | Iterations: [355/1995] | Training loss: 0.240\n",
            "Epoch: [1/2] | Iterations: [356/1995] | Training loss: 0.196\n",
            "Epoch: [1/2] | Iterations: [357/1995] | Training loss: 0.253\n",
            "Epoch: [1/2] | Iterations: [358/1995] | Training loss: 0.164\n",
            "Epoch: [1/2] | Iterations: [359/1995] | Training loss: 0.195\n",
            "Epoch: [1/2] | Iterations: [360/1995] | Training loss: 0.163\n",
            "Epoch: [1/2] | Iterations: [361/1995] | Training loss: 0.145\n",
            "Epoch: [1/2] | Iterations: [362/1995] | Training loss: 0.129\n",
            "Epoch: [1/2] | Iterations: [363/1995] | Training loss: 0.185\n",
            "Epoch: [1/2] | Iterations: [364/1995] | Training loss: 0.157\n",
            "Epoch: [1/2] | Iterations: [365/1995] | Training loss: 0.231\n",
            "Epoch: [1/2] | Iterations: [366/1995] | Training loss: 0.152\n",
            "Epoch: [1/2] | Iterations: [367/1995] | Training loss: 0.201\n",
            "Epoch: [1/2] | Iterations: [368/1995] | Training loss: 0.139\n",
            "Epoch: [1/2] | Iterations: [369/1995] | Training loss: 0.150\n",
            "Epoch: [1/2] | Iterations: [370/1995] | Training loss: 0.187\n",
            "Epoch: [1/2] | Iterations: [371/1995] | Training loss: 0.162\n",
            "Epoch: [1/2] | Iterations: [372/1995] | Training loss: 0.163\n",
            "Epoch: [1/2] | Iterations: [373/1995] | Training loss: 0.201\n",
            "Epoch: [1/2] | Iterations: [374/1995] | Training loss: 0.174\n",
            "Epoch: [1/2] | Iterations: [375/1995] | Training loss: 0.185\n",
            "Epoch: [1/2] | Iterations: [376/1995] | Training loss: 0.216\n",
            "Epoch: [1/2] | Iterations: [377/1995] | Training loss: 0.219\n",
            "Epoch: [1/2] | Iterations: [378/1995] | Training loss: 0.216\n",
            "Epoch: [1/2] | Iterations: [379/1995] | Training loss: 0.199\n",
            "Epoch: [1/2] | Iterations: [380/1995] | Training loss: 0.185\n",
            "Epoch: [1/2] | Iterations: [381/1995] | Training loss: 0.181\n",
            "Epoch: [1/2] | Iterations: [382/1995] | Training loss: 0.130\n",
            "Epoch: [1/2] | Iterations: [383/1995] | Training loss: 0.161\n",
            "Epoch: [1/2] | Iterations: [384/1995] | Training loss: 0.202\n",
            "Epoch: [1/2] | Iterations: [385/1995] | Training loss: 0.237\n",
            "Epoch: [1/2] | Iterations: [386/1995] | Training loss: 0.148\n",
            "Epoch: [1/2] | Iterations: [387/1995] | Training loss: 0.134\n",
            "Epoch: [1/2] | Iterations: [388/1995] | Training loss: 0.161\n",
            "Epoch: [1/2] | Iterations: [389/1995] | Training loss: 0.174\n",
            "Epoch: [1/2] | Iterations: [390/1995] | Training loss: 0.189\n",
            "Epoch: [1/2] | Iterations: [391/1995] | Training loss: 0.256\n",
            "Epoch: [1/2] | Iterations: [392/1995] | Training loss: 0.114\n",
            "Epoch: [1/2] | Iterations: [393/1995] | Training loss: 0.202\n",
            "Epoch: [1/2] | Iterations: [394/1995] | Training loss: 0.222\n",
            "Epoch: [1/2] | Iterations: [395/1995] | Training loss: 0.188\n",
            "Epoch: [1/2] | Iterations: [396/1995] | Training loss: 0.170\n",
            "Epoch: [1/2] | Iterations: [397/1995] | Training loss: 0.173\n",
            "Epoch: [1/2] | Iterations: [398/1995] | Training loss: 0.129\n",
            "Epoch: [1/2] | Iterations: [399/1995] | Training loss: 0.154\n",
            "Epoch: [1/2] | Iterations: [400/1995] | Training loss: 0.205\n",
            "Epoch: [1/2] | Iterations: [401/1995] | Training loss: 0.128\n",
            "Epoch: [1/2] | Iterations: [402/1995] | Training loss: 0.132\n",
            "Epoch: [1/2] | Iterations: [403/1995] | Training loss: 0.212\n",
            "Epoch: [1/2] | Iterations: [404/1995] | Training loss: 0.191\n",
            "Epoch: [1/2] | Iterations: [405/1995] | Training loss: 0.187\n",
            "Epoch: [1/2] | Iterations: [406/1995] | Training loss: 0.163\n",
            "Epoch: [1/2] | Iterations: [407/1995] | Training loss: 0.183\n",
            "Epoch: [1/2] | Iterations: [408/1995] | Training loss: 0.172\n",
            "Epoch: [1/2] | Iterations: [409/1995] | Training loss: 0.215\n",
            "Epoch: [1/2] | Iterations: [410/1995] | Training loss: 0.126\n",
            "Epoch: [1/2] | Iterations: [411/1995] | Training loss: 0.169\n",
            "Epoch: [1/2] | Iterations: [412/1995] | Training loss: 0.215\n",
            "Epoch: [1/2] | Iterations: [413/1995] | Training loss: 0.173\n",
            "Epoch: [1/2] | Iterations: [414/1995] | Training loss: 0.165\n",
            "Epoch: [1/2] | Iterations: [415/1995] | Training loss: 0.125\n",
            "Epoch: [1/2] | Iterations: [416/1995] | Training loss: 0.197\n",
            "Epoch: [1/2] | Iterations: [417/1995] | Training loss: 0.193\n",
            "Epoch: [1/2] | Iterations: [418/1995] | Training loss: 0.175\n",
            "Epoch: [1/2] | Iterations: [419/1995] | Training loss: 0.226\n",
            "Epoch: [1/2] | Iterations: [420/1995] | Training loss: 0.160\n",
            "Epoch: [1/2] | Iterations: [421/1995] | Training loss: 0.107\n",
            "Epoch: [1/2] | Iterations: [422/1995] | Training loss: 0.134\n",
            "Epoch: [1/2] | Iterations: [423/1995] | Training loss: 0.162\n",
            "Epoch: [1/2] | Iterations: [424/1995] | Training loss: 0.130\n",
            "Epoch: [1/2] | Iterations: [425/1995] | Training loss: 0.188\n",
            "Epoch: [1/2] | Iterations: [426/1995] | Training loss: 0.174\n",
            "Epoch: [1/2] | Iterations: [427/1995] | Training loss: 0.118\n",
            "Epoch: [1/2] | Iterations: [428/1995] | Training loss: 0.188\n",
            "Epoch: [1/2] | Iterations: [429/1995] | Training loss: 0.187\n",
            "Epoch: [1/2] | Iterations: [430/1995] | Training loss: 0.151\n",
            "Epoch: [1/2] | Iterations: [431/1995] | Training loss: 0.101\n",
            "Epoch: [1/2] | Iterations: [432/1995] | Training loss: 0.201\n",
            "Epoch: [1/2] | Iterations: [433/1995] | Training loss: 0.167\n",
            "Epoch: [1/2] | Iterations: [434/1995] | Training loss: 0.164\n",
            "Epoch: [1/2] | Iterations: [435/1995] | Training loss: 0.152\n",
            "Epoch: [1/2] | Iterations: [436/1995] | Training loss: 0.178\n",
            "Epoch: [1/2] | Iterations: [437/1995] | Training loss: 0.168\n",
            "Epoch: [1/2] | Iterations: [438/1995] | Training loss: 0.108\n",
            "Epoch: [1/2] | Iterations: [439/1995] | Training loss: 0.146\n",
            "Epoch: [1/2] | Iterations: [440/1995] | Training loss: 0.146\n",
            "Epoch: [1/2] | Iterations: [441/1995] | Training loss: 0.129\n",
            "Epoch: [1/2] | Iterations: [442/1995] | Training loss: 0.120\n",
            "Epoch: [1/2] | Iterations: [443/1995] | Training loss: 0.148\n",
            "Epoch: [1/2] | Iterations: [444/1995] | Training loss: 0.115\n",
            "Epoch: [1/2] | Iterations: [445/1995] | Training loss: 0.122\n",
            "Epoch: [1/2] | Iterations: [446/1995] | Training loss: 0.156\n",
            "Epoch: [1/2] | Iterations: [447/1995] | Training loss: 0.162\n",
            "Epoch: [1/2] | Iterations: [448/1995] | Training loss: 0.147\n",
            "Epoch: [1/2] | Iterations: [449/1995] | Training loss: 0.180\n",
            "Epoch: [1/2] | Iterations: [450/1995] | Training loss: 0.134\n",
            "Epoch: [1/2] | Iterations: [451/1995] | Training loss: 0.217\n",
            "Epoch: [1/2] | Iterations: [452/1995] | Training loss: 0.161\n",
            "Epoch: [1/2] | Iterations: [453/1995] | Training loss: 0.168\n",
            "Epoch: [1/2] | Iterations: [454/1995] | Training loss: 0.146\n",
            "Epoch: [1/2] | Iterations: [455/1995] | Training loss: 0.124\n",
            "Epoch: [1/2] | Iterations: [456/1995] | Training loss: 0.151\n",
            "Epoch: [1/2] | Iterations: [457/1995] | Training loss: 0.183\n",
            "Epoch: [1/2] | Iterations: [458/1995] | Training loss: 0.263\n",
            "Epoch: [1/2] | Iterations: [459/1995] | Training loss: 0.179\n",
            "Epoch: [1/2] | Iterations: [460/1995] | Training loss: 0.138\n",
            "Epoch: [1/2] | Iterations: [461/1995] | Training loss: 0.195\n",
            "Epoch: [1/2] | Iterations: [462/1995] | Training loss: 0.127\n",
            "Epoch: [1/2] | Iterations: [463/1995] | Training loss: 0.193\n",
            "Epoch: [1/2] | Iterations: [464/1995] | Training loss: 0.126\n",
            "Epoch: [1/2] | Iterations: [465/1995] | Training loss: 0.133\n",
            "Epoch: [1/2] | Iterations: [466/1995] | Training loss: 0.176\n",
            "Epoch: [1/2] | Iterations: [467/1995] | Training loss: 0.195\n",
            "Epoch: [1/2] | Iterations: [468/1995] | Training loss: 0.104\n",
            "Epoch: [1/2] | Iterations: [469/1995] | Training loss: 0.113\n",
            "Epoch: [1/2] | Iterations: [470/1995] | Training loss: 0.165\n",
            "Epoch: [1/2] | Iterations: [471/1995] | Training loss: 0.137\n",
            "Epoch: [1/2] | Iterations: [472/1995] | Training loss: 0.142\n",
            "Epoch: [1/2] | Iterations: [473/1995] | Training loss: 0.173\n",
            "Epoch: [1/2] | Iterations: [474/1995] | Training loss: 0.111\n",
            "Epoch: [1/2] | Iterations: [475/1995] | Training loss: 0.106\n",
            "Epoch: [1/2] | Iterations: [476/1995] | Training loss: 0.143\n",
            "Epoch: [1/2] | Iterations: [477/1995] | Training loss: 0.145\n",
            "Epoch: [1/2] | Iterations: [478/1995] | Training loss: 0.179\n",
            "Epoch: [1/2] | Iterations: [479/1995] | Training loss: 0.101\n",
            "Epoch: [1/2] | Iterations: [480/1995] | Training loss: 0.223\n",
            "Epoch: [1/2] | Iterations: [481/1995] | Training loss: 0.176\n",
            "Epoch: [1/2] | Iterations: [482/1995] | Training loss: 0.181\n",
            "Epoch: [1/2] | Iterations: [483/1995] | Training loss: 0.166\n",
            "Epoch: [1/2] | Iterations: [484/1995] | Training loss: 0.143\n",
            "Epoch: [1/2] | Iterations: [485/1995] | Training loss: 0.136\n",
            "Epoch: [1/2] | Iterations: [486/1995] | Training loss: 0.099\n",
            "Epoch: [1/2] | Iterations: [487/1995] | Training loss: 0.157\n",
            "Epoch: [1/2] | Iterations: [488/1995] | Training loss: 0.222\n",
            "Epoch: [1/2] | Iterations: [489/1995] | Training loss: 0.134\n",
            "Epoch: [1/2] | Iterations: [490/1995] | Training loss: 0.095\n",
            "Epoch: [1/2] | Iterations: [491/1995] | Training loss: 0.168\n",
            "Epoch: [1/2] | Iterations: [492/1995] | Training loss: 0.160\n",
            "Epoch: [1/2] | Iterations: [493/1995] | Training loss: 0.107\n",
            "Epoch: [1/2] | Iterations: [494/1995] | Training loss: 0.172\n",
            "Epoch: [1/2] | Iterations: [495/1995] | Training loss: 0.159\n",
            "Epoch: [1/2] | Iterations: [496/1995] | Training loss: 0.151\n",
            "Epoch: [1/2] | Iterations: [497/1995] | Training loss: 0.134\n",
            "Epoch: [1/2] | Iterations: [498/1995] | Training loss: 0.192\n",
            "Epoch: [1/2] | Iterations: [499/1995] | Training loss: 0.120\n",
            "Epoch: [1/2] | Iterations: [500/1995] | Training loss: 0.175\n",
            "Epoch: [1/2] | Iterations: [501/1995] | Training loss: 0.072\n",
            "Epoch: [1/2] | Iterations: [502/1995] | Training loss: 0.134\n",
            "Epoch: [1/2] | Iterations: [503/1995] | Training loss: 0.126\n",
            "Epoch: [1/2] | Iterations: [504/1995] | Training loss: 0.135\n",
            "Epoch: [1/2] | Iterations: [505/1995] | Training loss: 0.183\n",
            "Epoch: [1/2] | Iterations: [506/1995] | Training loss: 0.153\n",
            "Epoch: [1/2] | Iterations: [507/1995] | Training loss: 0.132\n",
            "Epoch: [1/2] | Iterations: [508/1995] | Training loss: 0.167\n",
            "Epoch: [1/2] | Iterations: [509/1995] | Training loss: 0.141\n",
            "Epoch: [1/2] | Iterations: [510/1995] | Training loss: 0.205\n",
            "Epoch: [1/2] | Iterations: [511/1995] | Training loss: 0.171\n",
            "Epoch: [1/2] | Iterations: [512/1995] | Training loss: 0.084\n",
            "Epoch: [1/2] | Iterations: [513/1995] | Training loss: 0.184\n",
            "Epoch: [1/2] | Iterations: [514/1995] | Training loss: 0.230\n",
            "Epoch: [1/2] | Iterations: [515/1995] | Training loss: 0.105\n",
            "Epoch: [1/2] | Iterations: [516/1995] | Training loss: 0.161\n",
            "Epoch: [1/2] | Iterations: [517/1995] | Training loss: 0.121\n",
            "Epoch: [1/2] | Iterations: [518/1995] | Training loss: 0.132\n",
            "Epoch: [1/2] | Iterations: [519/1995] | Training loss: 0.145\n",
            "Epoch: [1/2] | Iterations: [520/1995] | Training loss: 0.095\n",
            "Epoch: [1/2] | Iterations: [521/1995] | Training loss: 0.241\n",
            "Epoch: [1/2] | Iterations: [522/1995] | Training loss: 0.144\n",
            "Epoch: [1/2] | Iterations: [523/1995] | Training loss: 0.158\n",
            "Epoch: [1/2] | Iterations: [524/1995] | Training loss: 0.122\n",
            "Epoch: [1/2] | Iterations: [525/1995] | Training loss: 0.119\n",
            "Epoch: [1/2] | Iterations: [526/1995] | Training loss: 0.151\n",
            "Epoch: [1/2] | Iterations: [527/1995] | Training loss: 0.118\n",
            "Epoch: [1/2] | Iterations: [528/1995] | Training loss: 0.272\n",
            "Epoch: [1/2] | Iterations: [529/1995] | Training loss: 0.095\n",
            "Epoch: [1/2] | Iterations: [530/1995] | Training loss: 0.117\n",
            "Epoch: [1/2] | Iterations: [531/1995] | Training loss: 0.135\n",
            "Epoch: [1/2] | Iterations: [532/1995] | Training loss: 0.180\n",
            "Epoch: [1/2] | Iterations: [533/1995] | Training loss: 0.173\n",
            "Epoch: [1/2] | Iterations: [534/1995] | Training loss: 0.144\n",
            "Epoch: [1/2] | Iterations: [535/1995] | Training loss: 0.201\n",
            "Epoch: [1/2] | Iterations: [536/1995] | Training loss: 0.187\n",
            "Epoch: [1/2] | Iterations: [537/1995] | Training loss: 0.108\n",
            "Epoch: [1/2] | Iterations: [538/1995] | Training loss: 0.280\n",
            "Epoch: [1/2] | Iterations: [539/1995] | Training loss: 0.202\n",
            "Epoch: [1/2] | Iterations: [540/1995] | Training loss: 0.186\n",
            "Epoch: [1/2] | Iterations: [541/1995] | Training loss: 0.126\n",
            "Epoch: [1/2] | Iterations: [542/1995] | Training loss: 0.144\n",
            "Epoch: [1/2] | Iterations: [543/1995] | Training loss: 0.182\n",
            "Epoch: [1/2] | Iterations: [544/1995] | Training loss: 0.206\n",
            "Epoch: [1/2] | Iterations: [545/1995] | Training loss: 0.152\n",
            "Epoch: [1/2] | Iterations: [546/1995] | Training loss: 0.209\n",
            "Epoch: [1/2] | Iterations: [547/1995] | Training loss: 0.137\n",
            "Epoch: [1/2] | Iterations: [548/1995] | Training loss: 0.183\n",
            "Epoch: [1/2] | Iterations: [549/1995] | Training loss: 0.151\n",
            "Epoch: [1/2] | Iterations: [550/1995] | Training loss: 0.171\n",
            "Epoch: [1/2] | Iterations: [551/1995] | Training loss: 0.200\n",
            "Epoch: [1/2] | Iterations: [552/1995] | Training loss: 0.160\n",
            "Epoch: [1/2] | Iterations: [553/1995] | Training loss: 0.190\n",
            "Epoch: [1/2] | Iterations: [554/1995] | Training loss: 0.112\n",
            "Epoch: [1/2] | Iterations: [555/1995] | Training loss: 0.140\n",
            "Epoch: [1/2] | Iterations: [556/1995] | Training loss: 0.154\n",
            "Epoch: [1/2] | Iterations: [557/1995] | Training loss: 0.082\n",
            "Epoch: [1/2] | Iterations: [558/1995] | Training loss: 0.202\n",
            "Epoch: [1/2] | Iterations: [559/1995] | Training loss: 0.107\n",
            "Epoch: [1/2] | Iterations: [560/1995] | Training loss: 0.123\n",
            "Epoch: [1/2] | Iterations: [561/1995] | Training loss: 0.130\n",
            "Epoch: [1/2] | Iterations: [562/1995] | Training loss: 0.123\n",
            "Epoch: [1/2] | Iterations: [563/1995] | Training loss: 0.103\n",
            "Epoch: [1/2] | Iterations: [564/1995] | Training loss: 0.123\n",
            "Epoch: [1/2] | Iterations: [565/1995] | Training loss: 0.146\n",
            "Epoch: [1/2] | Iterations: [566/1995] | Training loss: 0.145\n",
            "Epoch: [1/2] | Iterations: [567/1995] | Training loss: 0.133\n",
            "Epoch: [1/2] | Iterations: [568/1995] | Training loss: 0.168\n",
            "Epoch: [1/2] | Iterations: [569/1995] | Training loss: 0.151\n",
            "Epoch: [1/2] | Iterations: [570/1995] | Training loss: 0.194\n",
            "Epoch: [1/2] | Iterations: [571/1995] | Training loss: 0.164\n",
            "Epoch: [1/2] | Iterations: [572/1995] | Training loss: 0.166\n",
            "Epoch: [1/2] | Iterations: [573/1995] | Training loss: 0.064\n",
            "Epoch: [1/2] | Iterations: [574/1995] | Training loss: 0.116\n",
            "Epoch: [1/2] | Iterations: [575/1995] | Training loss: 0.231\n",
            "Epoch: [1/2] | Iterations: [576/1995] | Training loss: 0.217\n",
            "Epoch: [1/2] | Iterations: [577/1995] | Training loss: 0.101\n",
            "Epoch: [1/2] | Iterations: [578/1995] | Training loss: 0.120\n",
            "Epoch: [1/2] | Iterations: [579/1995] | Training loss: 0.184\n",
            "Epoch: [1/2] | Iterations: [580/1995] | Training loss: 0.119\n",
            "Epoch: [1/2] | Iterations: [581/1995] | Training loss: 0.137\n",
            "Epoch: [1/2] | Iterations: [582/1995] | Training loss: 0.184\n",
            "Epoch: [1/2] | Iterations: [583/1995] | Training loss: 0.112\n",
            "Epoch: [1/2] | Iterations: [584/1995] | Training loss: 0.151\n",
            "Epoch: [1/2] | Iterations: [585/1995] | Training loss: 0.172\n",
            "Epoch: [1/2] | Iterations: [586/1995] | Training loss: 0.151\n",
            "Epoch: [1/2] | Iterations: [587/1995] | Training loss: 0.163\n",
            "Epoch: [1/2] | Iterations: [588/1995] | Training loss: 0.128\n",
            "Epoch: [1/2] | Iterations: [589/1995] | Training loss: 0.173\n",
            "Epoch: [1/2] | Iterations: [590/1995] | Training loss: 0.093\n",
            "Epoch: [1/2] | Iterations: [591/1995] | Training loss: 0.192\n",
            "Epoch: [1/2] | Iterations: [592/1995] | Training loss: 0.090\n",
            "Epoch: [1/2] | Iterations: [593/1995] | Training loss: 0.125\n",
            "Epoch: [1/2] | Iterations: [594/1995] | Training loss: 0.142\n",
            "Epoch: [1/2] | Iterations: [595/1995] | Training loss: 0.150\n",
            "Epoch: [1/2] | Iterations: [596/1995] | Training loss: 0.204\n",
            "Epoch: [1/2] | Iterations: [597/1995] | Training loss: 0.140\n",
            "Epoch: [1/2] | Iterations: [598/1995] | Training loss: 0.124\n",
            "Epoch: [1/2] | Iterations: [599/1995] | Training loss: 0.126\n",
            "Epoch: [1/2] | Iterations: [600/1995] | Training loss: 0.154\n",
            "Epoch: [1/2] | Iterations: [601/1995] | Training loss: 0.089\n",
            "Epoch: [1/2] | Iterations: [602/1995] | Training loss: 0.121\n",
            "Epoch: [1/2] | Iterations: [603/1995] | Training loss: 0.183\n",
            "Epoch: [1/2] | Iterations: [604/1995] | Training loss: 0.131\n",
            "Epoch: [1/2] | Iterations: [605/1995] | Training loss: 0.167\n",
            "Epoch: [1/2] | Iterations: [606/1995] | Training loss: 0.102\n",
            "Epoch: [1/2] | Iterations: [607/1995] | Training loss: 0.101\n",
            "Epoch: [1/2] | Iterations: [608/1995] | Training loss: 0.276\n",
            "Epoch: [1/2] | Iterations: [609/1995] | Training loss: 0.152\n",
            "Epoch: [1/2] | Iterations: [610/1995] | Training loss: 0.091\n",
            "Epoch: [1/2] | Iterations: [611/1995] | Training loss: 0.165\n",
            "Epoch: [1/2] | Iterations: [612/1995] | Training loss: 0.221\n",
            "Epoch: [1/2] | Iterations: [613/1995] | Training loss: 0.167\n",
            "Epoch: [1/2] | Iterations: [614/1995] | Training loss: 0.142\n",
            "Epoch: [1/2] | Iterations: [615/1995] | Training loss: 0.114\n",
            "Epoch: [1/2] | Iterations: [616/1995] | Training loss: 0.176\n",
            "Epoch: [1/2] | Iterations: [617/1995] | Training loss: 0.223\n",
            "Epoch: [1/2] | Iterations: [618/1995] | Training loss: 0.128\n",
            "Epoch: [1/2] | Iterations: [619/1995] | Training loss: 0.122\n",
            "Epoch: [1/2] | Iterations: [620/1995] | Training loss: 0.103\n",
            "Epoch: [1/2] | Iterations: [621/1995] | Training loss: 0.159\n",
            "Epoch: [1/2] | Iterations: [622/1995] | Training loss: 0.102\n",
            "Epoch: [1/2] | Iterations: [623/1995] | Training loss: 0.209\n",
            "Epoch: [1/2] | Iterations: [624/1995] | Training loss: 0.134\n",
            "Epoch: [1/2] | Iterations: [625/1995] | Training loss: 0.133\n",
            "Epoch: [1/2] | Iterations: [626/1995] | Training loss: 0.131\n",
            "Epoch: [1/2] | Iterations: [627/1995] | Training loss: 0.212\n",
            "Epoch: [1/2] | Iterations: [628/1995] | Training loss: 0.149\n",
            "Epoch: [1/2] | Iterations: [629/1995] | Training loss: 0.162\n",
            "Epoch: [1/2] | Iterations: [630/1995] | Training loss: 0.089\n",
            "Epoch: [1/2] | Iterations: [631/1995] | Training loss: 0.133\n",
            "Epoch: [1/2] | Iterations: [632/1995] | Training loss: 0.124\n",
            "Epoch: [1/2] | Iterations: [633/1995] | Training loss: 0.129\n",
            "Epoch: [1/2] | Iterations: [634/1995] | Training loss: 0.170\n",
            "Epoch: [1/2] | Iterations: [635/1995] | Training loss: 0.122\n",
            "Epoch: [1/2] | Iterations: [636/1995] | Training loss: 0.163\n",
            "Epoch: [1/2] | Iterations: [637/1995] | Training loss: 0.212\n",
            "Epoch: [1/2] | Iterations: [638/1995] | Training loss: 0.140\n",
            "Epoch: [1/2] | Iterations: [639/1995] | Training loss: 0.107\n",
            "Epoch: [1/2] | Iterations: [640/1995] | Training loss: 0.140\n",
            "Epoch: [1/2] | Iterations: [641/1995] | Training loss: 0.159\n",
            "Epoch: [1/2] | Iterations: [642/1995] | Training loss: 0.138\n",
            "Epoch: [1/2] | Iterations: [643/1995] | Training loss: 0.146\n",
            "Epoch: [1/2] | Iterations: [644/1995] | Training loss: 0.184\n",
            "Epoch: [1/2] | Iterations: [645/1995] | Training loss: 0.157\n",
            "Epoch: [1/2] | Iterations: [646/1995] | Training loss: 0.102\n",
            "Epoch: [1/2] | Iterations: [647/1995] | Training loss: 0.162\n",
            "Epoch: [1/2] | Iterations: [648/1995] | Training loss: 0.134\n",
            "Epoch: [1/2] | Iterations: [649/1995] | Training loss: 0.135\n",
            "Epoch: [1/2] | Iterations: [650/1995] | Training loss: 0.161\n",
            "Epoch: [1/2] | Iterations: [651/1995] | Training loss: 0.110\n",
            "Epoch: [1/2] | Iterations: [652/1995] | Training loss: 0.090\n",
            "Epoch: [1/2] | Iterations: [653/1995] | Training loss: 0.204\n",
            "Epoch: [1/2] | Iterations: [654/1995] | Training loss: 0.104\n",
            "Epoch: [1/2] | Iterations: [655/1995] | Training loss: 0.121\n",
            "Epoch: [1/2] | Iterations: [656/1995] | Training loss: 0.154\n",
            "Epoch: [1/2] | Iterations: [657/1995] | Training loss: 0.119\n",
            "Epoch: [1/2] | Iterations: [658/1995] | Training loss: 0.121\n",
            "Epoch: [1/2] | Iterations: [659/1995] | Training loss: 0.141\n",
            "Epoch: [1/2] | Iterations: [660/1995] | Training loss: 0.128\n",
            "Epoch: [1/2] | Iterations: [661/1995] | Training loss: 0.087\n",
            "Epoch: [1/2] | Iterations: [662/1995] | Training loss: 0.154\n",
            "Epoch: [1/2] | Iterations: [663/1995] | Training loss: 0.258\n",
            "Epoch: [1/2] | Iterations: [664/1995] | Training loss: 0.142\n",
            "Epoch: [1/2] | Iterations: [665/1995] | Training loss: 0.151\n",
            "Epoch: [1/2] | Iterations: [666/1995] | Training loss: 0.131\n",
            "Epoch: [1/2] | Iterations: [667/1995] | Training loss: 0.177\n",
            "Epoch: [1/2] | Iterations: [668/1995] | Training loss: 0.201\n",
            "Epoch: [1/2] | Iterations: [669/1995] | Training loss: 0.179\n",
            "Epoch: [1/2] | Iterations: [670/1995] | Training loss: 0.219\n",
            "Epoch: [1/2] | Iterations: [671/1995] | Training loss: 0.126\n",
            "Epoch: [1/2] | Iterations: [672/1995] | Training loss: 0.125\n",
            "Epoch: [1/2] | Iterations: [673/1995] | Training loss: 0.156\n",
            "Epoch: [1/2] | Iterations: [674/1995] | Training loss: 0.100\n",
            "Epoch: [1/2] | Iterations: [675/1995] | Training loss: 0.153\n",
            "Epoch: [1/2] | Iterations: [676/1995] | Training loss: 0.105\n",
            "Epoch: [1/2] | Iterations: [677/1995] | Training loss: 0.120\n",
            "Epoch: [1/2] | Iterations: [678/1995] | Training loss: 0.124\n",
            "Epoch: [1/2] | Iterations: [679/1995] | Training loss: 0.170\n",
            "Epoch: [1/2] | Iterations: [680/1995] | Training loss: 0.084\n",
            "Epoch: [1/2] | Iterations: [681/1995] | Training loss: 0.142\n",
            "Epoch: [1/2] | Iterations: [682/1995] | Training loss: 0.149\n",
            "Epoch: [1/2] | Iterations: [683/1995] | Training loss: 0.129\n",
            "Epoch: [1/2] | Iterations: [684/1995] | Training loss: 0.118\n",
            "Epoch: [1/2] | Iterations: [685/1995] | Training loss: 0.067\n",
            "Epoch: [1/2] | Iterations: [686/1995] | Training loss: 0.067\n",
            "Epoch: [1/2] | Iterations: [687/1995] | Training loss: 0.199\n",
            "Epoch: [1/2] | Iterations: [688/1995] | Training loss: 0.118\n",
            "Epoch: [1/2] | Iterations: [689/1995] | Training loss: 0.068\n",
            "Epoch: [1/2] | Iterations: [690/1995] | Training loss: 0.123\n",
            "Epoch: [1/2] | Iterations: [691/1995] | Training loss: 0.120\n",
            "Epoch: [1/2] | Iterations: [692/1995] | Training loss: 0.097\n",
            "Epoch: [1/2] | Iterations: [693/1995] | Training loss: 0.177\n",
            "Epoch: [1/2] | Iterations: [694/1995] | Training loss: 0.143\n",
            "Epoch: [1/2] | Iterations: [695/1995] | Training loss: 0.152\n",
            "Epoch: [1/2] | Iterations: [696/1995] | Training loss: 0.121\n",
            "Epoch: [1/2] | Iterations: [697/1995] | Training loss: 0.086\n",
            "Epoch: [1/2] | Iterations: [698/1995] | Training loss: 0.174\n",
            "Epoch: [1/2] | Iterations: [699/1995] | Training loss: 0.141\n",
            "Epoch: [1/2] | Iterations: [700/1995] | Training loss: 0.129\n",
            "Epoch: [1/2] | Iterations: [701/1995] | Training loss: 0.119\n",
            "Epoch: [1/2] | Iterations: [702/1995] | Training loss: 0.145\n",
            "Epoch: [1/2] | Iterations: [703/1995] | Training loss: 0.162\n",
            "Epoch: [1/2] | Iterations: [704/1995] | Training loss: 0.201\n",
            "Epoch: [1/2] | Iterations: [705/1995] | Training loss: 0.127\n",
            "Epoch: [1/2] | Iterations: [706/1995] | Training loss: 0.182\n",
            "Epoch: [1/2] | Iterations: [707/1995] | Training loss: 0.146\n",
            "Epoch: [1/2] | Iterations: [708/1995] | Training loss: 0.208\n",
            "Epoch: [1/2] | Iterations: [709/1995] | Training loss: 0.144\n",
            "Epoch: [1/2] | Iterations: [710/1995] | Training loss: 0.057\n",
            "Epoch: [1/2] | Iterations: [711/1995] | Training loss: 0.144\n",
            "Epoch: [1/2] | Iterations: [712/1995] | Training loss: 0.155\n",
            "Epoch: [1/2] | Iterations: [713/1995] | Training loss: 0.125\n",
            "Epoch: [1/2] | Iterations: [714/1995] | Training loss: 0.088\n",
            "Epoch: [1/2] | Iterations: [715/1995] | Training loss: 0.109\n",
            "Epoch: [1/2] | Iterations: [716/1995] | Training loss: 0.127\n",
            "Epoch: [1/2] | Iterations: [717/1995] | Training loss: 0.163\n",
            "Epoch: [1/2] | Iterations: [718/1995] | Training loss: 0.173\n",
            "Epoch: [1/2] | Iterations: [719/1995] | Training loss: 0.148\n",
            "Epoch: [1/2] | Iterations: [720/1995] | Training loss: 0.100\n",
            "Epoch: [1/2] | Iterations: [721/1995] | Training loss: 0.080\n",
            "Epoch: [1/2] | Iterations: [722/1995] | Training loss: 0.144\n",
            "Epoch: [1/2] | Iterations: [723/1995] | Training loss: 0.176\n",
            "Epoch: [1/2] | Iterations: [724/1995] | Training loss: 0.176\n",
            "Epoch: [1/2] | Iterations: [725/1995] | Training loss: 0.172\n",
            "Epoch: [1/2] | Iterations: [726/1995] | Training loss: 0.121\n",
            "Epoch: [1/2] | Iterations: [727/1995] | Training loss: 0.092\n",
            "Epoch: [1/2] | Iterations: [728/1995] | Training loss: 0.111\n",
            "Epoch: [1/2] | Iterations: [729/1995] | Training loss: 0.140\n",
            "Epoch: [1/2] | Iterations: [730/1995] | Training loss: 0.145\n",
            "Epoch: [1/2] | Iterations: [731/1995] | Training loss: 0.123\n",
            "Epoch: [1/2] | Iterations: [732/1995] | Training loss: 0.082\n",
            "Epoch: [1/2] | Iterations: [733/1995] | Training loss: 0.268\n",
            "Epoch: [1/2] | Iterations: [734/1995] | Training loss: 0.114\n",
            "Epoch: [1/2] | Iterations: [735/1995] | Training loss: 0.117\n",
            "Epoch: [1/2] | Iterations: [736/1995] | Training loss: 0.153\n",
            "Epoch: [1/2] | Iterations: [737/1995] | Training loss: 0.090\n",
            "Epoch: [1/2] | Iterations: [738/1995] | Training loss: 0.130\n",
            "Epoch: [1/2] | Iterations: [739/1995] | Training loss: 0.135\n",
            "Epoch: [1/2] | Iterations: [740/1995] | Training loss: 0.246\n",
            "Epoch: [1/2] | Iterations: [741/1995] | Training loss: 0.158\n",
            "Epoch: [1/2] | Iterations: [742/1995] | Training loss: 0.161\n",
            "Epoch: [1/2] | Iterations: [743/1995] | Training loss: 0.155\n",
            "Epoch: [1/2] | Iterations: [744/1995] | Training loss: 0.103\n",
            "Epoch: [1/2] | Iterations: [745/1995] | Training loss: 0.174\n",
            "Epoch: [1/2] | Iterations: [746/1995] | Training loss: 0.149\n",
            "Epoch: [1/2] | Iterations: [747/1995] | Training loss: 0.128\n",
            "Epoch: [1/2] | Iterations: [748/1995] | Training loss: 0.118\n",
            "Epoch: [1/2] | Iterations: [749/1995] | Training loss: 0.193\n",
            "Epoch: [1/2] | Iterations: [750/1995] | Training loss: 0.158\n",
            "Epoch: [1/2] | Iterations: [751/1995] | Training loss: 0.162\n",
            "Epoch: [1/2] | Iterations: [752/1995] | Training loss: 0.111\n",
            "Epoch: [1/2] | Iterations: [753/1995] | Training loss: 0.133\n",
            "Epoch: [1/2] | Iterations: [754/1995] | Training loss: 0.180\n",
            "Epoch: [1/2] | Iterations: [755/1995] | Training loss: 0.227\n",
            "Epoch: [1/2] | Iterations: [756/1995] | Training loss: 0.104\n",
            "Epoch: [1/2] | Iterations: [757/1995] | Training loss: 0.163\n",
            "Epoch: [1/2] | Iterations: [758/1995] | Training loss: 0.158\n",
            "Epoch: [1/2] | Iterations: [759/1995] | Training loss: 0.159\n",
            "Epoch: [1/2] | Iterations: [760/1995] | Training loss: 0.158\n",
            "Epoch: [1/2] | Iterations: [761/1995] | Training loss: 0.112\n",
            "Epoch: [1/2] | Iterations: [762/1995] | Training loss: 0.192\n",
            "Epoch: [1/2] | Iterations: [763/1995] | Training loss: 0.163\n",
            "Epoch: [1/2] | Iterations: [764/1995] | Training loss: 0.107\n",
            "Epoch: [1/2] | Iterations: [765/1995] | Training loss: 0.123\n",
            "Epoch: [1/2] | Iterations: [766/1995] | Training loss: 0.122\n",
            "Epoch: [1/2] | Iterations: [767/1995] | Training loss: 0.112\n",
            "Epoch: [1/2] | Iterations: [768/1995] | Training loss: 0.243\n",
            "Epoch: [1/2] | Iterations: [769/1995] | Training loss: 0.217\n",
            "Epoch: [1/2] | Iterations: [770/1995] | Training loss: 0.166\n",
            "Epoch: [1/2] | Iterations: [771/1995] | Training loss: 0.124\n",
            "Epoch: [1/2] | Iterations: [772/1995] | Training loss: 0.182\n",
            "Epoch: [1/2] | Iterations: [773/1995] | Training loss: 0.128\n",
            "Epoch: [1/2] | Iterations: [774/1995] | Training loss: 0.113\n",
            "Epoch: [1/2] | Iterations: [775/1995] | Training loss: 0.164\n",
            "Epoch: [1/2] | Iterations: [776/1995] | Training loss: 0.206\n",
            "Epoch: [1/2] | Iterations: [777/1995] | Training loss: 0.140\n",
            "Epoch: [1/2] | Iterations: [778/1995] | Training loss: 0.153\n",
            "Epoch: [1/2] | Iterations: [779/1995] | Training loss: 0.111\n",
            "Epoch: [1/2] | Iterations: [780/1995] | Training loss: 0.160\n",
            "Epoch: [1/2] | Iterations: [781/1995] | Training loss: 0.089\n",
            "Epoch: [1/2] | Iterations: [782/1995] | Training loss: 0.177\n",
            "Epoch: [1/2] | Iterations: [783/1995] | Training loss: 0.192\n",
            "Epoch: [1/2] | Iterations: [784/1995] | Training loss: 0.121\n",
            "Epoch: [1/2] | Iterations: [785/1995] | Training loss: 0.106\n",
            "Epoch: [1/2] | Iterations: [786/1995] | Training loss: 0.155\n",
            "Epoch: [1/2] | Iterations: [787/1995] | Training loss: 0.135\n",
            "Epoch: [1/2] | Iterations: [788/1995] | Training loss: 0.103\n",
            "Epoch: [1/2] | Iterations: [789/1995] | Training loss: 0.112\n",
            "Epoch: [1/2] | Iterations: [790/1995] | Training loss: 0.141\n",
            "Epoch: [1/2] | Iterations: [791/1995] | Training loss: 0.153\n",
            "Epoch: [1/2] | Iterations: [792/1995] | Training loss: 0.161\n",
            "Epoch: [1/2] | Iterations: [793/1995] | Training loss: 0.090\n",
            "Epoch: [1/2] | Iterations: [794/1995] | Training loss: 0.172\n",
            "Epoch: [1/2] | Iterations: [795/1995] | Training loss: 0.139\n",
            "Epoch: [1/2] | Iterations: [796/1995] | Training loss: 0.187\n",
            "Epoch: [1/2] | Iterations: [797/1995] | Training loss: 0.057\n",
            "Epoch: [1/2] | Iterations: [798/1995] | Training loss: 0.209\n",
            "Epoch: [1/2] | Iterations: [799/1995] | Training loss: 0.125\n",
            "Epoch: [1/2] | Iterations: [800/1995] | Training loss: 0.127\n",
            "Epoch: [1/2] | Iterations: [801/1995] | Training loss: 0.102\n",
            "Epoch: [1/2] | Iterations: [802/1995] | Training loss: 0.140\n",
            "Epoch: [1/2] | Iterations: [803/1995] | Training loss: 0.197\n",
            "Epoch: [1/2] | Iterations: [804/1995] | Training loss: 0.092\n",
            "Epoch: [1/2] | Iterations: [805/1995] | Training loss: 0.086\n",
            "Epoch: [1/2] | Iterations: [806/1995] | Training loss: 0.156\n",
            "Epoch: [1/2] | Iterations: [807/1995] | Training loss: 0.107\n",
            "Epoch: [1/2] | Iterations: [808/1995] | Training loss: 0.127\n",
            "Epoch: [1/2] | Iterations: [809/1995] | Training loss: 0.089\n",
            "Epoch: [1/2] | Iterations: [810/1995] | Training loss: 0.133\n",
            "Epoch: [1/2] | Iterations: [811/1995] | Training loss: 0.100\n",
            "Epoch: [1/2] | Iterations: [812/1995] | Training loss: 0.149\n",
            "Epoch: [1/2] | Iterations: [813/1995] | Training loss: 0.120\n",
            "Epoch: [1/2] | Iterations: [814/1995] | Training loss: 0.118\n",
            "Epoch: [1/2] | Iterations: [815/1995] | Training loss: 0.085\n",
            "Epoch: [1/2] | Iterations: [816/1995] | Training loss: 0.167\n",
            "Epoch: [1/2] | Iterations: [817/1995] | Training loss: 0.206\n",
            "Epoch: [1/2] | Iterations: [818/1995] | Training loss: 0.206\n",
            "Epoch: [1/2] | Iterations: [819/1995] | Training loss: 0.221\n",
            "Epoch: [1/2] | Iterations: [820/1995] | Training loss: 0.194\n",
            "Epoch: [1/2] | Iterations: [821/1995] | Training loss: 0.189\n",
            "Epoch: [1/2] | Iterations: [822/1995] | Training loss: 0.128\n",
            "Epoch: [1/2] | Iterations: [823/1995] | Training loss: 0.114\n",
            "Epoch: [1/2] | Iterations: [824/1995] | Training loss: 0.177\n",
            "Epoch: [1/2] | Iterations: [825/1995] | Training loss: 0.068\n",
            "Epoch: [1/2] | Iterations: [826/1995] | Training loss: 0.145\n",
            "Epoch: [1/2] | Iterations: [827/1995] | Training loss: 0.243\n",
            "Epoch: [1/2] | Iterations: [828/1995] | Training loss: 0.125\n",
            "Epoch: [1/2] | Iterations: [829/1995] | Training loss: 0.109\n",
            "Epoch: [1/2] | Iterations: [830/1995] | Training loss: 0.120\n",
            "Epoch: [1/2] | Iterations: [831/1995] | Training loss: 0.120\n",
            "Epoch: [1/2] | Iterations: [832/1995] | Training loss: 0.201\n",
            "Epoch: [1/2] | Iterations: [833/1995] | Training loss: 0.111\n",
            "Epoch: [1/2] | Iterations: [834/1995] | Training loss: 0.078\n",
            "Epoch: [1/2] | Iterations: [835/1995] | Training loss: 0.251\n",
            "Epoch: [1/2] | Iterations: [836/1995] | Training loss: 0.179\n",
            "Epoch: [1/2] | Iterations: [837/1995] | Training loss: 0.120\n",
            "Epoch: [1/2] | Iterations: [838/1995] | Training loss: 0.097\n",
            "Epoch: [1/2] | Iterations: [839/1995] | Training loss: 0.071\n",
            "Epoch: [1/2] | Iterations: [840/1995] | Training loss: 0.154\n",
            "Epoch: [1/2] | Iterations: [841/1995] | Training loss: 0.115\n",
            "Epoch: [1/2] | Iterations: [842/1995] | Training loss: 0.116\n",
            "Epoch: [1/2] | Iterations: [843/1995] | Training loss: 0.095\n",
            "Epoch: [1/2] | Iterations: [844/1995] | Training loss: 0.125\n",
            "Epoch: [1/2] | Iterations: [845/1995] | Training loss: 0.138\n",
            "Epoch: [1/2] | Iterations: [846/1995] | Training loss: 0.164\n",
            "Epoch: [1/2] | Iterations: [847/1995] | Training loss: 0.120\n",
            "Epoch: [1/2] | Iterations: [848/1995] | Training loss: 0.085\n",
            "Epoch: [1/2] | Iterations: [849/1995] | Training loss: 0.132\n",
            "Epoch: [1/2] | Iterations: [850/1995] | Training loss: 0.169\n",
            "Epoch: [1/2] | Iterations: [851/1995] | Training loss: 0.101\n",
            "Epoch: [1/2] | Iterations: [852/1995] | Training loss: 0.119\n",
            "Epoch: [1/2] | Iterations: [853/1995] | Training loss: 0.112\n",
            "Epoch: [1/2] | Iterations: [854/1995] | Training loss: 0.120\n",
            "Epoch: [1/2] | Iterations: [855/1995] | Training loss: 0.218\n",
            "Epoch: [1/2] | Iterations: [856/1995] | Training loss: 0.154\n",
            "Epoch: [1/2] | Iterations: [857/1995] | Training loss: 0.116\n",
            "Epoch: [1/2] | Iterations: [858/1995] | Training loss: 0.116\n",
            "Epoch: [1/2] | Iterations: [859/1995] | Training loss: 0.148\n",
            "Epoch: [1/2] | Iterations: [860/1995] | Training loss: 0.125\n",
            "Epoch: [1/2] | Iterations: [861/1995] | Training loss: 0.235\n",
            "Epoch: [1/2] | Iterations: [862/1995] | Training loss: 0.074\n",
            "Epoch: [1/2] | Iterations: [863/1995] | Training loss: 0.110\n",
            "Epoch: [1/2] | Iterations: [864/1995] | Training loss: 0.155\n",
            "Epoch: [1/2] | Iterations: [865/1995] | Training loss: 0.192\n",
            "Epoch: [1/2] | Iterations: [866/1995] | Training loss: 0.150\n",
            "Epoch: [1/2] | Iterations: [867/1995] | Training loss: 0.092\n",
            "Epoch: [1/2] | Iterations: [868/1995] | Training loss: 0.126\n",
            "Epoch: [1/2] | Iterations: [869/1995] | Training loss: 0.120\n",
            "Epoch: [1/2] | Iterations: [870/1995] | Training loss: 0.146\n",
            "Epoch: [1/2] | Iterations: [871/1995] | Training loss: 0.186\n",
            "Epoch: [1/2] | Iterations: [872/1995] | Training loss: 0.183\n",
            "Epoch: [1/2] | Iterations: [873/1995] | Training loss: 0.067\n",
            "Epoch: [1/2] | Iterations: [874/1995] | Training loss: 0.171\n",
            "Epoch: [1/2] | Iterations: [875/1995] | Training loss: 0.194\n",
            "Epoch: [1/2] | Iterations: [876/1995] | Training loss: 0.124\n",
            "Epoch: [1/2] | Iterations: [877/1995] | Training loss: 0.153\n",
            "Epoch: [1/2] | Iterations: [878/1995] | Training loss: 0.084\n",
            "Epoch: [1/2] | Iterations: [879/1995] | Training loss: 0.148\n",
            "Epoch: [1/2] | Iterations: [880/1995] | Training loss: 0.195\n",
            "Epoch: [1/2] | Iterations: [881/1995] | Training loss: 0.126\n",
            "Epoch: [1/2] | Iterations: [882/1995] | Training loss: 0.119\n",
            "Epoch: [1/2] | Iterations: [883/1995] | Training loss: 0.114\n",
            "Epoch: [1/2] | Iterations: [884/1995] | Training loss: 0.181\n",
            "Epoch: [1/2] | Iterations: [885/1995] | Training loss: 0.127\n",
            "Epoch: [1/2] | Iterations: [886/1995] | Training loss: 0.103\n",
            "Epoch: [1/2] | Iterations: [887/1995] | Training loss: 0.097\n",
            "Epoch: [1/2] | Iterations: [888/1995] | Training loss: 0.073\n",
            "Epoch: [1/2] | Iterations: [889/1995] | Training loss: 0.141\n",
            "Epoch: [1/2] | Iterations: [890/1995] | Training loss: 0.143\n",
            "Epoch: [1/2] | Iterations: [891/1995] | Training loss: 0.139\n",
            "Epoch: [1/2] | Iterations: [892/1995] | Training loss: 0.158\n",
            "Epoch: [1/2] | Iterations: [893/1995] | Training loss: 0.174\n",
            "Epoch: [1/2] | Iterations: [894/1995] | Training loss: 0.191\n",
            "Epoch: [1/2] | Iterations: [895/1995] | Training loss: 0.197\n",
            "Epoch: [1/2] | Iterations: [896/1995] | Training loss: 0.156\n",
            "Epoch: [1/2] | Iterations: [897/1995] | Training loss: 0.146\n",
            "Epoch: [1/2] | Iterations: [898/1995] | Training loss: 0.184\n",
            "Epoch: [1/2] | Iterations: [899/1995] | Training loss: 0.094\n",
            "Epoch: [1/2] | Iterations: [900/1995] | Training loss: 0.089\n",
            "Epoch: [1/2] | Iterations: [901/1995] | Training loss: 0.110\n",
            "Epoch: [1/2] | Iterations: [902/1995] | Training loss: 0.192\n",
            "Epoch: [1/2] | Iterations: [903/1995] | Training loss: 0.151\n",
            "Epoch: [1/2] | Iterations: [904/1995] | Training loss: 0.125\n",
            "Epoch: [1/2] | Iterations: [905/1995] | Training loss: 0.123\n",
            "Epoch: [1/2] | Iterations: [906/1995] | Training loss: 0.148\n",
            "Epoch: [1/2] | Iterations: [907/1995] | Training loss: 0.149\n",
            "Epoch: [1/2] | Iterations: [908/1995] | Training loss: 0.113\n",
            "Epoch: [1/2] | Iterations: [909/1995] | Training loss: 0.133\n",
            "Epoch: [1/2] | Iterations: [910/1995] | Training loss: 0.168\n",
            "Epoch: [1/2] | Iterations: [911/1995] | Training loss: 0.158\n",
            "Epoch: [1/2] | Iterations: [912/1995] | Training loss: 0.143\n",
            "Epoch: [1/2] | Iterations: [913/1995] | Training loss: 0.130\n",
            "Epoch: [1/2] | Iterations: [914/1995] | Training loss: 0.125\n",
            "Epoch: [1/2] | Iterations: [915/1995] | Training loss: 0.115\n",
            "Epoch: [1/2] | Iterations: [916/1995] | Training loss: 0.100\n",
            "Epoch: [1/2] | Iterations: [917/1995] | Training loss: 0.206\n",
            "Epoch: [1/2] | Iterations: [918/1995] | Training loss: 0.160\n",
            "Epoch: [1/2] | Iterations: [919/1995] | Training loss: 0.143\n",
            "Epoch: [1/2] | Iterations: [920/1995] | Training loss: 0.067\n",
            "Epoch: [1/2] | Iterations: [921/1995] | Training loss: 0.191\n",
            "Epoch: [1/2] | Iterations: [922/1995] | Training loss: 0.102\n",
            "Epoch: [1/2] | Iterations: [923/1995] | Training loss: 0.178\n",
            "Epoch: [1/2] | Iterations: [924/1995] | Training loss: 0.138\n",
            "Epoch: [1/2] | Iterations: [925/1995] | Training loss: 0.120\n",
            "Epoch: [1/2] | Iterations: [926/1995] | Training loss: 0.138\n",
            "Epoch: [1/2] | Iterations: [927/1995] | Training loss: 0.130\n",
            "Epoch: [1/2] | Iterations: [928/1995] | Training loss: 0.076\n",
            "Epoch: [1/2] | Iterations: [929/1995] | Training loss: 0.089\n",
            "Epoch: [1/2] | Iterations: [930/1995] | Training loss: 0.089\n",
            "Epoch: [1/2] | Iterations: [931/1995] | Training loss: 0.128\n",
            "Epoch: [1/2] | Iterations: [932/1995] | Training loss: 0.142\n",
            "Epoch: [1/2] | Iterations: [933/1995] | Training loss: 0.126\n",
            "Epoch: [1/2] | Iterations: [934/1995] | Training loss: 0.099\n",
            "Epoch: [1/2] | Iterations: [935/1995] | Training loss: 0.081\n",
            "Epoch: [1/2] | Iterations: [936/1995] | Training loss: 0.122\n",
            "Epoch: [1/2] | Iterations: [937/1995] | Training loss: 0.108\n",
            "Epoch: [1/2] | Iterations: [938/1995] | Training loss: 0.074\n",
            "Epoch: [1/2] | Iterations: [939/1995] | Training loss: 0.148\n",
            "Epoch: [1/2] | Iterations: [940/1995] | Training loss: 0.185\n",
            "Epoch: [1/2] | Iterations: [941/1995] | Training loss: 0.087\n",
            "Epoch: [1/2] | Iterations: [942/1995] | Training loss: 0.120\n",
            "Epoch: [1/2] | Iterations: [943/1995] | Training loss: 0.132\n",
            "Epoch: [1/2] | Iterations: [944/1995] | Training loss: 0.116\n",
            "Epoch: [1/2] | Iterations: [945/1995] | Training loss: 0.145\n",
            "Epoch: [1/2] | Iterations: [946/1995] | Training loss: 0.180\n",
            "Epoch: [1/2] | Iterations: [947/1995] | Training loss: 0.129\n",
            "Epoch: [1/2] | Iterations: [948/1995] | Training loss: 0.213\n",
            "Epoch: [1/2] | Iterations: [949/1995] | Training loss: 0.086\n",
            "Epoch: [1/2] | Iterations: [950/1995] | Training loss: 0.183\n",
            "Epoch: [1/2] | Iterations: [951/1995] | Training loss: 0.142\n",
            "Epoch: [1/2] | Iterations: [952/1995] | Training loss: 0.111\n",
            "Epoch: [1/2] | Iterations: [953/1995] | Training loss: 0.074\n",
            "Epoch: [1/2] | Iterations: [954/1995] | Training loss: 0.082\n",
            "Epoch: [1/2] | Iterations: [955/1995] | Training loss: 0.192\n",
            "Epoch: [1/2] | Iterations: [956/1995] | Training loss: 0.123\n",
            "Epoch: [1/2] | Iterations: [957/1995] | Training loss: 0.126\n",
            "Epoch: [1/2] | Iterations: [958/1995] | Training loss: 0.091\n",
            "Epoch: [1/2] | Iterations: [959/1995] | Training loss: 0.125\n",
            "Epoch: [1/2] | Iterations: [960/1995] | Training loss: 0.162\n",
            "Epoch: [1/2] | Iterations: [961/1995] | Training loss: 0.207\n",
            "Epoch: [1/2] | Iterations: [962/1995] | Training loss: 0.100\n",
            "Epoch: [1/2] | Iterations: [963/1995] | Training loss: 0.094\n",
            "Epoch: [1/2] | Iterations: [964/1995] | Training loss: 0.144\n",
            "Epoch: [1/2] | Iterations: [965/1995] | Training loss: 0.133\n",
            "Epoch: [1/2] | Iterations: [966/1995] | Training loss: 0.176\n",
            "Epoch: [1/2] | Iterations: [967/1995] | Training loss: 0.101\n",
            "Epoch: [1/2] | Iterations: [968/1995] | Training loss: 0.073\n",
            "Epoch: [1/2] | Iterations: [969/1995] | Training loss: 0.144\n",
            "Epoch: [1/2] | Iterations: [970/1995] | Training loss: 0.056\n",
            "Epoch: [1/2] | Iterations: [971/1995] | Training loss: 0.148\n",
            "Epoch: [1/2] | Iterations: [972/1995] | Training loss: 0.114\n",
            "Epoch: [1/2] | Iterations: [973/1995] | Training loss: 0.172\n",
            "Epoch: [1/2] | Iterations: [974/1995] | Training loss: 0.125\n",
            "Epoch: [1/2] | Iterations: [975/1995] | Training loss: 0.115\n",
            "Epoch: [1/2] | Iterations: [976/1995] | Training loss: 0.144\n",
            "Epoch: [1/2] | Iterations: [977/1995] | Training loss: 0.090\n",
            "Epoch: [1/2] | Iterations: [978/1995] | Training loss: 0.174\n",
            "Epoch: [1/2] | Iterations: [979/1995] | Training loss: 0.116\n",
            "Epoch: [1/2] | Iterations: [980/1995] | Training loss: 0.072\n",
            "Epoch: [1/2] | Iterations: [981/1995] | Training loss: 0.111\n",
            "Epoch: [1/2] | Iterations: [982/1995] | Training loss: 0.076\n",
            "Epoch: [1/2] | Iterations: [983/1995] | Training loss: 0.164\n",
            "Epoch: [1/2] | Iterations: [984/1995] | Training loss: 0.091\n",
            "Epoch: [1/2] | Iterations: [985/1995] | Training loss: 0.156\n",
            "Epoch: [1/2] | Iterations: [986/1995] | Training loss: 0.115\n",
            "Epoch: [1/2] | Iterations: [987/1995] | Training loss: 0.113\n",
            "Epoch: [1/2] | Iterations: [988/1995] | Training loss: 0.123\n",
            "Epoch: [1/2] | Iterations: [989/1995] | Training loss: 0.128\n",
            "Epoch: [1/2] | Iterations: [990/1995] | Training loss: 0.115\n",
            "Epoch: [1/2] | Iterations: [991/1995] | Training loss: 0.194\n",
            "Epoch: [1/2] | Iterations: [992/1995] | Training loss: 0.130\n",
            "Epoch: [1/2] | Iterations: [993/1995] | Training loss: 0.247\n",
            "Epoch: [1/2] | Iterations: [994/1995] | Training loss: 0.144\n",
            "Epoch: [1/2] | Iterations: [995/1995] | Training loss: 0.161\n",
            "Epoch: [1/2] | Iterations: [996/1995] | Training loss: 0.147\n",
            "Epoch: [1/2] | Iterations: [997/1995] | Training loss: 0.114\n",
            "Epoch: [1/2] | Iterations: [998/1995] | Training loss: 0.146\n",
            "Epoch: [1/2] | Iterations: [999/1995] | Training loss: 0.244\n",
            "Epoch: [1/2] | Iterations: [1000/1995] | Training loss: 0.130\n",
            "Epoch: [1/2] | Iterations: [1001/1995] | Training loss: 0.198\n",
            "Epoch: [1/2] | Iterations: [1002/1995] | Training loss: 0.210\n",
            "Epoch: [1/2] | Iterations: [1003/1995] | Training loss: 0.082\n",
            "Epoch: [1/2] | Iterations: [1004/1995] | Training loss: 0.192\n",
            "Epoch: [1/2] | Iterations: [1005/1995] | Training loss: 0.149\n",
            "Epoch: [1/2] | Iterations: [1006/1995] | Training loss: 0.083\n",
            "Epoch: [1/2] | Iterations: [1007/1995] | Training loss: 0.177\n",
            "Epoch: [1/2] | Iterations: [1008/1995] | Training loss: 0.113\n",
            "Epoch: [1/2] | Iterations: [1009/1995] | Training loss: 0.159\n",
            "Epoch: [1/2] | Iterations: [1010/1995] | Training loss: 0.208\n",
            "Epoch: [1/2] | Iterations: [1011/1995] | Training loss: 0.106\n",
            "Epoch: [1/2] | Iterations: [1012/1995] | Training loss: 0.093\n",
            "Epoch: [1/2] | Iterations: [1013/1995] | Training loss: 0.122\n",
            "Epoch: [1/2] | Iterations: [1014/1995] | Training loss: 0.127\n",
            "Epoch: [1/2] | Iterations: [1015/1995] | Training loss: 0.167\n",
            "Epoch: [1/2] | Iterations: [1016/1995] | Training loss: 0.138\n",
            "Epoch: [1/2] | Iterations: [1017/1995] | Training loss: 0.147\n",
            "Epoch: [1/2] | Iterations: [1018/1995] | Training loss: 0.154\n",
            "Epoch: [1/2] | Iterations: [1019/1995] | Training loss: 0.141\n",
            "Epoch: [1/2] | Iterations: [1020/1995] | Training loss: 0.167\n",
            "Epoch: [1/2] | Iterations: [1021/1995] | Training loss: 0.164\n",
            "Epoch: [1/2] | Iterations: [1022/1995] | Training loss: 0.084\n",
            "Epoch: [1/2] | Iterations: [1023/1995] | Training loss: 0.186\n",
            "Epoch: [1/2] | Iterations: [1024/1995] | Training loss: 0.085\n",
            "Epoch: [1/2] | Iterations: [1025/1995] | Training loss: 0.139\n",
            "Epoch: [1/2] | Iterations: [1026/1995] | Training loss: 0.101\n",
            "Epoch: [1/2] | Iterations: [1027/1995] | Training loss: 0.127\n",
            "Epoch: [1/2] | Iterations: [1028/1995] | Training loss: 0.118\n",
            "Epoch: [1/2] | Iterations: [1029/1995] | Training loss: 0.198\n",
            "Epoch: [1/2] | Iterations: [1030/1995] | Training loss: 0.109\n",
            "Epoch: [1/2] | Iterations: [1031/1995] | Training loss: 0.108\n",
            "Epoch: [1/2] | Iterations: [1032/1995] | Training loss: 0.089\n",
            "Epoch: [1/2] | Iterations: [1033/1995] | Training loss: 0.158\n",
            "Epoch: [1/2] | Iterations: [1034/1995] | Training loss: 0.090\n",
            "Epoch: [1/2] | Iterations: [1035/1995] | Training loss: 0.118\n",
            "Epoch: [1/2] | Iterations: [1036/1995] | Training loss: 0.101\n",
            "Epoch: [1/2] | Iterations: [1037/1995] | Training loss: 0.186\n",
            "Epoch: [1/2] | Iterations: [1038/1995] | Training loss: 0.105\n",
            "Epoch: [1/2] | Iterations: [1039/1995] | Training loss: 0.167\n",
            "Epoch: [1/2] | Iterations: [1040/1995] | Training loss: 0.165\n",
            "Epoch: [1/2] | Iterations: [1041/1995] | Training loss: 0.120\n",
            "Epoch: [1/2] | Iterations: [1042/1995] | Training loss: 0.179\n",
            "Epoch: [1/2] | Iterations: [1043/1995] | Training loss: 0.190\n",
            "Epoch: [1/2] | Iterations: [1044/1995] | Training loss: 0.085\n",
            "Epoch: [1/2] | Iterations: [1045/1995] | Training loss: 0.130\n",
            "Epoch: [1/2] | Iterations: [1046/1995] | Training loss: 0.192\n",
            "Epoch: [1/2] | Iterations: [1047/1995] | Training loss: 0.109\n",
            "Epoch: [1/2] | Iterations: [1048/1995] | Training loss: 0.185\n",
            "Epoch: [1/2] | Iterations: [1049/1995] | Training loss: 0.188\n",
            "Epoch: [1/2] | Iterations: [1050/1995] | Training loss: 0.081\n",
            "Epoch: [1/2] | Iterations: [1051/1995] | Training loss: 0.133\n",
            "Epoch: [1/2] | Iterations: [1052/1995] | Training loss: 0.168\n",
            "Epoch: [1/2] | Iterations: [1053/1995] | Training loss: 0.178\n",
            "Epoch: [1/2] | Iterations: [1054/1995] | Training loss: 0.139\n",
            "Epoch: [1/2] | Iterations: [1055/1995] | Training loss: 0.239\n",
            "Epoch: [1/2] | Iterations: [1056/1995] | Training loss: 0.110\n",
            "Epoch: [1/2] | Iterations: [1057/1995] | Training loss: 0.136\n",
            "Epoch: [1/2] | Iterations: [1058/1995] | Training loss: 0.133\n",
            "Epoch: [1/2] | Iterations: [1059/1995] | Training loss: 0.115\n",
            "Epoch: [1/2] | Iterations: [1060/1995] | Training loss: 0.189\n",
            "Epoch: [1/2] | Iterations: [1061/1995] | Training loss: 0.135\n",
            "Epoch: [1/2] | Iterations: [1062/1995] | Training loss: 0.097\n",
            "Epoch: [1/2] | Iterations: [1063/1995] | Training loss: 0.159\n",
            "Epoch: [1/2] | Iterations: [1064/1995] | Training loss: 0.191\n",
            "Epoch: [1/2] | Iterations: [1065/1995] | Training loss: 0.112\n",
            "Epoch: [1/2] | Iterations: [1066/1995] | Training loss: 0.102\n",
            "Epoch: [1/2] | Iterations: [1067/1995] | Training loss: 0.102\n",
            "Epoch: [1/2] | Iterations: [1068/1995] | Training loss: 0.077\n",
            "Epoch: [1/2] | Iterations: [1069/1995] | Training loss: 0.151\n",
            "Epoch: [1/2] | Iterations: [1070/1995] | Training loss: 0.094\n",
            "Epoch: [1/2] | Iterations: [1071/1995] | Training loss: 0.119\n",
            "Epoch: [1/2] | Iterations: [1072/1995] | Training loss: 0.223\n",
            "Epoch: [1/2] | Iterations: [1073/1995] | Training loss: 0.135\n",
            "Epoch: [1/2] | Iterations: [1074/1995] | Training loss: 0.103\n",
            "Epoch: [1/2] | Iterations: [1075/1995] | Training loss: 0.087\n",
            "Epoch: [1/2] | Iterations: [1076/1995] | Training loss: 0.173\n",
            "Epoch: [1/2] | Iterations: [1077/1995] | Training loss: 0.195\n",
            "Epoch: [1/2] | Iterations: [1078/1995] | Training loss: 0.153\n",
            "Epoch: [1/2] | Iterations: [1079/1995] | Training loss: 0.171\n",
            "Epoch: [1/2] | Iterations: [1080/1995] | Training loss: 0.123\n",
            "Epoch: [1/2] | Iterations: [1081/1995] | Training loss: 0.114\n",
            "Epoch: [1/2] | Iterations: [1082/1995] | Training loss: 0.144\n",
            "Epoch: [1/2] | Iterations: [1083/1995] | Training loss: 0.117\n",
            "Epoch: [1/2] | Iterations: [1084/1995] | Training loss: 0.135\n",
            "Epoch: [1/2] | Iterations: [1085/1995] | Training loss: 0.112\n",
            "Epoch: [1/2] | Iterations: [1086/1995] | Training loss: 0.047\n",
            "Epoch: [1/2] | Iterations: [1087/1995] | Training loss: 0.089\n",
            "Epoch: [1/2] | Iterations: [1088/1995] | Training loss: 0.084\n",
            "Epoch: [1/2] | Iterations: [1089/1995] | Training loss: 0.079\n",
            "Epoch: [1/2] | Iterations: [1090/1995] | Training loss: 0.099\n",
            "Epoch: [1/2] | Iterations: [1091/1995] | Training loss: 0.118\n",
            "Epoch: [1/2] | Iterations: [1092/1995] | Training loss: 0.123\n",
            "Epoch: [1/2] | Iterations: [1093/1995] | Training loss: 0.203\n",
            "Epoch: [1/2] | Iterations: [1094/1995] | Training loss: 0.106\n",
            "Epoch: [1/2] | Iterations: [1095/1995] | Training loss: 0.108\n",
            "Epoch: [1/2] | Iterations: [1096/1995] | Training loss: 0.114\n",
            "Epoch: [1/2] | Iterations: [1097/1995] | Training loss: 0.112\n",
            "Epoch: [1/2] | Iterations: [1098/1995] | Training loss: 0.138\n",
            "Epoch: [1/2] | Iterations: [1099/1995] | Training loss: 0.102\n",
            "Epoch: [1/2] | Iterations: [1100/1995] | Training loss: 0.066\n",
            "Epoch: [1/2] | Iterations: [1101/1995] | Training loss: 0.190\n",
            "Epoch: [1/2] | Iterations: [1102/1995] | Training loss: 0.164\n",
            "Epoch: [1/2] | Iterations: [1103/1995] | Training loss: 0.080\n",
            "Epoch: [1/2] | Iterations: [1104/1995] | Training loss: 0.099\n",
            "Epoch: [1/2] | Iterations: [1105/1995] | Training loss: 0.137\n",
            "Epoch: [1/2] | Iterations: [1106/1995] | Training loss: 0.122\n",
            "Epoch: [1/2] | Iterations: [1107/1995] | Training loss: 0.124\n",
            "Epoch: [1/2] | Iterations: [1108/1995] | Training loss: 0.146\n",
            "Epoch: [1/2] | Iterations: [1109/1995] | Training loss: 0.061\n",
            "Epoch: [1/2] | Iterations: [1110/1995] | Training loss: 0.148\n",
            "Epoch: [1/2] | Iterations: [1111/1995] | Training loss: 0.226\n",
            "Epoch: [1/2] | Iterations: [1112/1995] | Training loss: 0.085\n",
            "Epoch: [1/2] | Iterations: [1113/1995] | Training loss: 0.151\n",
            "Epoch: [1/2] | Iterations: [1114/1995] | Training loss: 0.124\n",
            "Epoch: [1/2] | Iterations: [1115/1995] | Training loss: 0.049\n",
            "Epoch: [1/2] | Iterations: [1116/1995] | Training loss: 0.133\n",
            "Epoch: [1/2] | Iterations: [1117/1995] | Training loss: 0.137\n",
            "Epoch: [1/2] | Iterations: [1118/1995] | Training loss: 0.097\n",
            "Epoch: [1/2] | Iterations: [1119/1995] | Training loss: 0.251\n",
            "Epoch: [1/2] | Iterations: [1120/1995] | Training loss: 0.149\n",
            "Epoch: [1/2] | Iterations: [1121/1995] | Training loss: 0.165\n",
            "Epoch: [1/2] | Iterations: [1122/1995] | Training loss: 0.119\n",
            "Epoch: [1/2] | Iterations: [1123/1995] | Training loss: 0.080\n",
            "Epoch: [1/2] | Iterations: [1124/1995] | Training loss: 0.131\n",
            "Epoch: [1/2] | Iterations: [1125/1995] | Training loss: 0.087\n",
            "Epoch: [1/2] | Iterations: [1126/1995] | Training loss: 0.150\n",
            "Epoch: [1/2] | Iterations: [1127/1995] | Training loss: 0.085\n",
            "Epoch: [1/2] | Iterations: [1128/1995] | Training loss: 0.184\n",
            "Epoch: [1/2] | Iterations: [1129/1995] | Training loss: 0.127\n",
            "Epoch: [1/2] | Iterations: [1130/1995] | Training loss: 0.186\n",
            "Epoch: [1/2] | Iterations: [1131/1995] | Training loss: 0.083\n",
            "Epoch: [1/2] | Iterations: [1132/1995] | Training loss: 0.122\n",
            "Epoch: [1/2] | Iterations: [1133/1995] | Training loss: 0.058\n",
            "Epoch: [1/2] | Iterations: [1134/1995] | Training loss: 0.118\n",
            "Epoch: [1/2] | Iterations: [1135/1995] | Training loss: 0.151\n",
            "Epoch: [1/2] | Iterations: [1136/1995] | Training loss: 0.099\n",
            "Epoch: [1/2] | Iterations: [1137/1995] | Training loss: 0.091\n",
            "Epoch: [1/2] | Iterations: [1138/1995] | Training loss: 0.126\n",
            "Epoch: [1/2] | Iterations: [1139/1995] | Training loss: 0.093\n",
            "Epoch: [1/2] | Iterations: [1140/1995] | Training loss: 0.119\n",
            "Epoch: [1/2] | Iterations: [1141/1995] | Training loss: 0.154\n",
            "Epoch: [1/2] | Iterations: [1142/1995] | Training loss: 0.107\n",
            "Epoch: [1/2] | Iterations: [1143/1995] | Training loss: 0.101\n",
            "Epoch: [1/2] | Iterations: [1144/1995] | Training loss: 0.113\n",
            "Epoch: [1/2] | Iterations: [1145/1995] | Training loss: 0.102\n",
            "Epoch: [1/2] | Iterations: [1146/1995] | Training loss: 0.168\n",
            "Epoch: [1/2] | Iterations: [1147/1995] | Training loss: 0.123\n",
            "Epoch: [1/2] | Iterations: [1148/1995] | Training loss: 0.202\n",
            "Epoch: [1/2] | Iterations: [1149/1995] | Training loss: 0.100\n",
            "Epoch: [1/2] | Iterations: [1150/1995] | Training loss: 0.091\n",
            "Epoch: [1/2] | Iterations: [1151/1995] | Training loss: 0.108\n",
            "Epoch: [1/2] | Iterations: [1152/1995] | Training loss: 0.108\n",
            "Epoch: [1/2] | Iterations: [1153/1995] | Training loss: 0.095\n",
            "Epoch: [1/2] | Iterations: [1154/1995] | Training loss: 0.121\n",
            "Epoch: [1/2] | Iterations: [1155/1995] | Training loss: 0.128\n",
            "Epoch: [1/2] | Iterations: [1156/1995] | Training loss: 0.170\n",
            "Epoch: [1/2] | Iterations: [1157/1995] | Training loss: 0.156\n",
            "Epoch: [1/2] | Iterations: [1158/1995] | Training loss: 0.128\n",
            "Epoch: [1/2] | Iterations: [1159/1995] | Training loss: 0.182\n",
            "Epoch: [1/2] | Iterations: [1160/1995] | Training loss: 0.159\n",
            "Epoch: [1/2] | Iterations: [1161/1995] | Training loss: 0.222\n",
            "Epoch: [1/2] | Iterations: [1162/1995] | Training loss: 0.171\n",
            "Epoch: [1/2] | Iterations: [1163/1995] | Training loss: 0.138\n",
            "Epoch: [1/2] | Iterations: [1164/1995] | Training loss: 0.156\n",
            "Epoch: [1/2] | Iterations: [1165/1995] | Training loss: 0.114\n",
            "Epoch: [1/2] | Iterations: [1166/1995] | Training loss: 0.229\n",
            "Epoch: [1/2] | Iterations: [1167/1995] | Training loss: 0.119\n",
            "Epoch: [1/2] | Iterations: [1168/1995] | Training loss: 0.140\n",
            "Epoch: [1/2] | Iterations: [1169/1995] | Training loss: 0.142\n",
            "Epoch: [1/2] | Iterations: [1170/1995] | Training loss: 0.118\n",
            "Epoch: [1/2] | Iterations: [1171/1995] | Training loss: 0.132\n",
            "Epoch: [1/2] | Iterations: [1172/1995] | Training loss: 0.103\n",
            "Epoch: [1/2] | Iterations: [1173/1995] | Training loss: 0.175\n",
            "Epoch: [1/2] | Iterations: [1174/1995] | Training loss: 0.113\n",
            "Epoch: [1/2] | Iterations: [1175/1995] | Training loss: 0.124\n",
            "Epoch: [1/2] | Iterations: [1176/1995] | Training loss: 0.170\n",
            "Epoch: [1/2] | Iterations: [1177/1995] | Training loss: 0.110\n",
            "Epoch: [1/2] | Iterations: [1178/1995] | Training loss: 0.135\n",
            "Epoch: [1/2] | Iterations: [1179/1995] | Training loss: 0.097\n",
            "Epoch: [1/2] | Iterations: [1180/1995] | Training loss: 0.106\n",
            "Epoch: [1/2] | Iterations: [1181/1995] | Training loss: 0.150\n",
            "Epoch: [1/2] | Iterations: [1182/1995] | Training loss: 0.241\n",
            "Epoch: [1/2] | Iterations: [1183/1995] | Training loss: 0.124\n",
            "Epoch: [1/2] | Iterations: [1184/1995] | Training loss: 0.125\n",
            "Epoch: [1/2] | Iterations: [1185/1995] | Training loss: 0.142\n",
            "Epoch: [1/2] | Iterations: [1186/1995] | Training loss: 0.133\n",
            "Epoch: [1/2] | Iterations: [1187/1995] | Training loss: 0.110\n",
            "Epoch: [1/2] | Iterations: [1188/1995] | Training loss: 0.128\n",
            "Epoch: [1/2] | Iterations: [1189/1995] | Training loss: 0.053\n",
            "Epoch: [1/2] | Iterations: [1190/1995] | Training loss: 0.091\n",
            "Epoch: [1/2] | Iterations: [1191/1995] | Training loss: 0.102\n",
            "Epoch: [1/2] | Iterations: [1192/1995] | Training loss: 0.111\n",
            "Epoch: [1/2] | Iterations: [1193/1995] | Training loss: 0.159\n",
            "Epoch: [1/2] | Iterations: [1194/1995] | Training loss: 0.201\n",
            "Epoch: [1/2] | Iterations: [1195/1995] | Training loss: 0.088\n",
            "Epoch: [1/2] | Iterations: [1196/1995] | Training loss: 0.145\n",
            "Epoch: [1/2] | Iterations: [1197/1995] | Training loss: 0.096\n",
            "Epoch: [1/2] | Iterations: [1198/1995] | Training loss: 0.132\n",
            "Epoch: [1/2] | Iterations: [1199/1995] | Training loss: 0.115\n",
            "Epoch: [1/2] | Iterations: [1200/1995] | Training loss: 0.180\n",
            "Epoch: [1/2] | Iterations: [1201/1995] | Training loss: 0.133\n",
            "Epoch: [1/2] | Iterations: [1202/1995] | Training loss: 0.173\n",
            "Epoch: [1/2] | Iterations: [1203/1995] | Training loss: 0.241\n",
            "Epoch: [1/2] | Iterations: [1204/1995] | Training loss: 0.206\n",
            "Epoch: [1/2] | Iterations: [1205/1995] | Training loss: 0.125\n",
            "Epoch: [1/2] | Iterations: [1206/1995] | Training loss: 0.147\n",
            "Epoch: [1/2] | Iterations: [1207/1995] | Training loss: 0.143\n",
            "Epoch: [1/2] | Iterations: [1208/1995] | Training loss: 0.243\n",
            "Epoch: [1/2] | Iterations: [1209/1995] | Training loss: 0.159\n",
            "Epoch: [1/2] | Iterations: [1210/1995] | Training loss: 0.086\n",
            "Epoch: [1/2] | Iterations: [1211/1995] | Training loss: 0.096\n",
            "Epoch: [1/2] | Iterations: [1212/1995] | Training loss: 0.235\n",
            "Epoch: [1/2] | Iterations: [1213/1995] | Training loss: 0.135\n",
            "Epoch: [1/2] | Iterations: [1214/1995] | Training loss: 0.115\n",
            "Epoch: [1/2] | Iterations: [1215/1995] | Training loss: 0.120\n",
            "Epoch: [1/2] | Iterations: [1216/1995] | Training loss: 0.110\n",
            "Epoch: [1/2] | Iterations: [1217/1995] | Training loss: 0.082\n",
            "Epoch: [1/2] | Iterations: [1218/1995] | Training loss: 0.117\n",
            "Epoch: [1/2] | Iterations: [1219/1995] | Training loss: 0.094\n",
            "Epoch: [1/2] | Iterations: [1220/1995] | Training loss: 0.150\n",
            "Epoch: [1/2] | Iterations: [1221/1995] | Training loss: 0.103\n",
            "Epoch: [1/2] | Iterations: [1222/1995] | Training loss: 0.110\n",
            "Epoch: [1/2] | Iterations: [1223/1995] | Training loss: 0.117\n",
            "Epoch: [1/2] | Iterations: [1224/1995] | Training loss: 0.156\n",
            "Epoch: [1/2] | Iterations: [1225/1995] | Training loss: 0.155\n",
            "Epoch: [1/2] | Iterations: [1226/1995] | Training loss: 0.108\n",
            "Epoch: [1/2] | Iterations: [1227/1995] | Training loss: 0.148\n",
            "Epoch: [1/2] | Iterations: [1228/1995] | Training loss: 0.085\n",
            "Epoch: [1/2] | Iterations: [1229/1995] | Training loss: 0.129\n",
            "Epoch: [1/2] | Iterations: [1230/1995] | Training loss: 0.068\n",
            "Epoch: [1/2] | Iterations: [1231/1995] | Training loss: 0.061\n",
            "Epoch: [1/2] | Iterations: [1232/1995] | Training loss: 0.114\n",
            "Epoch: [1/2] | Iterations: [1233/1995] | Training loss: 0.058\n",
            "Epoch: [1/2] | Iterations: [1234/1995] | Training loss: 0.159\n",
            "Epoch: [1/2] | Iterations: [1235/1995] | Training loss: 0.074\n",
            "Epoch: [1/2] | Iterations: [1236/1995] | Training loss: 0.139\n",
            "Epoch: [1/2] | Iterations: [1237/1995] | Training loss: 0.103\n",
            "Epoch: [1/2] | Iterations: [1238/1995] | Training loss: 0.178\n",
            "Epoch: [1/2] | Iterations: [1239/1995] | Training loss: 0.161\n",
            "Epoch: [1/2] | Iterations: [1240/1995] | Training loss: 0.112\n",
            "Epoch: [1/2] | Iterations: [1241/1995] | Training loss: 0.102\n",
            "Epoch: [1/2] | Iterations: [1242/1995] | Training loss: 0.092\n",
            "Epoch: [1/2] | Iterations: [1243/1995] | Training loss: 0.070\n",
            "Epoch: [1/2] | Iterations: [1244/1995] | Training loss: 0.110\n",
            "Epoch: [1/2] | Iterations: [1245/1995] | Training loss: 0.115\n",
            "Epoch: [1/2] | Iterations: [1246/1995] | Training loss: 0.104\n",
            "Epoch: [1/2] | Iterations: [1247/1995] | Training loss: 0.118\n",
            "Epoch: [1/2] | Iterations: [1248/1995] | Training loss: 0.213\n",
            "Epoch: [1/2] | Iterations: [1249/1995] | Training loss: 0.140\n",
            "Epoch: [1/2] | Iterations: [1250/1995] | Training loss: 0.127\n",
            "Epoch: [1/2] | Iterations: [1251/1995] | Training loss: 0.065\n",
            "Epoch: [1/2] | Iterations: [1252/1995] | Training loss: 0.188\n",
            "Epoch: [1/2] | Iterations: [1253/1995] | Training loss: 0.047\n",
            "Epoch: [1/2] | Iterations: [1254/1995] | Training loss: 0.106\n",
            "Epoch: [1/2] | Iterations: [1255/1995] | Training loss: 0.116\n",
            "Epoch: [1/2] | Iterations: [1256/1995] | Training loss: 0.112\n",
            "Epoch: [1/2] | Iterations: [1257/1995] | Training loss: 0.140\n",
            "Epoch: [1/2] | Iterations: [1258/1995] | Training loss: 0.178\n",
            "Epoch: [1/2] | Iterations: [1259/1995] | Training loss: 0.143\n",
            "Epoch: [1/2] | Iterations: [1260/1995] | Training loss: 0.069\n",
            "Epoch: [1/2] | Iterations: [1261/1995] | Training loss: 0.097\n",
            "Epoch: [1/2] | Iterations: [1262/1995] | Training loss: 0.108\n",
            "Epoch: [1/2] | Iterations: [1263/1995] | Training loss: 0.177\n",
            "Epoch: [1/2] | Iterations: [1264/1995] | Training loss: 0.131\n",
            "Epoch: [1/2] | Iterations: [1265/1995] | Training loss: 0.075\n",
            "Epoch: [1/2] | Iterations: [1266/1995] | Training loss: 0.067\n",
            "Epoch: [1/2] | Iterations: [1267/1995] | Training loss: 0.129\n",
            "Epoch: [1/2] | Iterations: [1268/1995] | Training loss: 0.143\n",
            "Epoch: [1/2] | Iterations: [1269/1995] | Training loss: 0.123\n",
            "Epoch: [1/2] | Iterations: [1270/1995] | Training loss: 0.111\n",
            "Epoch: [1/2] | Iterations: [1271/1995] | Training loss: 0.141\n",
            "Epoch: [1/2] | Iterations: [1272/1995] | Training loss: 0.130\n",
            "Epoch: [1/2] | Iterations: [1273/1995] | Training loss: 0.146\n",
            "Epoch: [1/2] | Iterations: [1274/1995] | Training loss: 0.189\n",
            "Epoch: [1/2] | Iterations: [1275/1995] | Training loss: 0.088\n",
            "Epoch: [1/2] | Iterations: [1276/1995] | Training loss: 0.107\n",
            "Epoch: [1/2] | Iterations: [1277/1995] | Training loss: 0.124\n",
            "Epoch: [1/2] | Iterations: [1278/1995] | Training loss: 0.108\n",
            "Epoch: [1/2] | Iterations: [1279/1995] | Training loss: 0.150\n",
            "Epoch: [1/2] | Iterations: [1280/1995] | Training loss: 0.172\n",
            "Epoch: [1/2] | Iterations: [1281/1995] | Training loss: 0.086\n",
            "Epoch: [1/2] | Iterations: [1282/1995] | Training loss: 0.143\n",
            "Epoch: [1/2] | Iterations: [1283/1995] | Training loss: 0.112\n",
            "Epoch: [1/2] | Iterations: [1284/1995] | Training loss: 0.082\n",
            "Epoch: [1/2] | Iterations: [1285/1995] | Training loss: 0.114\n",
            "Epoch: [1/2] | Iterations: [1286/1995] | Training loss: 0.073\n",
            "Epoch: [1/2] | Iterations: [1287/1995] | Training loss: 0.133\n",
            "Epoch: [1/2] | Iterations: [1288/1995] | Training loss: 0.170\n",
            "Epoch: [1/2] | Iterations: [1289/1995] | Training loss: 0.184\n",
            "Epoch: [1/2] | Iterations: [1290/1995] | Training loss: 0.163\n",
            "Epoch: [1/2] | Iterations: [1291/1995] | Training loss: 0.181\n",
            "Epoch: [1/2] | Iterations: [1292/1995] | Training loss: 0.107\n",
            "Epoch: [1/2] | Iterations: [1293/1995] | Training loss: 0.151\n",
            "Epoch: [1/2] | Iterations: [1294/1995] | Training loss: 0.183\n",
            "Epoch: [1/2] | Iterations: [1295/1995] | Training loss: 0.115\n",
            "Epoch: [1/2] | Iterations: [1296/1995] | Training loss: 0.039\n",
            "Epoch: [1/2] | Iterations: [1297/1995] | Training loss: 0.088\n",
            "Epoch: [1/2] | Iterations: [1298/1995] | Training loss: 0.116\n",
            "Epoch: [1/2] | Iterations: [1299/1995] | Training loss: 0.105\n",
            "Epoch: [1/2] | Iterations: [1300/1995] | Training loss: 0.074\n",
            "Epoch: [1/2] | Iterations: [1301/1995] | Training loss: 0.094\n",
            "Epoch: [1/2] | Iterations: [1302/1995] | Training loss: 0.084\n",
            "Epoch: [1/2] | Iterations: [1303/1995] | Training loss: 0.113\n",
            "Epoch: [1/2] | Iterations: [1304/1995] | Training loss: 0.130\n",
            "Epoch: [1/2] | Iterations: [1305/1995] | Training loss: 0.138\n",
            "Epoch: [1/2] | Iterations: [1306/1995] | Training loss: 0.093\n",
            "Epoch: [1/2] | Iterations: [1307/1995] | Training loss: 0.149\n",
            "Epoch: [1/2] | Iterations: [1308/1995] | Training loss: 0.214\n",
            "Epoch: [1/2] | Iterations: [1309/1995] | Training loss: 0.133\n",
            "Epoch: [1/2] | Iterations: [1310/1995] | Training loss: 0.152\n",
            "Epoch: [1/2] | Iterations: [1311/1995] | Training loss: 0.123\n",
            "Epoch: [1/2] | Iterations: [1312/1995] | Training loss: 0.081\n",
            "Epoch: [1/2] | Iterations: [1313/1995] | Training loss: 0.163\n",
            "Epoch: [1/2] | Iterations: [1314/1995] | Training loss: 0.114\n",
            "Epoch: [1/2] | Iterations: [1315/1995] | Training loss: 0.254\n",
            "Epoch: [1/2] | Iterations: [1316/1995] | Training loss: 0.156\n",
            "Epoch: [1/2] | Iterations: [1317/1995] | Training loss: 0.103\n",
            "Epoch: [1/2] | Iterations: [1318/1995] | Training loss: 0.180\n",
            "Epoch: [1/2] | Iterations: [1319/1995] | Training loss: 0.081\n",
            "Epoch: [1/2] | Iterations: [1320/1995] | Training loss: 0.136\n",
            "Epoch: [1/2] | Iterations: [1321/1995] | Training loss: 0.129\n",
            "Epoch: [1/2] | Iterations: [1322/1995] | Training loss: 0.117\n",
            "Epoch: [1/2] | Iterations: [1323/1995] | Training loss: 0.107\n",
            "Epoch: [1/2] | Iterations: [1324/1995] | Training loss: 0.118\n",
            "Epoch: [1/2] | Iterations: [1325/1995] | Training loss: 0.057\n",
            "Epoch: [1/2] | Iterations: [1326/1995] | Training loss: 0.059\n",
            "Epoch: [1/2] | Iterations: [1327/1995] | Training loss: 0.137\n",
            "Epoch: [1/2] | Iterations: [1328/1995] | Training loss: 0.134\n",
            "Epoch: [1/2] | Iterations: [1329/1995] | Training loss: 0.071\n",
            "Epoch: [1/2] | Iterations: [1330/1995] | Training loss: 0.068\n",
            "Epoch: [1/2] | Iterations: [1331/1995] | Training loss: 0.123\n",
            "Epoch: [1/2] | Iterations: [1332/1995] | Training loss: 0.114\n",
            "Epoch: [1/2] | Iterations: [1333/1995] | Training loss: 0.139\n",
            "Epoch: [1/2] | Iterations: [1334/1995] | Training loss: 0.143\n",
            "Epoch: [1/2] | Iterations: [1335/1995] | Training loss: 0.246\n",
            "Epoch: [1/2] | Iterations: [1336/1995] | Training loss: 0.093\n",
            "Epoch: [1/2] | Iterations: [1337/1995] | Training loss: 0.150\n",
            "Epoch: [1/2] | Iterations: [1338/1995] | Training loss: 0.048\n",
            "Epoch: [1/2] | Iterations: [1339/1995] | Training loss: 0.138\n",
            "Epoch: [1/2] | Iterations: [1340/1995] | Training loss: 0.135\n",
            "Epoch: [1/2] | Iterations: [1341/1995] | Training loss: 0.138\n",
            "Epoch: [1/2] | Iterations: [1342/1995] | Training loss: 0.170\n",
            "Epoch: [1/2] | Iterations: [1343/1995] | Training loss: 0.135\n",
            "Epoch: [1/2] | Iterations: [1344/1995] | Training loss: 0.152\n",
            "Epoch: [1/2] | Iterations: [1345/1995] | Training loss: 0.118\n",
            "Epoch: [1/2] | Iterations: [1346/1995] | Training loss: 0.135\n",
            "Epoch: [1/2] | Iterations: [1347/1995] | Training loss: 0.090\n",
            "Epoch: [1/2] | Iterations: [1348/1995] | Training loss: 0.079\n",
            "Epoch: [1/2] | Iterations: [1349/1995] | Training loss: 0.113\n",
            "Epoch: [1/2] | Iterations: [1350/1995] | Training loss: 0.105\n",
            "Epoch: [1/2] | Iterations: [1351/1995] | Training loss: 0.126\n",
            "Epoch: [1/2] | Iterations: [1352/1995] | Training loss: 0.095\n",
            "Epoch: [1/2] | Iterations: [1353/1995] | Training loss: 0.102\n",
            "Epoch: [1/2] | Iterations: [1354/1995] | Training loss: 0.064\n",
            "Epoch: [1/2] | Iterations: [1355/1995] | Training loss: 0.084\n",
            "Epoch: [1/2] | Iterations: [1356/1995] | Training loss: 0.107\n",
            "Epoch: [1/2] | Iterations: [1357/1995] | Training loss: 0.093\n",
            "Epoch: [1/2] | Iterations: [1358/1995] | Training loss: 0.099\n",
            "Epoch: [1/2] | Iterations: [1359/1995] | Training loss: 0.109\n",
            "Epoch: [1/2] | Iterations: [1360/1995] | Training loss: 0.045\n",
            "Epoch: [1/2] | Iterations: [1361/1995] | Training loss: 0.173\n",
            "Epoch: [1/2] | Iterations: [1362/1995] | Training loss: 0.160\n",
            "Epoch: [1/2] | Iterations: [1363/1995] | Training loss: 0.160\n",
            "Epoch: [1/2] | Iterations: [1364/1995] | Training loss: 0.189\n",
            "Epoch: [1/2] | Iterations: [1365/1995] | Training loss: 0.085\n",
            "Epoch: [1/2] | Iterations: [1366/1995] | Training loss: 0.138\n",
            "Epoch: [1/2] | Iterations: [1367/1995] | Training loss: 0.121\n",
            "Epoch: [1/2] | Iterations: [1368/1995] | Training loss: 0.199\n",
            "Epoch: [1/2] | Iterations: [1369/1995] | Training loss: 0.101\n",
            "Epoch: [1/2] | Iterations: [1370/1995] | Training loss: 0.118\n",
            "Epoch: [1/2] | Iterations: [1371/1995] | Training loss: 0.093\n",
            "Epoch: [1/2] | Iterations: [1372/1995] | Training loss: 0.116\n",
            "Epoch: [1/2] | Iterations: [1373/1995] | Training loss: 0.068\n",
            "Epoch: [1/2] | Iterations: [1374/1995] | Training loss: 0.111\n",
            "Epoch: [1/2] | Iterations: [1375/1995] | Training loss: 0.228\n",
            "Epoch: [1/2] | Iterations: [1376/1995] | Training loss: 0.052\n",
            "Epoch: [1/2] | Iterations: [1377/1995] | Training loss: 0.105\n",
            "Epoch: [1/2] | Iterations: [1378/1995] | Training loss: 0.184\n",
            "Epoch: [1/2] | Iterations: [1379/1995] | Training loss: 0.194\n",
            "Epoch: [1/2] | Iterations: [1380/1995] | Training loss: 0.214\n",
            "Epoch: [1/2] | Iterations: [1381/1995] | Training loss: 0.110\n",
            "Epoch: [1/2] | Iterations: [1382/1995] | Training loss: 0.147\n",
            "Epoch: [1/2] | Iterations: [1383/1995] | Training loss: 0.117\n",
            "Epoch: [1/2] | Iterations: [1384/1995] | Training loss: 0.144\n",
            "Epoch: [1/2] | Iterations: [1385/1995] | Training loss: 0.116\n",
            "Epoch: [1/2] | Iterations: [1386/1995] | Training loss: 0.105\n",
            "Epoch: [1/2] | Iterations: [1387/1995] | Training loss: 0.139\n",
            "Epoch: [1/2] | Iterations: [1388/1995] | Training loss: 0.126\n",
            "Epoch: [1/2] | Iterations: [1389/1995] | Training loss: 0.076\n",
            "Epoch: [1/2] | Iterations: [1390/1995] | Training loss: 0.117\n",
            "Epoch: [1/2] | Iterations: [1391/1995] | Training loss: 0.060\n",
            "Epoch: [1/2] | Iterations: [1392/1995] | Training loss: 0.122\n",
            "Epoch: [1/2] | Iterations: [1393/1995] | Training loss: 0.146\n",
            "Epoch: [1/2] | Iterations: [1394/1995] | Training loss: 0.058\n",
            "Epoch: [1/2] | Iterations: [1395/1995] | Training loss: 0.152\n",
            "Epoch: [1/2] | Iterations: [1396/1995] | Training loss: 0.070\n",
            "Epoch: [1/2] | Iterations: [1397/1995] | Training loss: 0.080\n",
            "Epoch: [1/2] | Iterations: [1398/1995] | Training loss: 0.175\n",
            "Epoch: [1/2] | Iterations: [1399/1995] | Training loss: 0.117\n",
            "Epoch: [1/2] | Iterations: [1400/1995] | Training loss: 0.066\n",
            "Epoch: [1/2] | Iterations: [1401/1995] | Training loss: 0.100\n",
            "Epoch: [1/2] | Iterations: [1402/1995] | Training loss: 0.081\n",
            "Epoch: [1/2] | Iterations: [1403/1995] | Training loss: 0.104\n",
            "Epoch: [1/2] | Iterations: [1404/1995] | Training loss: 0.108\n",
            "Epoch: [1/2] | Iterations: [1405/1995] | Training loss: 0.113\n",
            "Epoch: [1/2] | Iterations: [1406/1995] | Training loss: 0.080\n",
            "Epoch: [1/2] | Iterations: [1407/1995] | Training loss: 0.105\n",
            "Epoch: [1/2] | Iterations: [1408/1995] | Training loss: 0.084\n",
            "Epoch: [1/2] | Iterations: [1409/1995] | Training loss: 0.095\n",
            "Epoch: [1/2] | Iterations: [1410/1995] | Training loss: 0.084\n",
            "Epoch: [1/2] | Iterations: [1411/1995] | Training loss: 0.081\n",
            "Epoch: [1/2] | Iterations: [1412/1995] | Training loss: 0.242\n",
            "Epoch: [1/2] | Iterations: [1413/1995] | Training loss: 0.188\n",
            "Epoch: [1/2] | Iterations: [1414/1995] | Training loss: 0.189\n",
            "Epoch: [1/2] | Iterations: [1415/1995] | Training loss: 0.093\n",
            "Epoch: [1/2] | Iterations: [1416/1995] | Training loss: 0.108\n",
            "Epoch: [1/2] | Iterations: [1417/1995] | Training loss: 0.130\n",
            "Epoch: [1/2] | Iterations: [1418/1995] | Training loss: 0.136\n",
            "Epoch: [1/2] | Iterations: [1419/1995] | Training loss: 0.071\n",
            "Epoch: [1/2] | Iterations: [1420/1995] | Training loss: 0.087\n",
            "Epoch: [1/2] | Iterations: [1421/1995] | Training loss: 0.131\n",
            "Epoch: [1/2] | Iterations: [1422/1995] | Training loss: 0.115\n",
            "Epoch: [1/2] | Iterations: [1423/1995] | Training loss: 0.138\n",
            "Epoch: [1/2] | Iterations: [1424/1995] | Training loss: 0.156\n",
            "Epoch: [1/2] | Iterations: [1425/1995] | Training loss: 0.144\n",
            "Epoch: [1/2] | Iterations: [1426/1995] | Training loss: 0.148\n",
            "Epoch: [1/2] | Iterations: [1427/1995] | Training loss: 0.091\n",
            "Epoch: [1/2] | Iterations: [1428/1995] | Training loss: 0.158\n",
            "Epoch: [1/2] | Iterations: [1429/1995] | Training loss: 0.091\n",
            "Epoch: [1/2] | Iterations: [1430/1995] | Training loss: 0.134\n",
            "Epoch: [1/2] | Iterations: [1431/1995] | Training loss: 0.055\n",
            "Epoch: [1/2] | Iterations: [1432/1995] | Training loss: 0.065\n",
            "Epoch: [1/2] | Iterations: [1433/1995] | Training loss: 0.097\n",
            "Epoch: [1/2] | Iterations: [1434/1995] | Training loss: 0.084\n",
            "Epoch: [1/2] | Iterations: [1435/1995] | Training loss: 0.163\n",
            "Epoch: [1/2] | Iterations: [1436/1995] | Training loss: 0.077\n",
            "Epoch: [1/2] | Iterations: [1437/1995] | Training loss: 0.064\n",
            "Epoch: [1/2] | Iterations: [1438/1995] | Training loss: 0.140\n",
            "Epoch: [1/2] | Iterations: [1439/1995] | Training loss: 0.112\n",
            "Epoch: [1/2] | Iterations: [1440/1995] | Training loss: 0.155\n",
            "Epoch: [1/2] | Iterations: [1441/1995] | Training loss: 0.121\n",
            "Epoch: [1/2] | Iterations: [1442/1995] | Training loss: 0.134\n",
            "Epoch: [1/2] | Iterations: [1443/1995] | Training loss: 0.058\n",
            "Epoch: [1/2] | Iterations: [1444/1995] | Training loss: 0.109\n",
            "Epoch: [1/2] | Iterations: [1445/1995] | Training loss: 0.115\n",
            "Epoch: [1/2] | Iterations: [1446/1995] | Training loss: 0.071\n",
            "Epoch: [1/2] | Iterations: [1447/1995] | Training loss: 0.145\n",
            "Epoch: [1/2] | Iterations: [1448/1995] | Training loss: 0.128\n",
            "Epoch: [1/2] | Iterations: [1449/1995] | Training loss: 0.108\n",
            "Epoch: [1/2] | Iterations: [1450/1995] | Training loss: 0.084\n",
            "Epoch: [1/2] | Iterations: [1451/1995] | Training loss: 0.101\n",
            "Epoch: [1/2] | Iterations: [1452/1995] | Training loss: 0.090\n",
            "Epoch: [1/2] | Iterations: [1453/1995] | Training loss: 0.135\n",
            "Epoch: [1/2] | Iterations: [1454/1995] | Training loss: 0.091\n",
            "Epoch: [1/2] | Iterations: [1455/1995] | Training loss: 0.171\n",
            "Epoch: [1/2] | Iterations: [1456/1995] | Training loss: 0.170\n",
            "Epoch: [1/2] | Iterations: [1457/1995] | Training loss: 0.120\n",
            "Epoch: [1/2] | Iterations: [1458/1995] | Training loss: 0.116\n",
            "Epoch: [1/2] | Iterations: [1459/1995] | Training loss: 0.086\n",
            "Epoch: [1/2] | Iterations: [1460/1995] | Training loss: 0.160\n",
            "Epoch: [1/2] | Iterations: [1461/1995] | Training loss: 0.150\n",
            "Epoch: [1/2] | Iterations: [1462/1995] | Training loss: 0.104\n",
            "Epoch: [1/2] | Iterations: [1463/1995] | Training loss: 0.147\n",
            "Epoch: [1/2] | Iterations: [1464/1995] | Training loss: 0.122\n",
            "Epoch: [1/2] | Iterations: [1465/1995] | Training loss: 0.092\n",
            "Epoch: [1/2] | Iterations: [1466/1995] | Training loss: 0.159\n",
            "Epoch: [1/2] | Iterations: [1467/1995] | Training loss: 0.145\n",
            "Epoch: [1/2] | Iterations: [1468/1995] | Training loss: 0.132\n",
            "Epoch: [1/2] | Iterations: [1469/1995] | Training loss: 0.100\n",
            "Epoch: [1/2] | Iterations: [1470/1995] | Training loss: 0.078\n",
            "Epoch: [1/2] | Iterations: [1471/1995] | Training loss: 0.094\n",
            "Epoch: [1/2] | Iterations: [1472/1995] | Training loss: 0.134\n",
            "Epoch: [1/2] | Iterations: [1473/1995] | Training loss: 0.086\n",
            "Epoch: [1/2] | Iterations: [1474/1995] | Training loss: 0.154\n",
            "Epoch: [1/2] | Iterations: [1475/1995] | Training loss: 0.169\n",
            "Epoch: [1/2] | Iterations: [1476/1995] | Training loss: 0.077\n",
            "Epoch: [1/2] | Iterations: [1477/1995] | Training loss: 0.114\n",
            "Epoch: [1/2] | Iterations: [1478/1995] | Training loss: 0.167\n",
            "Epoch: [1/2] | Iterations: [1479/1995] | Training loss: 0.171\n",
            "Epoch: [1/2] | Iterations: [1480/1995] | Training loss: 0.125\n",
            "Epoch: [1/2] | Iterations: [1481/1995] | Training loss: 0.148\n",
            "Epoch: [1/2] | Iterations: [1482/1995] | Training loss: 0.118\n",
            "Epoch: [1/2] | Iterations: [1483/1995] | Training loss: 0.116\n",
            "Epoch: [1/2] | Iterations: [1484/1995] | Training loss: 0.042\n",
            "Epoch: [1/2] | Iterations: [1485/1995] | Training loss: 0.206\n",
            "Epoch: [1/2] | Iterations: [1486/1995] | Training loss: 0.165\n",
            "Epoch: [1/2] | Iterations: [1487/1995] | Training loss: 0.076\n",
            "Epoch: [1/2] | Iterations: [1488/1995] | Training loss: 0.094\n",
            "Epoch: [1/2] | Iterations: [1489/1995] | Training loss: 0.121\n",
            "Epoch: [1/2] | Iterations: [1490/1995] | Training loss: 0.177\n",
            "Epoch: [1/2] | Iterations: [1491/1995] | Training loss: 0.123\n",
            "Epoch: [1/2] | Iterations: [1492/1995] | Training loss: 0.081\n",
            "Epoch: [1/2] | Iterations: [1493/1995] | Training loss: 0.123\n",
            "Epoch: [1/2] | Iterations: [1494/1995] | Training loss: 0.069\n",
            "Epoch: [1/2] | Iterations: [1495/1995] | Training loss: 0.207\n",
            "Epoch: [1/2] | Iterations: [1496/1995] | Training loss: 0.133\n",
            "Epoch: [1/2] | Iterations: [1497/1995] | Training loss: 0.042\n",
            "Epoch: [1/2] | Iterations: [1498/1995] | Training loss: 0.160\n",
            "Epoch: [1/2] | Iterations: [1499/1995] | Training loss: 0.139\n",
            "Epoch: [1/2] | Iterations: [1500/1995] | Training loss: 0.182\n",
            "Epoch: [1/2] | Iterations: [1501/1995] | Training loss: 0.119\n",
            "Epoch: [1/2] | Iterations: [1502/1995] | Training loss: 0.142\n",
            "Epoch: [1/2] | Iterations: [1503/1995] | Training loss: 0.131\n",
            "Epoch: [1/2] | Iterations: [1504/1995] | Training loss: 0.180\n",
            "Epoch: [1/2] | Iterations: [1505/1995] | Training loss: 0.180\n",
            "Epoch: [1/2] | Iterations: [1506/1995] | Training loss: 0.090\n",
            "Epoch: [1/2] | Iterations: [1507/1995] | Training loss: 0.114\n",
            "Epoch: [1/2] | Iterations: [1508/1995] | Training loss: 0.102\n",
            "Epoch: [1/2] | Iterations: [1509/1995] | Training loss: 0.104\n",
            "Epoch: [1/2] | Iterations: [1510/1995] | Training loss: 0.105\n",
            "Epoch: [1/2] | Iterations: [1511/1995] | Training loss: 0.141\n",
            "Epoch: [1/2] | Iterations: [1512/1995] | Training loss: 0.167\n",
            "Epoch: [1/2] | Iterations: [1513/1995] | Training loss: 0.131\n",
            "Epoch: [1/2] | Iterations: [1514/1995] | Training loss: 0.113\n",
            "Epoch: [1/2] | Iterations: [1515/1995] | Training loss: 0.065\n",
            "Epoch: [1/2] | Iterations: [1516/1995] | Training loss: 0.111\n",
            "Epoch: [1/2] | Iterations: [1517/1995] | Training loss: 0.089\n",
            "Epoch: [1/2] | Iterations: [1518/1995] | Training loss: 0.145\n",
            "Epoch: [1/2] | Iterations: [1519/1995] | Training loss: 0.144\n",
            "Epoch: [1/2] | Iterations: [1520/1995] | Training loss: 0.139\n",
            "Epoch: [1/2] | Iterations: [1521/1995] | Training loss: 0.175\n",
            "Epoch: [1/2] | Iterations: [1522/1995] | Training loss: 0.119\n",
            "Epoch: [1/2] | Iterations: [1523/1995] | Training loss: 0.104\n",
            "Epoch: [1/2] | Iterations: [1524/1995] | Training loss: 0.124\n",
            "Epoch: [1/2] | Iterations: [1525/1995] | Training loss: 0.152\n",
            "Epoch: [1/2] | Iterations: [1526/1995] | Training loss: 0.155\n",
            "Epoch: [1/2] | Iterations: [1527/1995] | Training loss: 0.124\n",
            "Epoch: [1/2] | Iterations: [1528/1995] | Training loss: 0.090\n",
            "Epoch: [1/2] | Iterations: [1529/1995] | Training loss: 0.119\n",
            "Epoch: [1/2] | Iterations: [1530/1995] | Training loss: 0.104\n",
            "Epoch: [1/2] | Iterations: [1531/1995] | Training loss: 0.078\n",
            "Epoch: [1/2] | Iterations: [1532/1995] | Training loss: 0.090\n",
            "Epoch: [1/2] | Iterations: [1533/1995] | Training loss: 0.125\n",
            "Epoch: [1/2] | Iterations: [1534/1995] | Training loss: 0.116\n",
            "Epoch: [1/2] | Iterations: [1535/1995] | Training loss: 0.115\n",
            "Epoch: [1/2] | Iterations: [1536/1995] | Training loss: 0.092\n",
            "Epoch: [1/2] | Iterations: [1537/1995] | Training loss: 0.093\n",
            "Epoch: [1/2] | Iterations: [1538/1995] | Training loss: 0.169\n",
            "Epoch: [1/2] | Iterations: [1539/1995] | Training loss: 0.088\n",
            "Epoch: [1/2] | Iterations: [1540/1995] | Training loss: 0.128\n",
            "Epoch: [1/2] | Iterations: [1541/1995] | Training loss: 0.113\n",
            "Epoch: [1/2] | Iterations: [1542/1995] | Training loss: 0.096\n",
            "Epoch: [1/2] | Iterations: [1543/1995] | Training loss: 0.152\n",
            "Epoch: [1/2] | Iterations: [1544/1995] | Training loss: 0.072\n",
            "Epoch: [1/2] | Iterations: [1545/1995] | Training loss: 0.080\n",
            "Epoch: [1/2] | Iterations: [1546/1995] | Training loss: 0.145\n",
            "Epoch: [1/2] | Iterations: [1547/1995] | Training loss: 0.186\n",
            "Epoch: [1/2] | Iterations: [1548/1995] | Training loss: 0.097\n",
            "Epoch: [1/2] | Iterations: [1549/1995] | Training loss: 0.141\n",
            "Epoch: [1/2] | Iterations: [1550/1995] | Training loss: 0.127\n",
            "Epoch: [1/2] | Iterations: [1551/1995] | Training loss: 0.120\n",
            "Epoch: [1/2] | Iterations: [1552/1995] | Training loss: 0.079\n",
            "Epoch: [1/2] | Iterations: [1553/1995] | Training loss: 0.171\n",
            "Epoch: [1/2] | Iterations: [1554/1995] | Training loss: 0.148\n",
            "Epoch: [1/2] | Iterations: [1555/1995] | Training loss: 0.160\n",
            "Epoch: [1/2] | Iterations: [1556/1995] | Training loss: 0.204\n",
            "Epoch: [1/2] | Iterations: [1557/1995] | Training loss: 0.126\n",
            "Epoch: [1/2] | Iterations: [1558/1995] | Training loss: 0.146\n",
            "Epoch: [1/2] | Iterations: [1559/1995] | Training loss: 0.173\n",
            "Epoch: [1/2] | Iterations: [1560/1995] | Training loss: 0.125\n",
            "Epoch: [1/2] | Iterations: [1561/1995] | Training loss: 0.127\n",
            "Epoch: [1/2] | Iterations: [1562/1995] | Training loss: 0.137\n",
            "Epoch: [1/2] | Iterations: [1563/1995] | Training loss: 0.190\n",
            "Epoch: [1/2] | Iterations: [1564/1995] | Training loss: 0.138\n",
            "Epoch: [1/2] | Iterations: [1565/1995] | Training loss: 0.073\n",
            "Epoch: [1/2] | Iterations: [1566/1995] | Training loss: 0.086\n",
            "Epoch: [1/2] | Iterations: [1567/1995] | Training loss: 0.066\n",
            "Epoch: [1/2] | Iterations: [1568/1995] | Training loss: 0.088\n",
            "Epoch: [1/2] | Iterations: [1569/1995] | Training loss: 0.095\n",
            "Epoch: [1/2] | Iterations: [1570/1995] | Training loss: 0.102\n",
            "Epoch: [1/2] | Iterations: [1571/1995] | Training loss: 0.135\n",
            "Epoch: [1/2] | Iterations: [1572/1995] | Training loss: 0.121\n",
            "Epoch: [1/2] | Iterations: [1573/1995] | Training loss: 0.127\n",
            "Epoch: [1/2] | Iterations: [1574/1995] | Training loss: 0.135\n",
            "Epoch: [1/2] | Iterations: [1575/1995] | Training loss: 0.099\n",
            "Epoch: [1/2] | Iterations: [1576/1995] | Training loss: 0.102\n",
            "Epoch: [1/2] | Iterations: [1577/1995] | Training loss: 0.120\n",
            "Epoch: [1/2] | Iterations: [1578/1995] | Training loss: 0.078\n",
            "Epoch: [1/2] | Iterations: [1579/1995] | Training loss: 0.090\n",
            "Epoch: [1/2] | Iterations: [1580/1995] | Training loss: 0.241\n",
            "Epoch: [1/2] | Iterations: [1581/1995] | Training loss: 0.082\n",
            "Epoch: [1/2] | Iterations: [1582/1995] | Training loss: 0.122\n",
            "Epoch: [1/2] | Iterations: [1583/1995] | Training loss: 0.116\n",
            "Epoch: [1/2] | Iterations: [1584/1995] | Training loss: 0.096\n",
            "Epoch: [1/2] | Iterations: [1585/1995] | Training loss: 0.204\n",
            "Epoch: [1/2] | Iterations: [1586/1995] | Training loss: 0.089\n",
            "Epoch: [1/2] | Iterations: [1587/1995] | Training loss: 0.118\n",
            "Epoch: [1/2] | Iterations: [1588/1995] | Training loss: 0.110\n",
            "Epoch: [1/2] | Iterations: [1589/1995] | Training loss: 0.092\n",
            "Epoch: [1/2] | Iterations: [1590/1995] | Training loss: 0.142\n",
            "Epoch: [1/2] | Iterations: [1591/1995] | Training loss: 0.117\n",
            "Epoch: [1/2] | Iterations: [1592/1995] | Training loss: 0.160\n",
            "Epoch: [1/2] | Iterations: [1593/1995] | Training loss: 0.184\n",
            "Epoch: [1/2] | Iterations: [1594/1995] | Training loss: 0.143\n",
            "Epoch: [1/2] | Iterations: [1595/1995] | Training loss: 0.105\n",
            "Epoch: [1/2] | Iterations: [1596/1995] | Training loss: 0.173\n",
            "Epoch: [1/2] | Iterations: [1597/1995] | Training loss: 0.143\n",
            "Epoch: [1/2] | Iterations: [1598/1995] | Training loss: 0.078\n",
            "Epoch: [1/2] | Iterations: [1599/1995] | Training loss: 0.113\n",
            "Epoch: [1/2] | Iterations: [1600/1995] | Training loss: 0.149\n",
            "Epoch: [1/2] | Iterations: [1601/1995] | Training loss: 0.170\n",
            "Epoch: [1/2] | Iterations: [1602/1995] | Training loss: 0.121\n",
            "Epoch: [1/2] | Iterations: [1603/1995] | Training loss: 0.133\n",
            "Epoch: [1/2] | Iterations: [1604/1995] | Training loss: 0.156\n",
            "Epoch: [1/2] | Iterations: [1605/1995] | Training loss: 0.040\n",
            "Epoch: [1/2] | Iterations: [1606/1995] | Training loss: 0.089\n",
            "Epoch: [1/2] | Iterations: [1607/1995] | Training loss: 0.161\n",
            "Epoch: [1/2] | Iterations: [1608/1995] | Training loss: 0.109\n",
            "Epoch: [1/2] | Iterations: [1609/1995] | Training loss: 0.118\n",
            "Epoch: [1/2] | Iterations: [1610/1995] | Training loss: 0.106\n",
            "Epoch: [1/2] | Iterations: [1611/1995] | Training loss: 0.120\n",
            "Epoch: [1/2] | Iterations: [1612/1995] | Training loss: 0.109\n",
            "Epoch: [1/2] | Iterations: [1613/1995] | Training loss: 0.141\n",
            "Epoch: [1/2] | Iterations: [1614/1995] | Training loss: 0.150\n",
            "Epoch: [1/2] | Iterations: [1615/1995] | Training loss: 0.127\n",
            "Epoch: [1/2] | Iterations: [1616/1995] | Training loss: 0.209\n",
            "Epoch: [1/2] | Iterations: [1617/1995] | Training loss: 0.160\n",
            "Epoch: [1/2] | Iterations: [1618/1995] | Training loss: 0.112\n",
            "Epoch: [1/2] | Iterations: [1619/1995] | Training loss: 0.142\n",
            "Epoch: [1/2] | Iterations: [1620/1995] | Training loss: 0.117\n",
            "Epoch: [1/2] | Iterations: [1621/1995] | Training loss: 0.101\n",
            "Epoch: [1/2] | Iterations: [1622/1995] | Training loss: 0.135\n",
            "Epoch: [1/2] | Iterations: [1623/1995] | Training loss: 0.098\n",
            "Epoch: [1/2] | Iterations: [1624/1995] | Training loss: 0.079\n",
            "Epoch: [1/2] | Iterations: [1625/1995] | Training loss: 0.113\n",
            "Epoch: [1/2] | Iterations: [1626/1995] | Training loss: 0.104\n",
            "Epoch: [1/2] | Iterations: [1627/1995] | Training loss: 0.161\n",
            "Epoch: [1/2] | Iterations: [1628/1995] | Training loss: 0.149\n",
            "Epoch: [1/2] | Iterations: [1629/1995] | Training loss: 0.096\n",
            "Epoch: [1/2] | Iterations: [1630/1995] | Training loss: 0.172\n",
            "Epoch: [1/2] | Iterations: [1631/1995] | Training loss: 0.140\n",
            "Epoch: [1/2] | Iterations: [1632/1995] | Training loss: 0.186\n",
            "Epoch: [1/2] | Iterations: [1633/1995] | Training loss: 0.084\n",
            "Epoch: [1/2] | Iterations: [1634/1995] | Training loss: 0.079\n",
            "Epoch: [1/2] | Iterations: [1635/1995] | Training loss: 0.160\n",
            "Epoch: [1/2] | Iterations: [1636/1995] | Training loss: 0.076\n",
            "Epoch: [1/2] | Iterations: [1637/1995] | Training loss: 0.156\n",
            "Epoch: [1/2] | Iterations: [1638/1995] | Training loss: 0.094\n",
            "Epoch: [1/2] | Iterations: [1639/1995] | Training loss: 0.120\n",
            "Epoch: [1/2] | Iterations: [1640/1995] | Training loss: 0.212\n",
            "Epoch: [1/2] | Iterations: [1641/1995] | Training loss: 0.106\n",
            "Epoch: [1/2] | Iterations: [1642/1995] | Training loss: 0.114\n",
            "Epoch: [1/2] | Iterations: [1643/1995] | Training loss: 0.243\n",
            "Epoch: [1/2] | Iterations: [1644/1995] | Training loss: 0.128\n",
            "Epoch: [1/2] | Iterations: [1645/1995] | Training loss: 0.155\n",
            "Epoch: [1/2] | Iterations: [1646/1995] | Training loss: 0.123\n",
            "Epoch: [1/2] | Iterations: [1647/1995] | Training loss: 0.185\n",
            "Epoch: [1/2] | Iterations: [1648/1995] | Training loss: 0.172\n",
            "Epoch: [1/2] | Iterations: [1649/1995] | Training loss: 0.163\n",
            "Epoch: [1/2] | Iterations: [1650/1995] | Training loss: 0.160\n",
            "Epoch: [1/2] | Iterations: [1651/1995] | Training loss: 0.135\n",
            "Epoch: [1/2] | Iterations: [1652/1995] | Training loss: 0.171\n",
            "Epoch: [1/2] | Iterations: [1653/1995] | Training loss: 0.176\n",
            "Epoch: [1/2] | Iterations: [1654/1995] | Training loss: 0.123\n",
            "Epoch: [1/2] | Iterations: [1655/1995] | Training loss: 0.164\n",
            "Epoch: [1/2] | Iterations: [1656/1995] | Training loss: 0.171\n",
            "Epoch: [1/2] | Iterations: [1657/1995] | Training loss: 0.132\n",
            "Epoch: [1/2] | Iterations: [1658/1995] | Training loss: 0.086\n",
            "Epoch: [1/2] | Iterations: [1659/1995] | Training loss: 0.253\n",
            "Epoch: [1/2] | Iterations: [1660/1995] | Training loss: 0.087\n",
            "Epoch: [1/2] | Iterations: [1661/1995] | Training loss: 0.137\n",
            "Epoch: [1/2] | Iterations: [1662/1995] | Training loss: 0.127\n",
            "Epoch: [1/2] | Iterations: [1663/1995] | Training loss: 0.097\n",
            "Epoch: [1/2] | Iterations: [1664/1995] | Training loss: 0.116\n",
            "Epoch: [1/2] | Iterations: [1665/1995] | Training loss: 0.105\n",
            "Epoch: [1/2] | Iterations: [1666/1995] | Training loss: 0.062\n",
            "Epoch: [1/2] | Iterations: [1667/1995] | Training loss: 0.096\n",
            "Epoch: [1/2] | Iterations: [1668/1995] | Training loss: 0.135\n",
            "Epoch: [1/2] | Iterations: [1669/1995] | Training loss: 0.146\n",
            "Epoch: [1/2] | Iterations: [1670/1995] | Training loss: 0.168\n",
            "Epoch: [1/2] | Iterations: [1671/1995] | Training loss: 0.113\n",
            "Epoch: [1/2] | Iterations: [1672/1995] | Training loss: 0.155\n",
            "Epoch: [1/2] | Iterations: [1673/1995] | Training loss: 0.185\n",
            "Epoch: [1/2] | Iterations: [1674/1995] | Training loss: 0.192\n",
            "Epoch: [1/2] | Iterations: [1675/1995] | Training loss: 0.147\n",
            "Epoch: [1/2] | Iterations: [1676/1995] | Training loss: 0.189\n",
            "Epoch: [1/2] | Iterations: [1677/1995] | Training loss: 0.056\n",
            "Epoch: [1/2] | Iterations: [1678/1995] | Training loss: 0.127\n",
            "Epoch: [1/2] | Iterations: [1679/1995] | Training loss: 0.136\n",
            "Epoch: [1/2] | Iterations: [1680/1995] | Training loss: 0.079\n",
            "Epoch: [1/2] | Iterations: [1681/1995] | Training loss: 0.163\n",
            "Epoch: [1/2] | Iterations: [1682/1995] | Training loss: 0.077\n",
            "Epoch: [1/2] | Iterations: [1683/1995] | Training loss: 0.154\n",
            "Epoch: [1/2] | Iterations: [1684/1995] | Training loss: 0.075\n",
            "Epoch: [1/2] | Iterations: [1685/1995] | Training loss: 0.094\n",
            "Epoch: [1/2] | Iterations: [1686/1995] | Training loss: 0.136\n",
            "Epoch: [1/2] | Iterations: [1687/1995] | Training loss: 0.105\n",
            "Epoch: [1/2] | Iterations: [1688/1995] | Training loss: 0.100\n",
            "Epoch: [1/2] | Iterations: [1689/1995] | Training loss: 0.095\n",
            "Epoch: [1/2] | Iterations: [1690/1995] | Training loss: 0.097\n",
            "Epoch: [1/2] | Iterations: [1691/1995] | Training loss: 0.129\n",
            "Epoch: [1/2] | Iterations: [1692/1995] | Training loss: 0.107\n",
            "Epoch: [1/2] | Iterations: [1693/1995] | Training loss: 0.101\n",
            "Epoch: [1/2] | Iterations: [1694/1995] | Training loss: 0.134\n",
            "Epoch: [1/2] | Iterations: [1695/1995] | Training loss: 0.128\n",
            "Epoch: [1/2] | Iterations: [1696/1995] | Training loss: 0.127\n",
            "Epoch: [1/2] | Iterations: [1697/1995] | Training loss: 0.135\n",
            "Epoch: [1/2] | Iterations: [1698/1995] | Training loss: 0.126\n",
            "Epoch: [1/2] | Iterations: [1699/1995] | Training loss: 0.163\n",
            "Epoch: [1/2] | Iterations: [1700/1995] | Training loss: 0.076\n",
            "Epoch: [1/2] | Iterations: [1701/1995] | Training loss: 0.184\n",
            "Epoch: [1/2] | Iterations: [1702/1995] | Training loss: 0.141\n",
            "Epoch: [1/2] | Iterations: [1703/1995] | Training loss: 0.090\n",
            "Epoch: [1/2] | Iterations: [1704/1995] | Training loss: 0.052\n",
            "Epoch: [1/2] | Iterations: [1705/1995] | Training loss: 0.106\n",
            "Epoch: [1/2] | Iterations: [1706/1995] | Training loss: 0.088\n",
            "Epoch: [1/2] | Iterations: [1707/1995] | Training loss: 0.124\n",
            "Epoch: [1/2] | Iterations: [1708/1995] | Training loss: 0.151\n",
            "Epoch: [1/2] | Iterations: [1709/1995] | Training loss: 0.099\n",
            "Epoch: [1/2] | Iterations: [1710/1995] | Training loss: 0.084\n",
            "Epoch: [1/2] | Iterations: [1711/1995] | Training loss: 0.113\n",
            "Epoch: [1/2] | Iterations: [1712/1995] | Training loss: 0.136\n",
            "Epoch: [1/2] | Iterations: [1713/1995] | Training loss: 0.065\n",
            "Epoch: [1/2] | Iterations: [1714/1995] | Training loss: 0.166\n",
            "Epoch: [1/2] | Iterations: [1715/1995] | Training loss: 0.104\n",
            "Epoch: [1/2] | Iterations: [1716/1995] | Training loss: 0.059\n",
            "Epoch: [1/2] | Iterations: [1717/1995] | Training loss: 0.154\n",
            "Epoch: [1/2] | Iterations: [1718/1995] | Training loss: 0.166\n",
            "Epoch: [1/2] | Iterations: [1719/1995] | Training loss: 0.111\n",
            "Epoch: [1/2] | Iterations: [1720/1995] | Training loss: 0.090\n",
            "Epoch: [1/2] | Iterations: [1721/1995] | Training loss: 0.129\n",
            "Epoch: [1/2] | Iterations: [1722/1995] | Training loss: 0.079\n",
            "Epoch: [1/2] | Iterations: [1723/1995] | Training loss: 0.133\n",
            "Epoch: [1/2] | Iterations: [1724/1995] | Training loss: 0.174\n",
            "Epoch: [1/2] | Iterations: [1725/1995] | Training loss: 0.089\n",
            "Epoch: [1/2] | Iterations: [1726/1995] | Training loss: 0.079\n",
            "Epoch: [1/2] | Iterations: [1727/1995] | Training loss: 0.149\n",
            "Epoch: [1/2] | Iterations: [1728/1995] | Training loss: 0.087\n",
            "Epoch: [1/2] | Iterations: [1729/1995] | Training loss: 0.121\n",
            "Epoch: [1/2] | Iterations: [1730/1995] | Training loss: 0.055\n",
            "Epoch: [1/2] | Iterations: [1731/1995] | Training loss: 0.071\n",
            "Epoch: [1/2] | Iterations: [1732/1995] | Training loss: 0.174\n",
            "Epoch: [1/2] | Iterations: [1733/1995] | Training loss: 0.176\n",
            "Epoch: [1/2] | Iterations: [1734/1995] | Training loss: 0.156\n",
            "Epoch: [1/2] | Iterations: [1735/1995] | Training loss: 0.164\n",
            "Epoch: [1/2] | Iterations: [1736/1995] | Training loss: 0.129\n",
            "Epoch: [1/2] | Iterations: [1737/1995] | Training loss: 0.172\n",
            "Epoch: [1/2] | Iterations: [1738/1995] | Training loss: 0.144\n",
            "Epoch: [1/2] | Iterations: [1739/1995] | Training loss: 0.150\n",
            "Epoch: [1/2] | Iterations: [1740/1995] | Training loss: 0.150\n",
            "Epoch: [1/2] | Iterations: [1741/1995] | Training loss: 0.083\n",
            "Epoch: [1/2] | Iterations: [1742/1995] | Training loss: 0.062\n",
            "Epoch: [1/2] | Iterations: [1743/1995] | Training loss: 0.147\n",
            "Epoch: [1/2] | Iterations: [1744/1995] | Training loss: 0.162\n",
            "Epoch: [1/2] | Iterations: [1745/1995] | Training loss: 0.106\n",
            "Epoch: [1/2] | Iterations: [1746/1995] | Training loss: 0.140\n",
            "Epoch: [1/2] | Iterations: [1747/1995] | Training loss: 0.089\n",
            "Epoch: [1/2] | Iterations: [1748/1995] | Training loss: 0.141\n",
            "Epoch: [1/2] | Iterations: [1749/1995] | Training loss: 0.170\n",
            "Epoch: [1/2] | Iterations: [1750/1995] | Training loss: 0.124\n",
            "Epoch: [1/2] | Iterations: [1751/1995] | Training loss: 0.055\n",
            "Epoch: [1/2] | Iterations: [1752/1995] | Training loss: 0.115\n",
            "Epoch: [1/2] | Iterations: [1753/1995] | Training loss: 0.108\n",
            "Epoch: [1/2] | Iterations: [1754/1995] | Training loss: 0.093\n",
            "Epoch: [1/2] | Iterations: [1755/1995] | Training loss: 0.133\n",
            "Epoch: [1/2] | Iterations: [1756/1995] | Training loss: 0.119\n",
            "Epoch: [1/2] | Iterations: [1757/1995] | Training loss: 0.062\n",
            "Epoch: [1/2] | Iterations: [1758/1995] | Training loss: 0.163\n",
            "Epoch: [1/2] | Iterations: [1759/1995] | Training loss: 0.100\n",
            "Epoch: [1/2] | Iterations: [1760/1995] | Training loss: 0.136\n",
            "Epoch: [1/2] | Iterations: [1761/1995] | Training loss: 0.120\n",
            "Epoch: [1/2] | Iterations: [1762/1995] | Training loss: 0.123\n",
            "Epoch: [1/2] | Iterations: [1763/1995] | Training loss: 0.079\n",
            "Epoch: [1/2] | Iterations: [1764/1995] | Training loss: 0.155\n",
            "Epoch: [1/2] | Iterations: [1765/1995] | Training loss: 0.071\n",
            "Epoch: [1/2] | Iterations: [1766/1995] | Training loss: 0.100\n",
            "Epoch: [1/2] | Iterations: [1767/1995] | Training loss: 0.118\n",
            "Epoch: [1/2] | Iterations: [1768/1995] | Training loss: 0.085\n",
            "Epoch: [1/2] | Iterations: [1769/1995] | Training loss: 0.133\n",
            "Epoch: [1/2] | Iterations: [1770/1995] | Training loss: 0.180\n",
            "Epoch: [1/2] | Iterations: [1771/1995] | Training loss: 0.200\n",
            "Epoch: [1/2] | Iterations: [1772/1995] | Training loss: 0.107\n",
            "Epoch: [1/2] | Iterations: [1773/1995] | Training loss: 0.119\n",
            "Epoch: [1/2] | Iterations: [1774/1995] | Training loss: 0.053\n",
            "Epoch: [1/2] | Iterations: [1775/1995] | Training loss: 0.110\n",
            "Epoch: [1/2] | Iterations: [1776/1995] | Training loss: 0.114\n",
            "Epoch: [1/2] | Iterations: [1777/1995] | Training loss: 0.101\n",
            "Epoch: [1/2] | Iterations: [1778/1995] | Training loss: 0.159\n",
            "Epoch: [1/2] | Iterations: [1779/1995] | Training loss: 0.083\n",
            "Epoch: [1/2] | Iterations: [1780/1995] | Training loss: 0.115\n",
            "Epoch: [1/2] | Iterations: [1781/1995] | Training loss: 0.188\n",
            "Epoch: [1/2] | Iterations: [1782/1995] | Training loss: 0.165\n",
            "Epoch: [1/2] | Iterations: [1783/1995] | Training loss: 0.066\n",
            "Epoch: [1/2] | Iterations: [1784/1995] | Training loss: 0.121\n",
            "Epoch: [1/2] | Iterations: [1785/1995] | Training loss: 0.138\n",
            "Epoch: [1/2] | Iterations: [1786/1995] | Training loss: 0.166\n",
            "Epoch: [1/2] | Iterations: [1787/1995] | Training loss: 0.150\n",
            "Epoch: [1/2] | Iterations: [1788/1995] | Training loss: 0.077\n",
            "Epoch: [1/2] | Iterations: [1789/1995] | Training loss: 0.142\n",
            "Epoch: [1/2] | Iterations: [1790/1995] | Training loss: 0.098\n",
            "Epoch: [1/2] | Iterations: [1791/1995] | Training loss: 0.122\n",
            "Epoch: [1/2] | Iterations: [1792/1995] | Training loss: 0.138\n",
            "Epoch: [1/2] | Iterations: [1793/1995] | Training loss: 0.112\n",
            "Epoch: [1/2] | Iterations: [1794/1995] | Training loss: 0.117\n",
            "Epoch: [1/2] | Iterations: [1795/1995] | Training loss: 0.103\n",
            "Epoch: [1/2] | Iterations: [1796/1995] | Training loss: 0.101\n",
            "Epoch: [1/2] | Iterations: [1797/1995] | Training loss: 0.071\n",
            "Epoch: [1/2] | Iterations: [1798/1995] | Training loss: 0.123\n",
            "Epoch: [1/2] | Iterations: [1799/1995] | Training loss: 0.069\n",
            "Epoch: [1/2] | Iterations: [1800/1995] | Training loss: 0.113\n",
            "Epoch: [1/2] | Iterations: [1801/1995] | Training loss: 0.212\n",
            "Epoch: [1/2] | Iterations: [1802/1995] | Training loss: 0.107\n",
            "Epoch: [1/2] | Iterations: [1803/1995] | Training loss: 0.105\n",
            "Epoch: [1/2] | Iterations: [1804/1995] | Training loss: 0.166\n",
            "Epoch: [1/2] | Iterations: [1805/1995] | Training loss: 0.078\n",
            "Epoch: [1/2] | Iterations: [1806/1995] | Training loss: 0.111\n",
            "Epoch: [1/2] | Iterations: [1807/1995] | Training loss: 0.098\n",
            "Epoch: [1/2] | Iterations: [1808/1995] | Training loss: 0.218\n",
            "Epoch: [1/2] | Iterations: [1809/1995] | Training loss: 0.097\n",
            "Epoch: [1/2] | Iterations: [1810/1995] | Training loss: 0.062\n",
            "Epoch: [1/2] | Iterations: [1811/1995] | Training loss: 0.117\n",
            "Epoch: [1/2] | Iterations: [1812/1995] | Training loss: 0.147\n",
            "Epoch: [1/2] | Iterations: [1813/1995] | Training loss: 0.178\n",
            "Epoch: [1/2] | Iterations: [1814/1995] | Training loss: 0.085\n",
            "Epoch: [1/2] | Iterations: [1815/1995] | Training loss: 0.069\n",
            "Epoch: [1/2] | Iterations: [1816/1995] | Training loss: 0.197\n",
            "Epoch: [1/2] | Iterations: [1817/1995] | Training loss: 0.215\n",
            "Epoch: [1/2] | Iterations: [1818/1995] | Training loss: 0.068\n",
            "Epoch: [1/2] | Iterations: [1819/1995] | Training loss: 0.127\n",
            "Epoch: [1/2] | Iterations: [1820/1995] | Training loss: 0.123\n",
            "Epoch: [1/2] | Iterations: [1821/1995] | Training loss: 0.161\n",
            "Epoch: [1/2] | Iterations: [1822/1995] | Training loss: 0.103\n",
            "Epoch: [1/2] | Iterations: [1823/1995] | Training loss: 0.120\n",
            "Epoch: [1/2] | Iterations: [1824/1995] | Training loss: 0.138\n",
            "Epoch: [1/2] | Iterations: [1825/1995] | Training loss: 0.162\n",
            "Epoch: [1/2] | Iterations: [1826/1995] | Training loss: 0.109\n",
            "Epoch: [1/2] | Iterations: [1827/1995] | Training loss: 0.105\n",
            "Epoch: [1/2] | Iterations: [1828/1995] | Training loss: 0.091\n",
            "Epoch: [1/2] | Iterations: [1829/1995] | Training loss: 0.114\n",
            "Epoch: [1/2] | Iterations: [1830/1995] | Training loss: 0.126\n",
            "Epoch: [1/2] | Iterations: [1831/1995] | Training loss: 0.076\n",
            "Epoch: [1/2] | Iterations: [1832/1995] | Training loss: 0.117\n",
            "Epoch: [1/2] | Iterations: [1833/1995] | Training loss: 0.152\n",
            "Epoch: [1/2] | Iterations: [1834/1995] | Training loss: 0.155\n",
            "Epoch: [1/2] | Iterations: [1835/1995] | Training loss: 0.096\n",
            "Epoch: [1/2] | Iterations: [1836/1995] | Training loss: 0.081\n",
            "Epoch: [1/2] | Iterations: [1837/1995] | Training loss: 0.145\n",
            "Epoch: [1/2] | Iterations: [1838/1995] | Training loss: 0.116\n",
            "Epoch: [1/2] | Iterations: [1839/1995] | Training loss: 0.115\n",
            "Epoch: [1/2] | Iterations: [1840/1995] | Training loss: 0.088\n",
            "Epoch: [1/2] | Iterations: [1841/1995] | Training loss: 0.079\n",
            "Epoch: [1/2] | Iterations: [1842/1995] | Training loss: 0.129\n",
            "Epoch: [1/2] | Iterations: [1843/1995] | Training loss: 0.127\n",
            "Epoch: [1/2] | Iterations: [1844/1995] | Training loss: 0.131\n",
            "Epoch: [1/2] | Iterations: [1845/1995] | Training loss: 0.083\n",
            "Epoch: [1/2] | Iterations: [1846/1995] | Training loss: 0.108\n",
            "Epoch: [1/2] | Iterations: [1847/1995] | Training loss: 0.155\n",
            "Epoch: [1/2] | Iterations: [1848/1995] | Training loss: 0.119\n",
            "Epoch: [1/2] | Iterations: [1849/1995] | Training loss: 0.155\n",
            "Epoch: [1/2] | Iterations: [1850/1995] | Training loss: 0.194\n",
            "Epoch: [1/2] | Iterations: [1851/1995] | Training loss: 0.082\n",
            "Epoch: [1/2] | Iterations: [1852/1995] | Training loss: 0.115\n",
            "Epoch: [1/2] | Iterations: [1853/1995] | Training loss: 0.121\n",
            "Epoch: [1/2] | Iterations: [1854/1995] | Training loss: 0.162\n",
            "Epoch: [1/2] | Iterations: [1855/1995] | Training loss: 0.101\n",
            "Epoch: [1/2] | Iterations: [1856/1995] | Training loss: 0.080\n",
            "Epoch: [1/2] | Iterations: [1857/1995] | Training loss: 0.126\n",
            "Epoch: [1/2] | Iterations: [1858/1995] | Training loss: 0.120\n",
            "Epoch: [1/2] | Iterations: [1859/1995] | Training loss: 0.084\n",
            "Epoch: [1/2] | Iterations: [1860/1995] | Training loss: 0.172\n",
            "Epoch: [1/2] | Iterations: [1861/1995] | Training loss: 0.115\n",
            "Epoch: [1/2] | Iterations: [1862/1995] | Training loss: 0.085\n",
            "Epoch: [1/2] | Iterations: [1863/1995] | Training loss: 0.171\n",
            "Epoch: [1/2] | Iterations: [1864/1995] | Training loss: 0.105\n",
            "Epoch: [1/2] | Iterations: [1865/1995] | Training loss: 0.083\n",
            "Epoch: [1/2] | Iterations: [1866/1995] | Training loss: 0.061\n",
            "Epoch: [1/2] | Iterations: [1867/1995] | Training loss: 0.081\n",
            "Epoch: [1/2] | Iterations: [1868/1995] | Training loss: 0.184\n",
            "Epoch: [1/2] | Iterations: [1869/1995] | Training loss: 0.071\n",
            "Epoch: [1/2] | Iterations: [1870/1995] | Training loss: 0.123\n",
            "Epoch: [1/2] | Iterations: [1871/1995] | Training loss: 0.100\n",
            "Epoch: [1/2] | Iterations: [1872/1995] | Training loss: 0.085\n",
            "Epoch: [1/2] | Iterations: [1873/1995] | Training loss: 0.102\n",
            "Epoch: [1/2] | Iterations: [1874/1995] | Training loss: 0.129\n",
            "Epoch: [1/2] | Iterations: [1875/1995] | Training loss: 0.219\n",
            "Epoch: [1/2] | Iterations: [1876/1995] | Training loss: 0.100\n",
            "Epoch: [1/2] | Iterations: [1877/1995] | Training loss: 0.239\n",
            "Epoch: [1/2] | Iterations: [1878/1995] | Training loss: 0.082\n",
            "Epoch: [1/2] | Iterations: [1879/1995] | Training loss: 0.120\n",
            "Epoch: [1/2] | Iterations: [1880/1995] | Training loss: 0.127\n",
            "Epoch: [1/2] | Iterations: [1881/1995] | Training loss: 0.106\n",
            "Epoch: [1/2] | Iterations: [1882/1995] | Training loss: 0.086\n",
            "Epoch: [1/2] | Iterations: [1883/1995] | Training loss: 0.127\n",
            "Epoch: [1/2] | Iterations: [1884/1995] | Training loss: 0.105\n",
            "Epoch: [1/2] | Iterations: [1885/1995] | Training loss: 0.125\n",
            "Epoch: [1/2] | Iterations: [1886/1995] | Training loss: 0.163\n",
            "Epoch: [1/2] | Iterations: [1887/1995] | Training loss: 0.119\n",
            "Epoch: [1/2] | Iterations: [1888/1995] | Training loss: 0.136\n",
            "Epoch: [1/2] | Iterations: [1889/1995] | Training loss: 0.162\n",
            "Epoch: [1/2] | Iterations: [1890/1995] | Training loss: 0.080\n",
            "Epoch: [1/2] | Iterations: [1891/1995] | Training loss: 0.092\n",
            "Epoch: [1/2] | Iterations: [1892/1995] | Training loss: 0.104\n",
            "Epoch: [1/2] | Iterations: [1893/1995] | Training loss: 0.081\n",
            "Epoch: [1/2] | Iterations: [1894/1995] | Training loss: 0.113\n",
            "Epoch: [1/2] | Iterations: [1895/1995] | Training loss: 0.100\n",
            "Epoch: [1/2] | Iterations: [1896/1995] | Training loss: 0.155\n",
            "Epoch: [1/2] | Iterations: [1897/1995] | Training loss: 0.133\n",
            "Epoch: [1/2] | Iterations: [1898/1995] | Training loss: 0.141\n",
            "Epoch: [1/2] | Iterations: [1899/1995] | Training loss: 0.117\n",
            "Epoch: [1/2] | Iterations: [1900/1995] | Training loss: 0.184\n",
            "Epoch: [1/2] | Iterations: [1901/1995] | Training loss: 0.143\n",
            "Epoch: [1/2] | Iterations: [1902/1995] | Training loss: 0.104\n",
            "Epoch: [1/2] | Iterations: [1903/1995] | Training loss: 0.076\n",
            "Epoch: [1/2] | Iterations: [1904/1995] | Training loss: 0.151\n",
            "Epoch: [1/2] | Iterations: [1905/1995] | Training loss: 0.215\n",
            "Epoch: [1/2] | Iterations: [1906/1995] | Training loss: 0.117\n",
            "Epoch: [1/2] | Iterations: [1907/1995] | Training loss: 0.122\n",
            "Epoch: [1/2] | Iterations: [1908/1995] | Training loss: 0.099\n",
            "Epoch: [1/2] | Iterations: [1909/1995] | Training loss: 0.113\n",
            "Epoch: [1/2] | Iterations: [1910/1995] | Training loss: 0.122\n",
            "Epoch: [1/2] | Iterations: [1911/1995] | Training loss: 0.118\n",
            "Epoch: [1/2] | Iterations: [1912/1995] | Training loss: 0.121\n",
            "Epoch: [1/2] | Iterations: [1913/1995] | Training loss: 0.110\n",
            "Epoch: [1/2] | Iterations: [1914/1995] | Training loss: 0.168\n",
            "Epoch: [1/2] | Iterations: [1915/1995] | Training loss: 0.101\n",
            "Epoch: [1/2] | Iterations: [1916/1995] | Training loss: 0.096\n",
            "Epoch: [1/2] | Iterations: [1917/1995] | Training loss: 0.135\n",
            "Epoch: [1/2] | Iterations: [1918/1995] | Training loss: 0.146\n",
            "Epoch: [1/2] | Iterations: [1919/1995] | Training loss: 0.123\n",
            "Epoch: [1/2] | Iterations: [1920/1995] | Training loss: 0.090\n",
            "Epoch: [1/2] | Iterations: [1921/1995] | Training loss: 0.073\n",
            "Epoch: [1/2] | Iterations: [1922/1995] | Training loss: 0.070\n",
            "Epoch: [1/2] | Iterations: [1923/1995] | Training loss: 0.135\n",
            "Epoch: [1/2] | Iterations: [1924/1995] | Training loss: 0.101\n",
            "Epoch: [1/2] | Iterations: [1925/1995] | Training loss: 0.125\n",
            "Epoch: [1/2] | Iterations: [1926/1995] | Training loss: 0.123\n",
            "Epoch: [1/2] | Iterations: [1927/1995] | Training loss: 0.161\n",
            "Epoch: [1/2] | Iterations: [1928/1995] | Training loss: 0.080\n",
            "Epoch: [1/2] | Iterations: [1929/1995] | Training loss: 0.144\n",
            "Epoch: [1/2] | Iterations: [1930/1995] | Training loss: 0.137\n",
            "Epoch: [1/2] | Iterations: [1931/1995] | Training loss: 0.144\n",
            "Epoch: [1/2] | Iterations: [1932/1995] | Training loss: 0.090\n",
            "Epoch: [1/2] | Iterations: [1933/1995] | Training loss: 0.105\n",
            "Epoch: [1/2] | Iterations: [1934/1995] | Training loss: 0.118\n",
            "Epoch: [1/2] | Iterations: [1935/1995] | Training loss: 0.129\n",
            "Epoch: [1/2] | Iterations: [1936/1995] | Training loss: 0.130\n",
            "Epoch: [1/2] | Iterations: [1937/1995] | Training loss: 0.070\n",
            "Epoch: [1/2] | Iterations: [1938/1995] | Training loss: 0.130\n",
            "Epoch: [1/2] | Iterations: [1939/1995] | Training loss: 0.093\n",
            "Epoch: [1/2] | Iterations: [1940/1995] | Training loss: 0.033\n",
            "Epoch: [1/2] | Iterations: [1941/1995] | Training loss: 0.110\n",
            "Epoch: [1/2] | Iterations: [1942/1995] | Training loss: 0.101\n",
            "Epoch: [1/2] | Iterations: [1943/1995] | Training loss: 0.142\n",
            "Epoch: [1/2] | Iterations: [1944/1995] | Training loss: 0.092\n",
            "Epoch: [1/2] | Iterations: [1945/1995] | Training loss: 0.130\n",
            "Epoch: [1/2] | Iterations: [1946/1995] | Training loss: 0.092\n",
            "Epoch: [1/2] | Iterations: [1947/1995] | Training loss: 0.076\n",
            "Epoch: [1/2] | Iterations: [1948/1995] | Training loss: 0.091\n",
            "Epoch: [1/2] | Iterations: [1949/1995] | Training loss: 0.077\n",
            "Epoch: [1/2] | Iterations: [1950/1995] | Training loss: 0.185\n",
            "Epoch: [1/2] | Iterations: [1951/1995] | Training loss: 0.122\n",
            "Epoch: [1/2] | Iterations: [1952/1995] | Training loss: 0.117\n",
            "Epoch: [1/2] | Iterations: [1953/1995] | Training loss: 0.166\n",
            "Epoch: [1/2] | Iterations: [1954/1995] | Training loss: 0.117\n",
            "Epoch: [1/2] | Iterations: [1955/1995] | Training loss: 0.077\n",
            "Epoch: [1/2] | Iterations: [1956/1995] | Training loss: 0.099\n",
            "Epoch: [1/2] | Iterations: [1957/1995] | Training loss: 0.065\n",
            "Epoch: [1/2] | Iterations: [1958/1995] | Training loss: 0.206\n",
            "Epoch: [1/2] | Iterations: [1959/1995] | Training loss: 0.111\n",
            "Epoch: [1/2] | Iterations: [1960/1995] | Training loss: 0.069\n",
            "Epoch: [1/2] | Iterations: [1961/1995] | Training loss: 0.119\n",
            "Epoch: [1/2] | Iterations: [1962/1995] | Training loss: 0.060\n",
            "Epoch: [1/2] | Iterations: [1963/1995] | Training loss: 0.073\n",
            "Epoch: [1/2] | Iterations: [1964/1995] | Training loss: 0.072\n",
            "Epoch: [1/2] | Iterations: [1965/1995] | Training loss: 0.162\n",
            "Epoch: [1/2] | Iterations: [1966/1995] | Training loss: 0.117\n",
            "Epoch: [1/2] | Iterations: [1967/1995] | Training loss: 0.119\n",
            "Epoch: [1/2] | Iterations: [1968/1995] | Training loss: 0.079\n",
            "Epoch: [1/2] | Iterations: [1969/1995] | Training loss: 0.103\n",
            "Epoch: [1/2] | Iterations: [1970/1995] | Training loss: 0.085\n",
            "Epoch: [1/2] | Iterations: [1971/1995] | Training loss: 0.136\n",
            "Epoch: [1/2] | Iterations: [1972/1995] | Training loss: 0.117\n",
            "Epoch: [1/2] | Iterations: [1973/1995] | Training loss: 0.198\n",
            "Epoch: [1/2] | Iterations: [1974/1995] | Training loss: 0.128\n",
            "Epoch: [1/2] | Iterations: [1975/1995] | Training loss: 0.169\n",
            "Epoch: [1/2] | Iterations: [1976/1995] | Training loss: 0.133\n",
            "Epoch: [1/2] | Iterations: [1977/1995] | Training loss: 0.153\n",
            "Epoch: [1/2] | Iterations: [1978/1995] | Training loss: 0.134\n",
            "Epoch: [1/2] | Iterations: [1979/1995] | Training loss: 0.128\n",
            "Epoch: [1/2] | Iterations: [1980/1995] | Training loss: 0.114\n",
            "Epoch: [1/2] | Iterations: [1981/1995] | Training loss: 0.144\n",
            "Epoch: [1/2] | Iterations: [1982/1995] | Training loss: 0.063\n",
            "Epoch: [1/2] | Iterations: [1983/1995] | Training loss: 0.154\n",
            "Epoch: [1/2] | Iterations: [1984/1995] | Training loss: 0.041\n",
            "Epoch: [1/2] | Iterations: [1985/1995] | Training loss: 0.177\n",
            "Epoch: [1/2] | Iterations: [1986/1995] | Training loss: 0.075\n",
            "Epoch: [1/2] | Iterations: [1987/1995] | Training loss: 0.153\n",
            "Epoch: [1/2] | Iterations: [1988/1995] | Training loss: 0.090\n",
            "Epoch: [1/2] | Iterations: [1989/1995] | Training loss: 0.083\n",
            "Epoch: [1/2] | Iterations: [1990/1995] | Training loss: 0.157\n",
            "Epoch: [1/2] | Iterations: [1991/1995] | Training loss: 0.102\n",
            "Epoch: [1/2] | Iterations: [1992/1995] | Training loss: 0.137\n",
            "Epoch: [1/2] | Iterations: [1993/1995] | Training loss: 0.068\n",
            "Epoch: [1/2] | Iterations: [1994/1995] | Training loss: 0.078\n",
            "Epoch: [1/2] | Iterations: [1995/1995] | Training loss: 0.068\n",
            "Epoch: [2/2] | Iterations: [1/1995] | Training loss: 0.101\n",
            "Epoch: [2/2] | Iterations: [2/1995] | Training loss: 0.133\n",
            "Epoch: [2/2] | Iterations: [3/1995] | Training loss: 0.091\n",
            "Epoch: [2/2] | Iterations: [4/1995] | Training loss: 0.057\n",
            "Epoch: [2/2] | Iterations: [5/1995] | Training loss: 0.100\n",
            "Epoch: [2/2] | Iterations: [6/1995] | Training loss: 0.125\n",
            "Epoch: [2/2] | Iterations: [7/1995] | Training loss: 0.079\n",
            "Epoch: [2/2] | Iterations: [8/1995] | Training loss: 0.198\n",
            "Epoch: [2/2] | Iterations: [9/1995] | Training loss: 0.120\n",
            "Epoch: [2/2] | Iterations: [10/1995] | Training loss: 0.077\n",
            "Epoch: [2/2] | Iterations: [11/1995] | Training loss: 0.069\n",
            "Epoch: [2/2] | Iterations: [12/1995] | Training loss: 0.094\n",
            "Epoch: [2/2] | Iterations: [13/1995] | Training loss: 0.138\n",
            "Epoch: [2/2] | Iterations: [14/1995] | Training loss: 0.190\n",
            "Epoch: [2/2] | Iterations: [15/1995] | Training loss: 0.102\n",
            "Epoch: [2/2] | Iterations: [16/1995] | Training loss: 0.126\n",
            "Epoch: [2/2] | Iterations: [17/1995] | Training loss: 0.077\n",
            "Epoch: [2/2] | Iterations: [18/1995] | Training loss: 0.091\n",
            "Epoch: [2/2] | Iterations: [19/1995] | Training loss: 0.065\n",
            "Epoch: [2/2] | Iterations: [20/1995] | Training loss: 0.134\n",
            "Epoch: [2/2] | Iterations: [21/1995] | Training loss: 0.193\n",
            "Epoch: [2/2] | Iterations: [22/1995] | Training loss: 0.099\n",
            "Epoch: [2/2] | Iterations: [23/1995] | Training loss: 0.058\n",
            "Epoch: [2/2] | Iterations: [24/1995] | Training loss: 0.134\n",
            "Epoch: [2/2] | Iterations: [25/1995] | Training loss: 0.131\n",
            "Epoch: [2/2] | Iterations: [26/1995] | Training loss: 0.052\n",
            "Epoch: [2/2] | Iterations: [27/1995] | Training loss: 0.144\n",
            "Epoch: [2/2] | Iterations: [28/1995] | Training loss: 0.094\n",
            "Epoch: [2/2] | Iterations: [29/1995] | Training loss: 0.121\n",
            "Epoch: [2/2] | Iterations: [30/1995] | Training loss: 0.137\n",
            "Epoch: [2/2] | Iterations: [31/1995] | Training loss: 0.173\n",
            "Epoch: [2/2] | Iterations: [32/1995] | Training loss: 0.210\n",
            "Epoch: [2/2] | Iterations: [33/1995] | Training loss: 0.079\n",
            "Epoch: [2/2] | Iterations: [34/1995] | Training loss: 0.124\n",
            "Epoch: [2/2] | Iterations: [35/1995] | Training loss: 0.102\n",
            "Epoch: [2/2] | Iterations: [36/1995] | Training loss: 0.169\n",
            "Epoch: [2/2] | Iterations: [37/1995] | Training loss: 0.095\n",
            "Epoch: [2/2] | Iterations: [38/1995] | Training loss: 0.151\n",
            "Epoch: [2/2] | Iterations: [39/1995] | Training loss: 0.073\n",
            "Epoch: [2/2] | Iterations: [40/1995] | Training loss: 0.180\n",
            "Epoch: [2/2] | Iterations: [41/1995] | Training loss: 0.097\n",
            "Epoch: [2/2] | Iterations: [42/1995] | Training loss: 0.115\n",
            "Epoch: [2/2] | Iterations: [43/1995] | Training loss: 0.163\n",
            "Epoch: [2/2] | Iterations: [44/1995] | Training loss: 0.066\n",
            "Epoch: [2/2] | Iterations: [45/1995] | Training loss: 0.113\n",
            "Epoch: [2/2] | Iterations: [46/1995] | Training loss: 0.132\n",
            "Epoch: [2/2] | Iterations: [47/1995] | Training loss: 0.084\n",
            "Epoch: [2/2] | Iterations: [48/1995] | Training loss: 0.104\n",
            "Epoch: [2/2] | Iterations: [49/1995] | Training loss: 0.116\n",
            "Epoch: [2/2] | Iterations: [50/1995] | Training loss: 0.082\n",
            "Epoch: [2/2] | Iterations: [51/1995] | Training loss: 0.102\n",
            "Epoch: [2/2] | Iterations: [52/1995] | Training loss: 0.087\n",
            "Epoch: [2/2] | Iterations: [53/1995] | Training loss: 0.140\n",
            "Epoch: [2/2] | Iterations: [54/1995] | Training loss: 0.191\n",
            "Epoch: [2/2] | Iterations: [55/1995] | Training loss: 0.075\n",
            "Epoch: [2/2] | Iterations: [56/1995] | Training loss: 0.092\n",
            "Epoch: [2/2] | Iterations: [57/1995] | Training loss: 0.149\n",
            "Epoch: [2/2] | Iterations: [58/1995] | Training loss: 0.132\n",
            "Epoch: [2/2] | Iterations: [59/1995] | Training loss: 0.091\n",
            "Epoch: [2/2] | Iterations: [60/1995] | Training loss: 0.151\n",
            "Epoch: [2/2] | Iterations: [61/1995] | Training loss: 0.123\n",
            "Epoch: [2/2] | Iterations: [62/1995] | Training loss: 0.078\n",
            "Epoch: [2/2] | Iterations: [63/1995] | Training loss: 0.122\n",
            "Epoch: [2/2] | Iterations: [64/1995] | Training loss: 0.137\n",
            "Epoch: [2/2] | Iterations: [65/1995] | Training loss: 0.197\n",
            "Epoch: [2/2] | Iterations: [66/1995] | Training loss: 0.139\n",
            "Epoch: [2/2] | Iterations: [67/1995] | Training loss: 0.073\n",
            "Epoch: [2/2] | Iterations: [68/1995] | Training loss: 0.123\n",
            "Epoch: [2/2] | Iterations: [69/1995] | Training loss: 0.104\n",
            "Epoch: [2/2] | Iterations: [70/1995] | Training loss: 0.141\n",
            "Epoch: [2/2] | Iterations: [71/1995] | Training loss: 0.124\n",
            "Epoch: [2/2] | Iterations: [72/1995] | Training loss: 0.148\n",
            "Epoch: [2/2] | Iterations: [73/1995] | Training loss: 0.158\n",
            "Epoch: [2/2] | Iterations: [74/1995] | Training loss: 0.120\n",
            "Epoch: [2/2] | Iterations: [75/1995] | Training loss: 0.130\n",
            "Epoch: [2/2] | Iterations: [76/1995] | Training loss: 0.096\n",
            "Epoch: [2/2] | Iterations: [77/1995] | Training loss: 0.204\n",
            "Epoch: [2/2] | Iterations: [78/1995] | Training loss: 0.104\n",
            "Epoch: [2/2] | Iterations: [79/1995] | Training loss: 0.087\n",
            "Epoch: [2/2] | Iterations: [80/1995] | Training loss: 0.128\n",
            "Epoch: [2/2] | Iterations: [81/1995] | Training loss: 0.180\n",
            "Epoch: [2/2] | Iterations: [82/1995] | Training loss: 0.098\n",
            "Epoch: [2/2] | Iterations: [83/1995] | Training loss: 0.160\n",
            "Epoch: [2/2] | Iterations: [84/1995] | Training loss: 0.121\n",
            "Epoch: [2/2] | Iterations: [85/1995] | Training loss: 0.151\n",
            "Epoch: [2/2] | Iterations: [86/1995] | Training loss: 0.127\n",
            "Epoch: [2/2] | Iterations: [87/1995] | Training loss: 0.131\n",
            "Epoch: [2/2] | Iterations: [88/1995] | Training loss: 0.074\n",
            "Epoch: [2/2] | Iterations: [89/1995] | Training loss: 0.102\n",
            "Epoch: [2/2] | Iterations: [90/1995] | Training loss: 0.051\n",
            "Epoch: [2/2] | Iterations: [91/1995] | Training loss: 0.076\n",
            "Epoch: [2/2] | Iterations: [92/1995] | Training loss: 0.167\n",
            "Epoch: [2/2] | Iterations: [93/1995] | Training loss: 0.185\n",
            "Epoch: [2/2] | Iterations: [94/1995] | Training loss: 0.138\n",
            "Epoch: [2/2] | Iterations: [95/1995] | Training loss: 0.107\n",
            "Epoch: [2/2] | Iterations: [96/1995] | Training loss: 0.084\n",
            "Epoch: [2/2] | Iterations: [97/1995] | Training loss: 0.053\n",
            "Epoch: [2/2] | Iterations: [98/1995] | Training loss: 0.087\n",
            "Epoch: [2/2] | Iterations: [99/1995] | Training loss: 0.135\n",
            "Epoch: [2/2] | Iterations: [100/1995] | Training loss: 0.143\n",
            "Epoch: [2/2] | Iterations: [101/1995] | Training loss: 0.073\n",
            "Epoch: [2/2] | Iterations: [102/1995] | Training loss: 0.122\n",
            "Epoch: [2/2] | Iterations: [103/1995] | Training loss: 0.152\n",
            "Epoch: [2/2] | Iterations: [104/1995] | Training loss: 0.208\n",
            "Epoch: [2/2] | Iterations: [105/1995] | Training loss: 0.133\n",
            "Epoch: [2/2] | Iterations: [106/1995] | Training loss: 0.163\n",
            "Epoch: [2/2] | Iterations: [107/1995] | Training loss: 0.083\n",
            "Epoch: [2/2] | Iterations: [108/1995] | Training loss: 0.140\n",
            "Epoch: [2/2] | Iterations: [109/1995] | Training loss: 0.151\n",
            "Epoch: [2/2] | Iterations: [110/1995] | Training loss: 0.143\n",
            "Epoch: [2/2] | Iterations: [111/1995] | Training loss: 0.130\n",
            "Epoch: [2/2] | Iterations: [112/1995] | Training loss: 0.169\n",
            "Epoch: [2/2] | Iterations: [113/1995] | Training loss: 0.157\n",
            "Epoch: [2/2] | Iterations: [114/1995] | Training loss: 0.052\n",
            "Epoch: [2/2] | Iterations: [115/1995] | Training loss: 0.097\n",
            "Epoch: [2/2] | Iterations: [116/1995] | Training loss: 0.080\n",
            "Epoch: [2/2] | Iterations: [117/1995] | Training loss: 0.120\n",
            "Epoch: [2/2] | Iterations: [118/1995] | Training loss: 0.087\n",
            "Epoch: [2/2] | Iterations: [119/1995] | Training loss: 0.105\n",
            "Epoch: [2/2] | Iterations: [120/1995] | Training loss: 0.107\n",
            "Epoch: [2/2] | Iterations: [121/1995] | Training loss: 0.115\n",
            "Epoch: [2/2] | Iterations: [122/1995] | Training loss: 0.054\n",
            "Epoch: [2/2] | Iterations: [123/1995] | Training loss: 0.084\n",
            "Epoch: [2/2] | Iterations: [124/1995] | Training loss: 0.106\n",
            "Epoch: [2/2] | Iterations: [125/1995] | Training loss: 0.069\n",
            "Epoch: [2/2] | Iterations: [126/1995] | Training loss: 0.121\n",
            "Epoch: [2/2] | Iterations: [127/1995] | Training loss: 0.128\n",
            "Epoch: [2/2] | Iterations: [128/1995] | Training loss: 0.129\n",
            "Epoch: [2/2] | Iterations: [129/1995] | Training loss: 0.074\n",
            "Epoch: [2/2] | Iterations: [130/1995] | Training loss: 0.171\n",
            "Epoch: [2/2] | Iterations: [131/1995] | Training loss: 0.111\n",
            "Epoch: [2/2] | Iterations: [132/1995] | Training loss: 0.090\n",
            "Epoch: [2/2] | Iterations: [133/1995] | Training loss: 0.103\n",
            "Epoch: [2/2] | Iterations: [134/1995] | Training loss: 0.073\n",
            "Epoch: [2/2] | Iterations: [135/1995] | Training loss: 0.078\n",
            "Epoch: [2/2] | Iterations: [136/1995] | Training loss: 0.117\n",
            "Epoch: [2/2] | Iterations: [137/1995] | Training loss: 0.070\n",
            "Epoch: [2/2] | Iterations: [138/1995] | Training loss: 0.128\n",
            "Epoch: [2/2] | Iterations: [139/1995] | Training loss: 0.090\n",
            "Epoch: [2/2] | Iterations: [140/1995] | Training loss: 0.092\n",
            "Epoch: [2/2] | Iterations: [141/1995] | Training loss: 0.049\n",
            "Epoch: [2/2] | Iterations: [142/1995] | Training loss: 0.064\n",
            "Epoch: [2/2] | Iterations: [143/1995] | Training loss: 0.198\n",
            "Epoch: [2/2] | Iterations: [144/1995] | Training loss: 0.113\n",
            "Epoch: [2/2] | Iterations: [145/1995] | Training loss: 0.050\n",
            "Epoch: [2/2] | Iterations: [146/1995] | Training loss: 0.081\n",
            "Epoch: [2/2] | Iterations: [147/1995] | Training loss: 0.060\n",
            "Epoch: [2/2] | Iterations: [148/1995] | Training loss: 0.088\n",
            "Epoch: [2/2] | Iterations: [149/1995] | Training loss: 0.104\n",
            "Epoch: [2/2] | Iterations: [150/1995] | Training loss: 0.063\n",
            "Epoch: [2/2] | Iterations: [151/1995] | Training loss: 0.078\n",
            "Epoch: [2/2] | Iterations: [152/1995] | Training loss: 0.099\n",
            "Epoch: [2/2] | Iterations: [153/1995] | Training loss: 0.077\n",
            "Epoch: [2/2] | Iterations: [154/1995] | Training loss: 0.139\n",
            "Epoch: [2/2] | Iterations: [155/1995] | Training loss: 0.130\n",
            "Epoch: [2/2] | Iterations: [156/1995] | Training loss: 0.107\n",
            "Epoch: [2/2] | Iterations: [157/1995] | Training loss: 0.078\n",
            "Epoch: [2/2] | Iterations: [158/1995] | Training loss: 0.119\n",
            "Epoch: [2/2] | Iterations: [159/1995] | Training loss: 0.089\n",
            "Epoch: [2/2] | Iterations: [160/1995] | Training loss: 0.081\n",
            "Epoch: [2/2] | Iterations: [161/1995] | Training loss: 0.085\n",
            "Epoch: [2/2] | Iterations: [162/1995] | Training loss: 0.078\n",
            "Epoch: [2/2] | Iterations: [163/1995] | Training loss: 0.108\n",
            "Epoch: [2/2] | Iterations: [164/1995] | Training loss: 0.100\n",
            "Epoch: [2/2] | Iterations: [165/1995] | Training loss: 0.087\n",
            "Epoch: [2/2] | Iterations: [166/1995] | Training loss: 0.109\n",
            "Epoch: [2/2] | Iterations: [167/1995] | Training loss: 0.188\n",
            "Epoch: [2/2] | Iterations: [168/1995] | Training loss: 0.068\n",
            "Epoch: [2/2] | Iterations: [169/1995] | Training loss: 0.130\n",
            "Epoch: [2/2] | Iterations: [170/1995] | Training loss: 0.153\n",
            "Epoch: [2/2] | Iterations: [171/1995] | Training loss: 0.157\n",
            "Epoch: [2/2] | Iterations: [172/1995] | Training loss: 0.114\n",
            "Epoch: [2/2] | Iterations: [173/1995] | Training loss: 0.169\n",
            "Epoch: [2/2] | Iterations: [174/1995] | Training loss: 0.070\n",
            "Epoch: [2/2] | Iterations: [175/1995] | Training loss: 0.108\n",
            "Epoch: [2/2] | Iterations: [176/1995] | Training loss: 0.121\n",
            "Epoch: [2/2] | Iterations: [177/1995] | Training loss: 0.126\n",
            "Epoch: [2/2] | Iterations: [178/1995] | Training loss: 0.078\n",
            "Epoch: [2/2] | Iterations: [179/1995] | Training loss: 0.114\n",
            "Epoch: [2/2] | Iterations: [180/1995] | Training loss: 0.076\n",
            "Epoch: [2/2] | Iterations: [181/1995] | Training loss: 0.149\n",
            "Epoch: [2/2] | Iterations: [182/1995] | Training loss: 0.086\n",
            "Epoch: [2/2] | Iterations: [183/1995] | Training loss: 0.089\n",
            "Epoch: [2/2] | Iterations: [184/1995] | Training loss: 0.129\n",
            "Epoch: [2/2] | Iterations: [185/1995] | Training loss: 0.049\n",
            "Epoch: [2/2] | Iterations: [186/1995] | Training loss: 0.142\n",
            "Epoch: [2/2] | Iterations: [187/1995] | Training loss: 0.124\n",
            "Epoch: [2/2] | Iterations: [188/1995] | Training loss: 0.109\n",
            "Epoch: [2/2] | Iterations: [189/1995] | Training loss: 0.078\n",
            "Epoch: [2/2] | Iterations: [190/1995] | Training loss: 0.069\n",
            "Epoch: [2/2] | Iterations: [191/1995] | Training loss: 0.217\n",
            "Epoch: [2/2] | Iterations: [192/1995] | Training loss: 0.087\n",
            "Epoch: [2/2] | Iterations: [193/1995] | Training loss: 0.128\n",
            "Epoch: [2/2] | Iterations: [194/1995] | Training loss: 0.090\n",
            "Epoch: [2/2] | Iterations: [195/1995] | Training loss: 0.095\n",
            "Epoch: [2/2] | Iterations: [196/1995] | Training loss: 0.121\n",
            "Epoch: [2/2] | Iterations: [197/1995] | Training loss: 0.044\n",
            "Epoch: [2/2] | Iterations: [198/1995] | Training loss: 0.130\n",
            "Epoch: [2/2] | Iterations: [199/1995] | Training loss: 0.051\n",
            "Epoch: [2/2] | Iterations: [200/1995] | Training loss: 0.055\n",
            "Epoch: [2/2] | Iterations: [201/1995] | Training loss: 0.100\n",
            "Epoch: [2/2] | Iterations: [202/1995] | Training loss: 0.098\n",
            "Epoch: [2/2] | Iterations: [203/1995] | Training loss: 0.128\n",
            "Epoch: [2/2] | Iterations: [204/1995] | Training loss: 0.100\n",
            "Epoch: [2/2] | Iterations: [205/1995] | Training loss: 0.108\n",
            "Epoch: [2/2] | Iterations: [206/1995] | Training loss: 0.123\n",
            "Epoch: [2/2] | Iterations: [207/1995] | Training loss: 0.095\n",
            "Epoch: [2/2] | Iterations: [208/1995] | Training loss: 0.097\n",
            "Epoch: [2/2] | Iterations: [209/1995] | Training loss: 0.074\n",
            "Epoch: [2/2] | Iterations: [210/1995] | Training loss: 0.097\n",
            "Epoch: [2/2] | Iterations: [211/1995] | Training loss: 0.063\n",
            "Epoch: [2/2] | Iterations: [212/1995] | Training loss: 0.151\n",
            "Epoch: [2/2] | Iterations: [213/1995] | Training loss: 0.118\n",
            "Epoch: [2/2] | Iterations: [214/1995] | Training loss: 0.160\n",
            "Epoch: [2/2] | Iterations: [215/1995] | Training loss: 0.064\n",
            "Epoch: [2/2] | Iterations: [216/1995] | Training loss: 0.056\n",
            "Epoch: [2/2] | Iterations: [217/1995] | Training loss: 0.084\n",
            "Epoch: [2/2] | Iterations: [218/1995] | Training loss: 0.085\n",
            "Epoch: [2/2] | Iterations: [219/1995] | Training loss: 0.102\n",
            "Epoch: [2/2] | Iterations: [220/1995] | Training loss: 0.201\n",
            "Epoch: [2/2] | Iterations: [221/1995] | Training loss: 0.136\n",
            "Epoch: [2/2] | Iterations: [222/1995] | Training loss: 0.086\n",
            "Epoch: [2/2] | Iterations: [223/1995] | Training loss: 0.126\n",
            "Epoch: [2/2] | Iterations: [224/1995] | Training loss: 0.119\n",
            "Epoch: [2/2] | Iterations: [225/1995] | Training loss: 0.083\n",
            "Epoch: [2/2] | Iterations: [226/1995] | Training loss: 0.097\n",
            "Epoch: [2/2] | Iterations: [227/1995] | Training loss: 0.189\n",
            "Epoch: [2/2] | Iterations: [228/1995] | Training loss: 0.084\n",
            "Epoch: [2/2] | Iterations: [229/1995] | Training loss: 0.112\n",
            "Epoch: [2/2] | Iterations: [230/1995] | Training loss: 0.077\n",
            "Epoch: [2/2] | Iterations: [231/1995] | Training loss: 0.098\n",
            "Epoch: [2/2] | Iterations: [232/1995] | Training loss: 0.063\n",
            "Epoch: [2/2] | Iterations: [233/1995] | Training loss: 0.084\n",
            "Epoch: [2/2] | Iterations: [234/1995] | Training loss: 0.101\n",
            "Epoch: [2/2] | Iterations: [235/1995] | Training loss: 0.119\n",
            "Epoch: [2/2] | Iterations: [236/1995] | Training loss: 0.063\n",
            "Epoch: [2/2] | Iterations: [237/1995] | Training loss: 0.095\n",
            "Epoch: [2/2] | Iterations: [238/1995] | Training loss: 0.131\n",
            "Epoch: [2/2] | Iterations: [239/1995] | Training loss: 0.096\n",
            "Epoch: [2/2] | Iterations: [240/1995] | Training loss: 0.124\n",
            "Epoch: [2/2] | Iterations: [241/1995] | Training loss: 0.127\n",
            "Epoch: [2/2] | Iterations: [242/1995] | Training loss: 0.062\n",
            "Epoch: [2/2] | Iterations: [243/1995] | Training loss: 0.141\n",
            "Epoch: [2/2] | Iterations: [244/1995] | Training loss: 0.105\n",
            "Epoch: [2/2] | Iterations: [245/1995] | Training loss: 0.129\n",
            "Epoch: [2/2] | Iterations: [246/1995] | Training loss: 0.083\n",
            "Epoch: [2/2] | Iterations: [247/1995] | Training loss: 0.082\n",
            "Epoch: [2/2] | Iterations: [248/1995] | Training loss: 0.157\n",
            "Epoch: [2/2] | Iterations: [249/1995] | Training loss: 0.089\n",
            "Epoch: [2/2] | Iterations: [250/1995] | Training loss: 0.103\n",
            "Epoch: [2/2] | Iterations: [251/1995] | Training loss: 0.147\n",
            "Epoch: [2/2] | Iterations: [252/1995] | Training loss: 0.115\n",
            "Epoch: [2/2] | Iterations: [253/1995] | Training loss: 0.175\n",
            "Epoch: [2/2] | Iterations: [254/1995] | Training loss: 0.148\n",
            "Epoch: [2/2] | Iterations: [255/1995] | Training loss: 0.093\n",
            "Epoch: [2/2] | Iterations: [256/1995] | Training loss: 0.074\n",
            "Epoch: [2/2] | Iterations: [257/1995] | Training loss: 0.114\n",
            "Epoch: [2/2] | Iterations: [258/1995] | Training loss: 0.143\n",
            "Epoch: [2/2] | Iterations: [259/1995] | Training loss: 0.158\n",
            "Epoch: [2/2] | Iterations: [260/1995] | Training loss: 0.130\n",
            "Epoch: [2/2] | Iterations: [261/1995] | Training loss: 0.113\n",
            "Epoch: [2/2] | Iterations: [262/1995] | Training loss: 0.109\n",
            "Epoch: [2/2] | Iterations: [263/1995] | Training loss: 0.113\n",
            "Epoch: [2/2] | Iterations: [264/1995] | Training loss: 0.129\n",
            "Epoch: [2/2] | Iterations: [265/1995] | Training loss: 0.134\n",
            "Epoch: [2/2] | Iterations: [266/1995] | Training loss: 0.145\n",
            "Epoch: [2/2] | Iterations: [267/1995] | Training loss: 0.099\n",
            "Epoch: [2/2] | Iterations: [268/1995] | Training loss: 0.084\n",
            "Epoch: [2/2] | Iterations: [269/1995] | Training loss: 0.126\n",
            "Epoch: [2/2] | Iterations: [270/1995] | Training loss: 0.067\n",
            "Epoch: [2/2] | Iterations: [271/1995] | Training loss: 0.083\n",
            "Epoch: [2/2] | Iterations: [272/1995] | Training loss: 0.095\n",
            "Epoch: [2/2] | Iterations: [273/1995] | Training loss: 0.086\n",
            "Epoch: [2/2] | Iterations: [274/1995] | Training loss: 0.126\n",
            "Epoch: [2/2] | Iterations: [275/1995] | Training loss: 0.064\n",
            "Epoch: [2/2] | Iterations: [276/1995] | Training loss: 0.095\n",
            "Epoch: [2/2] | Iterations: [277/1995] | Training loss: 0.125\n",
            "Epoch: [2/2] | Iterations: [278/1995] | Training loss: 0.113\n",
            "Epoch: [2/2] | Iterations: [279/1995] | Training loss: 0.092\n",
            "Epoch: [2/2] | Iterations: [280/1995] | Training loss: 0.164\n",
            "Epoch: [2/2] | Iterations: [281/1995] | Training loss: 0.117\n",
            "Epoch: [2/2] | Iterations: [282/1995] | Training loss: 0.136\n",
            "Epoch: [2/2] | Iterations: [283/1995] | Training loss: 0.158\n",
            "Epoch: [2/2] | Iterations: [284/1995] | Training loss: 0.077\n",
            "Epoch: [2/2] | Iterations: [285/1995] | Training loss: 0.139\n",
            "Epoch: [2/2] | Iterations: [286/1995] | Training loss: 0.059\n",
            "Epoch: [2/2] | Iterations: [287/1995] | Training loss: 0.090\n",
            "Epoch: [2/2] | Iterations: [288/1995] | Training loss: 0.094\n",
            "Epoch: [2/2] | Iterations: [289/1995] | Training loss: 0.151\n",
            "Epoch: [2/2] | Iterations: [290/1995] | Training loss: 0.139\n",
            "Epoch: [2/2] | Iterations: [291/1995] | Training loss: 0.115\n",
            "Epoch: [2/2] | Iterations: [292/1995] | Training loss: 0.063\n",
            "Epoch: [2/2] | Iterations: [293/1995] | Training loss: 0.098\n",
            "Epoch: [2/2] | Iterations: [294/1995] | Training loss: 0.118\n",
            "Epoch: [2/2] | Iterations: [295/1995] | Training loss: 0.078\n",
            "Epoch: [2/2] | Iterations: [296/1995] | Training loss: 0.083\n",
            "Epoch: [2/2] | Iterations: [297/1995] | Training loss: 0.107\n",
            "Epoch: [2/2] | Iterations: [298/1995] | Training loss: 0.071\n",
            "Epoch: [2/2] | Iterations: [299/1995] | Training loss: 0.073\n",
            "Epoch: [2/2] | Iterations: [300/1995] | Training loss: 0.074\n",
            "Epoch: [2/2] | Iterations: [301/1995] | Training loss: 0.081\n",
            "Epoch: [2/2] | Iterations: [302/1995] | Training loss: 0.048\n",
            "Epoch: [2/2] | Iterations: [303/1995] | Training loss: 0.039\n",
            "Epoch: [2/2] | Iterations: [304/1995] | Training loss: 0.097\n",
            "Epoch: [2/2] | Iterations: [305/1995] | Training loss: 0.078\n",
            "Epoch: [2/2] | Iterations: [306/1995] | Training loss: 0.086\n",
            "Epoch: [2/2] | Iterations: [307/1995] | Training loss: 0.096\n",
            "Epoch: [2/2] | Iterations: [308/1995] | Training loss: 0.105\n",
            "Epoch: [2/2] | Iterations: [309/1995] | Training loss: 0.137\n",
            "Epoch: [2/2] | Iterations: [310/1995] | Training loss: 0.082\n",
            "Epoch: [2/2] | Iterations: [311/1995] | Training loss: 0.106\n",
            "Epoch: [2/2] | Iterations: [312/1995] | Training loss: 0.102\n",
            "Epoch: [2/2] | Iterations: [313/1995] | Training loss: 0.204\n",
            "Epoch: [2/2] | Iterations: [314/1995] | Training loss: 0.132\n",
            "Epoch: [2/2] | Iterations: [315/1995] | Training loss: 0.109\n",
            "Epoch: [2/2] | Iterations: [316/1995] | Training loss: 0.099\n",
            "Epoch: [2/2] | Iterations: [317/1995] | Training loss: 0.049\n",
            "Epoch: [2/2] | Iterations: [318/1995] | Training loss: 0.120\n",
            "Epoch: [2/2] | Iterations: [319/1995] | Training loss: 0.074\n",
            "Epoch: [2/2] | Iterations: [320/1995] | Training loss: 0.066\n",
            "Epoch: [2/2] | Iterations: [321/1995] | Training loss: 0.148\n",
            "Epoch: [2/2] | Iterations: [322/1995] | Training loss: 0.141\n",
            "Epoch: [2/2] | Iterations: [323/1995] | Training loss: 0.148\n",
            "Epoch: [2/2] | Iterations: [324/1995] | Training loss: 0.157\n",
            "Epoch: [2/2] | Iterations: [325/1995] | Training loss: 0.067\n",
            "Epoch: [2/2] | Iterations: [326/1995] | Training loss: 0.102\n",
            "Epoch: [2/2] | Iterations: [327/1995] | Training loss: 0.221\n",
            "Epoch: [2/2] | Iterations: [328/1995] | Training loss: 0.126\n",
            "Epoch: [2/2] | Iterations: [329/1995] | Training loss: 0.094\n",
            "Epoch: [2/2] | Iterations: [330/1995] | Training loss: 0.125\n",
            "Epoch: [2/2] | Iterations: [331/1995] | Training loss: 0.078\n",
            "Epoch: [2/2] | Iterations: [332/1995] | Training loss: 0.108\n",
            "Epoch: [2/2] | Iterations: [333/1995] | Training loss: 0.206\n",
            "Epoch: [2/2] | Iterations: [334/1995] | Training loss: 0.168\n",
            "Epoch: [2/2] | Iterations: [335/1995] | Training loss: 0.095\n",
            "Epoch: [2/2] | Iterations: [336/1995] | Training loss: 0.142\n",
            "Epoch: [2/2] | Iterations: [337/1995] | Training loss: 0.088\n",
            "Epoch: [2/2] | Iterations: [338/1995] | Training loss: 0.098\n",
            "Epoch: [2/2] | Iterations: [339/1995] | Training loss: 0.098\n",
            "Epoch: [2/2] | Iterations: [340/1995] | Training loss: 0.079\n",
            "Epoch: [2/2] | Iterations: [341/1995] | Training loss: 0.070\n",
            "Epoch: [2/2] | Iterations: [342/1995] | Training loss: 0.082\n",
            "Epoch: [2/2] | Iterations: [343/1995] | Training loss: 0.147\n",
            "Epoch: [2/2] | Iterations: [344/1995] | Training loss: 0.105\n",
            "Epoch: [2/2] | Iterations: [345/1995] | Training loss: 0.093\n",
            "Epoch: [2/2] | Iterations: [346/1995] | Training loss: 0.118\n",
            "Epoch: [2/2] | Iterations: [347/1995] | Training loss: 0.132\n",
            "Epoch: [2/2] | Iterations: [348/1995] | Training loss: 0.086\n",
            "Epoch: [2/2] | Iterations: [349/1995] | Training loss: 0.053\n",
            "Epoch: [2/2] | Iterations: [350/1995] | Training loss: 0.111\n",
            "Epoch: [2/2] | Iterations: [351/1995] | Training loss: 0.086\n",
            "Epoch: [2/2] | Iterations: [352/1995] | Training loss: 0.119\n",
            "Epoch: [2/2] | Iterations: [353/1995] | Training loss: 0.135\n",
            "Epoch: [2/2] | Iterations: [354/1995] | Training loss: 0.163\n",
            "Epoch: [2/2] | Iterations: [355/1995] | Training loss: 0.076\n",
            "Epoch: [2/2] | Iterations: [356/1995] | Training loss: 0.099\n",
            "Epoch: [2/2] | Iterations: [357/1995] | Training loss: 0.065\n",
            "Epoch: [2/2] | Iterations: [358/1995] | Training loss: 0.062\n",
            "Epoch: [2/2] | Iterations: [359/1995] | Training loss: 0.044\n",
            "Epoch: [2/2] | Iterations: [360/1995] | Training loss: 0.069\n",
            "Epoch: [2/2] | Iterations: [361/1995] | Training loss: 0.051\n",
            "Epoch: [2/2] | Iterations: [362/1995] | Training loss: 0.155\n",
            "Epoch: [2/2] | Iterations: [363/1995] | Training loss: 0.083\n",
            "Epoch: [2/2] | Iterations: [364/1995] | Training loss: 0.080\n",
            "Epoch: [2/2] | Iterations: [365/1995] | Training loss: 0.142\n",
            "Epoch: [2/2] | Iterations: [366/1995] | Training loss: 0.075\n",
            "Epoch: [2/2] | Iterations: [367/1995] | Training loss: 0.104\n",
            "Epoch: [2/2] | Iterations: [368/1995] | Training loss: 0.130\n",
            "Epoch: [2/2] | Iterations: [369/1995] | Training loss: 0.088\n",
            "Epoch: [2/2] | Iterations: [370/1995] | Training loss: 0.133\n",
            "Epoch: [2/2] | Iterations: [371/1995] | Training loss: 0.078\n",
            "Epoch: [2/2] | Iterations: [372/1995] | Training loss: 0.131\n",
            "Epoch: [2/2] | Iterations: [373/1995] | Training loss: 0.107\n",
            "Epoch: [2/2] | Iterations: [374/1995] | Training loss: 0.142\n",
            "Epoch: [2/2] | Iterations: [375/1995] | Training loss: 0.095\n",
            "Epoch: [2/2] | Iterations: [376/1995] | Training loss: 0.127\n",
            "Epoch: [2/2] | Iterations: [377/1995] | Training loss: 0.140\n",
            "Epoch: [2/2] | Iterations: [378/1995] | Training loss: 0.172\n",
            "Epoch: [2/2] | Iterations: [379/1995] | Training loss: 0.115\n",
            "Epoch: [2/2] | Iterations: [380/1995] | Training loss: 0.147\n",
            "Epoch: [2/2] | Iterations: [381/1995] | Training loss: 0.099\n",
            "Epoch: [2/2] | Iterations: [382/1995] | Training loss: 0.059\n",
            "Epoch: [2/2] | Iterations: [383/1995] | Training loss: 0.163\n",
            "Epoch: [2/2] | Iterations: [384/1995] | Training loss: 0.045\n",
            "Epoch: [2/2] | Iterations: [385/1995] | Training loss: 0.122\n",
            "Epoch: [2/2] | Iterations: [386/1995] | Training loss: 0.042\n",
            "Epoch: [2/2] | Iterations: [387/1995] | Training loss: 0.145\n",
            "Epoch: [2/2] | Iterations: [388/1995] | Training loss: 0.061\n",
            "Epoch: [2/2] | Iterations: [389/1995] | Training loss: 0.085\n",
            "Epoch: [2/2] | Iterations: [390/1995] | Training loss: 0.053\n",
            "Epoch: [2/2] | Iterations: [391/1995] | Training loss: 0.131\n",
            "Epoch: [2/2] | Iterations: [392/1995] | Training loss: 0.047\n",
            "Epoch: [2/2] | Iterations: [393/1995] | Training loss: 0.086\n",
            "Epoch: [2/2] | Iterations: [394/1995] | Training loss: 0.105\n",
            "Epoch: [2/2] | Iterations: [395/1995] | Training loss: 0.144\n",
            "Epoch: [2/2] | Iterations: [396/1995] | Training loss: 0.099\n",
            "Epoch: [2/2] | Iterations: [397/1995] | Training loss: 0.074\n",
            "Epoch: [2/2] | Iterations: [398/1995] | Training loss: 0.094\n",
            "Epoch: [2/2] | Iterations: [399/1995] | Training loss: 0.073\n",
            "Epoch: [2/2] | Iterations: [400/1995] | Training loss: 0.183\n",
            "Epoch: [2/2] | Iterations: [401/1995] | Training loss: 0.119\n",
            "Epoch: [2/2] | Iterations: [402/1995] | Training loss: 0.133\n",
            "Epoch: [2/2] | Iterations: [403/1995] | Training loss: 0.173\n",
            "Epoch: [2/2] | Iterations: [404/1995] | Training loss: 0.146\n",
            "Epoch: [2/2] | Iterations: [405/1995] | Training loss: 0.151\n",
            "Epoch: [2/2] | Iterations: [406/1995] | Training loss: 0.055\n",
            "Epoch: [2/2] | Iterations: [407/1995] | Training loss: 0.125\n",
            "Epoch: [2/2] | Iterations: [408/1995] | Training loss: 0.146\n",
            "Epoch: [2/2] | Iterations: [409/1995] | Training loss: 0.121\n",
            "Epoch: [2/2] | Iterations: [410/1995] | Training loss: 0.065\n",
            "Epoch: [2/2] | Iterations: [411/1995] | Training loss: 0.104\n",
            "Epoch: [2/2] | Iterations: [412/1995] | Training loss: 0.058\n",
            "Epoch: [2/2] | Iterations: [413/1995] | Training loss: 0.169\n",
            "Epoch: [2/2] | Iterations: [414/1995] | Training loss: 0.110\n",
            "Epoch: [2/2] | Iterations: [415/1995] | Training loss: 0.076\n",
            "Epoch: [2/2] | Iterations: [416/1995] | Training loss: 0.091\n",
            "Epoch: [2/2] | Iterations: [417/1995] | Training loss: 0.080\n",
            "Epoch: [2/2] | Iterations: [418/1995] | Training loss: 0.059\n",
            "Epoch: [2/2] | Iterations: [419/1995] | Training loss: 0.119\n",
            "Epoch: [2/2] | Iterations: [420/1995] | Training loss: 0.123\n",
            "Epoch: [2/2] | Iterations: [421/1995] | Training loss: 0.142\n",
            "Epoch: [2/2] | Iterations: [422/1995] | Training loss: 0.113\n",
            "Epoch: [2/2] | Iterations: [423/1995] | Training loss: 0.169\n",
            "Epoch: [2/2] | Iterations: [424/1995] | Training loss: 0.113\n",
            "Epoch: [2/2] | Iterations: [425/1995] | Training loss: 0.107\n",
            "Epoch: [2/2] | Iterations: [426/1995] | Training loss: 0.097\n",
            "Epoch: [2/2] | Iterations: [427/1995] | Training loss: 0.120\n",
            "Epoch: [2/2] | Iterations: [428/1995] | Training loss: 0.119\n",
            "Epoch: [2/2] | Iterations: [429/1995] | Training loss: 0.149\n",
            "Epoch: [2/2] | Iterations: [430/1995] | Training loss: 0.074\n",
            "Epoch: [2/2] | Iterations: [431/1995] | Training loss: 0.095\n",
            "Epoch: [2/2] | Iterations: [432/1995] | Training loss: 0.154\n",
            "Epoch: [2/2] | Iterations: [433/1995] | Training loss: 0.089\n",
            "Epoch: [2/2] | Iterations: [434/1995] | Training loss: 0.069\n",
            "Epoch: [2/2] | Iterations: [435/1995] | Training loss: 0.100\n",
            "Epoch: [2/2] | Iterations: [436/1995] | Training loss: 0.073\n",
            "Epoch: [2/2] | Iterations: [437/1995] | Training loss: 0.118\n",
            "Epoch: [2/2] | Iterations: [438/1995] | Training loss: 0.113\n",
            "Epoch: [2/2] | Iterations: [439/1995] | Training loss: 0.108\n",
            "Epoch: [2/2] | Iterations: [440/1995] | Training loss: 0.091\n",
            "Epoch: [2/2] | Iterations: [441/1995] | Training loss: 0.114\n",
            "Epoch: [2/2] | Iterations: [442/1995] | Training loss: 0.144\n",
            "Epoch: [2/2] | Iterations: [443/1995] | Training loss: 0.166\n",
            "Epoch: [2/2] | Iterations: [444/1995] | Training loss: 0.083\n",
            "Epoch: [2/2] | Iterations: [445/1995] | Training loss: 0.148\n",
            "Epoch: [2/2] | Iterations: [446/1995] | Training loss: 0.131\n",
            "Epoch: [2/2] | Iterations: [447/1995] | Training loss: 0.159\n",
            "Epoch: [2/2] | Iterations: [448/1995] | Training loss: 0.067\n",
            "Epoch: [2/2] | Iterations: [449/1995] | Training loss: 0.136\n",
            "Epoch: [2/2] | Iterations: [450/1995] | Training loss: 0.072\n",
            "Epoch: [2/2] | Iterations: [451/1995] | Training loss: 0.131\n",
            "Epoch: [2/2] | Iterations: [452/1995] | Training loss: 0.105\n",
            "Epoch: [2/2] | Iterations: [453/1995] | Training loss: 0.065\n",
            "Epoch: [2/2] | Iterations: [454/1995] | Training loss: 0.073\n",
            "Epoch: [2/2] | Iterations: [455/1995] | Training loss: 0.121\n",
            "Epoch: [2/2] | Iterations: [456/1995] | Training loss: 0.105\n",
            "Epoch: [2/2] | Iterations: [457/1995] | Training loss: 0.088\n",
            "Epoch: [2/2] | Iterations: [458/1995] | Training loss: 0.069\n",
            "Epoch: [2/2] | Iterations: [459/1995] | Training loss: 0.115\n",
            "Epoch: [2/2] | Iterations: [460/1995] | Training loss: 0.191\n",
            "Epoch: [2/2] | Iterations: [461/1995] | Training loss: 0.153\n",
            "Epoch: [2/2] | Iterations: [462/1995] | Training loss: 0.086\n",
            "Epoch: [2/2] | Iterations: [463/1995] | Training loss: 0.068\n",
            "Epoch: [2/2] | Iterations: [464/1995] | Training loss: 0.092\n",
            "Epoch: [2/2] | Iterations: [465/1995] | Training loss: 0.151\n",
            "Epoch: [2/2] | Iterations: [466/1995] | Training loss: 0.089\n",
            "Epoch: [2/2] | Iterations: [467/1995] | Training loss: 0.107\n",
            "Epoch: [2/2] | Iterations: [468/1995] | Training loss: 0.047\n",
            "Epoch: [2/2] | Iterations: [469/1995] | Training loss: 0.117\n",
            "Epoch: [2/2] | Iterations: [470/1995] | Training loss: 0.118\n",
            "Epoch: [2/2] | Iterations: [471/1995] | Training loss: 0.101\n",
            "Epoch: [2/2] | Iterations: [472/1995] | Training loss: 0.136\n",
            "Epoch: [2/2] | Iterations: [473/1995] | Training loss: 0.140\n",
            "Epoch: [2/2] | Iterations: [474/1995] | Training loss: 0.071\n",
            "Epoch: [2/2] | Iterations: [475/1995] | Training loss: 0.086\n",
            "Epoch: [2/2] | Iterations: [476/1995] | Training loss: 0.063\n",
            "Epoch: [2/2] | Iterations: [477/1995] | Training loss: 0.158\n",
            "Epoch: [2/2] | Iterations: [478/1995] | Training loss: 0.069\n",
            "Epoch: [2/2] | Iterations: [479/1995] | Training loss: 0.133\n",
            "Epoch: [2/2] | Iterations: [480/1995] | Training loss: 0.053\n",
            "Epoch: [2/2] | Iterations: [481/1995] | Training loss: 0.112\n",
            "Epoch: [2/2] | Iterations: [482/1995] | Training loss: 0.182\n",
            "Epoch: [2/2] | Iterations: [483/1995] | Training loss: 0.146\n",
            "Epoch: [2/2] | Iterations: [484/1995] | Training loss: 0.243\n",
            "Epoch: [2/2] | Iterations: [485/1995] | Training loss: 0.092\n",
            "Epoch: [2/2] | Iterations: [486/1995] | Training loss: 0.148\n",
            "Epoch: [2/2] | Iterations: [487/1995] | Training loss: 0.116\n",
            "Epoch: [2/2] | Iterations: [488/1995] | Training loss: 0.149\n",
            "Epoch: [2/2] | Iterations: [489/1995] | Training loss: 0.079\n",
            "Epoch: [2/2] | Iterations: [490/1995] | Training loss: 0.045\n",
            "Epoch: [2/2] | Iterations: [491/1995] | Training loss: 0.116\n",
            "Epoch: [2/2] | Iterations: [492/1995] | Training loss: 0.141\n",
            "Epoch: [2/2] | Iterations: [493/1995] | Training loss: 0.157\n",
            "Epoch: [2/2] | Iterations: [494/1995] | Training loss: 0.091\n",
            "Epoch: [2/2] | Iterations: [495/1995] | Training loss: 0.082\n",
            "Epoch: [2/2] | Iterations: [496/1995] | Training loss: 0.155\n",
            "Epoch: [2/2] | Iterations: [497/1995] | Training loss: 0.073\n",
            "Epoch: [2/2] | Iterations: [498/1995] | Training loss: 0.069\n",
            "Epoch: [2/2] | Iterations: [499/1995] | Training loss: 0.079\n",
            "Epoch: [2/2] | Iterations: [500/1995] | Training loss: 0.087\n",
            "Epoch: [2/2] | Iterations: [501/1995] | Training loss: 0.068\n",
            "Epoch: [2/2] | Iterations: [502/1995] | Training loss: 0.090\n",
            "Epoch: [2/2] | Iterations: [503/1995] | Training loss: 0.125\n",
            "Epoch: [2/2] | Iterations: [504/1995] | Training loss: 0.029\n",
            "Epoch: [2/2] | Iterations: [505/1995] | Training loss: 0.104\n",
            "Epoch: [2/2] | Iterations: [506/1995] | Training loss: 0.097\n",
            "Epoch: [2/2] | Iterations: [507/1995] | Training loss: 0.105\n",
            "Epoch: [2/2] | Iterations: [508/1995] | Training loss: 0.086\n",
            "Epoch: [2/2] | Iterations: [509/1995] | Training loss: 0.079\n",
            "Epoch: [2/2] | Iterations: [510/1995] | Training loss: 0.081\n",
            "Epoch: [2/2] | Iterations: [511/1995] | Training loss: 0.093\n",
            "Epoch: [2/2] | Iterations: [512/1995] | Training loss: 0.101\n",
            "Epoch: [2/2] | Iterations: [513/1995] | Training loss: 0.171\n",
            "Epoch: [2/2] | Iterations: [514/1995] | Training loss: 0.141\n",
            "Epoch: [2/2] | Iterations: [515/1995] | Training loss: 0.095\n",
            "Epoch: [2/2] | Iterations: [516/1995] | Training loss: 0.144\n",
            "Epoch: [2/2] | Iterations: [517/1995] | Training loss: 0.118\n",
            "Epoch: [2/2] | Iterations: [518/1995] | Training loss: 0.071\n",
            "Epoch: [2/2] | Iterations: [519/1995] | Training loss: 0.109\n",
            "Epoch: [2/2] | Iterations: [520/1995] | Training loss: 0.143\n",
            "Epoch: [2/2] | Iterations: [521/1995] | Training loss: 0.096\n",
            "Epoch: [2/2] | Iterations: [522/1995] | Training loss: 0.131\n",
            "Epoch: [2/2] | Iterations: [523/1995] | Training loss: 0.079\n",
            "Epoch: [2/2] | Iterations: [524/1995] | Training loss: 0.059\n",
            "Epoch: [2/2] | Iterations: [525/1995] | Training loss: 0.077\n",
            "Epoch: [2/2] | Iterations: [526/1995] | Training loss: 0.152\n",
            "Epoch: [2/2] | Iterations: [527/1995] | Training loss: 0.101\n",
            "Epoch: [2/2] | Iterations: [528/1995] | Training loss: 0.072\n",
            "Epoch: [2/2] | Iterations: [529/1995] | Training loss: 0.138\n",
            "Epoch: [2/2] | Iterations: [530/1995] | Training loss: 0.192\n",
            "Epoch: [2/2] | Iterations: [531/1995] | Training loss: 0.114\n",
            "Epoch: [2/2] | Iterations: [532/1995] | Training loss: 0.119\n",
            "Epoch: [2/2] | Iterations: [533/1995] | Training loss: 0.158\n",
            "Epoch: [2/2] | Iterations: [534/1995] | Training loss: 0.093\n",
            "Epoch: [2/2] | Iterations: [535/1995] | Training loss: 0.054\n",
            "Epoch: [2/2] | Iterations: [536/1995] | Training loss: 0.083\n",
            "Epoch: [2/2] | Iterations: [537/1995] | Training loss: 0.035\n",
            "Epoch: [2/2] | Iterations: [538/1995] | Training loss: 0.077\n",
            "Epoch: [2/2] | Iterations: [539/1995] | Training loss: 0.071\n",
            "Epoch: [2/2] | Iterations: [540/1995] | Training loss: 0.098\n",
            "Epoch: [2/2] | Iterations: [541/1995] | Training loss: 0.086\n",
            "Epoch: [2/2] | Iterations: [542/1995] | Training loss: 0.117\n",
            "Epoch: [2/2] | Iterations: [543/1995] | Training loss: 0.143\n",
            "Epoch: [2/2] | Iterations: [544/1995] | Training loss: 0.166\n",
            "Epoch: [2/2] | Iterations: [545/1995] | Training loss: 0.165\n",
            "Epoch: [2/2] | Iterations: [546/1995] | Training loss: 0.070\n",
            "Epoch: [2/2] | Iterations: [547/1995] | Training loss: 0.054\n",
            "Epoch: [2/2] | Iterations: [548/1995] | Training loss: 0.089\n",
            "Epoch: [2/2] | Iterations: [549/1995] | Training loss: 0.069\n",
            "Epoch: [2/2] | Iterations: [550/1995] | Training loss: 0.118\n",
            "Epoch: [2/2] | Iterations: [551/1995] | Training loss: 0.079\n",
            "Epoch: [2/2] | Iterations: [552/1995] | Training loss: 0.137\n",
            "Epoch: [2/2] | Iterations: [553/1995] | Training loss: 0.107\n",
            "Epoch: [2/2] | Iterations: [554/1995] | Training loss: 0.103\n",
            "Epoch: [2/2] | Iterations: [555/1995] | Training loss: 0.069\n",
            "Epoch: [2/2] | Iterations: [556/1995] | Training loss: 0.086\n",
            "Epoch: [2/2] | Iterations: [557/1995] | Training loss: 0.090\n",
            "Epoch: [2/2] | Iterations: [558/1995] | Training loss: 0.117\n",
            "Epoch: [2/2] | Iterations: [559/1995] | Training loss: 0.116\n",
            "Epoch: [2/2] | Iterations: [560/1995] | Training loss: 0.101\n",
            "Epoch: [2/2] | Iterations: [561/1995] | Training loss: 0.076\n",
            "Epoch: [2/2] | Iterations: [562/1995] | Training loss: 0.094\n",
            "Epoch: [2/2] | Iterations: [563/1995] | Training loss: 0.115\n",
            "Epoch: [2/2] | Iterations: [564/1995] | Training loss: 0.081\n",
            "Epoch: [2/2] | Iterations: [565/1995] | Training loss: 0.121\n",
            "Epoch: [2/2] | Iterations: [566/1995] | Training loss: 0.101\n",
            "Epoch: [2/2] | Iterations: [567/1995] | Training loss: 0.066\n",
            "Epoch: [2/2] | Iterations: [568/1995] | Training loss: 0.142\n",
            "Epoch: [2/2] | Iterations: [569/1995] | Training loss: 0.053\n",
            "Epoch: [2/2] | Iterations: [570/1995] | Training loss: 0.096\n",
            "Epoch: [2/2] | Iterations: [571/1995] | Training loss: 0.123\n",
            "Epoch: [2/2] | Iterations: [572/1995] | Training loss: 0.115\n",
            "Epoch: [2/2] | Iterations: [573/1995] | Training loss: 0.115\n",
            "Epoch: [2/2] | Iterations: [574/1995] | Training loss: 0.100\n",
            "Epoch: [2/2] | Iterations: [575/1995] | Training loss: 0.145\n",
            "Epoch: [2/2] | Iterations: [576/1995] | Training loss: 0.105\n",
            "Epoch: [2/2] | Iterations: [577/1995] | Training loss: 0.109\n",
            "Epoch: [2/2] | Iterations: [578/1995] | Training loss: 0.111\n",
            "Epoch: [2/2] | Iterations: [579/1995] | Training loss: 0.063\n",
            "Epoch: [2/2] | Iterations: [580/1995] | Training loss: 0.083\n",
            "Epoch: [2/2] | Iterations: [581/1995] | Training loss: 0.099\n",
            "Epoch: [2/2] | Iterations: [582/1995] | Training loss: 0.073\n",
            "Epoch: [2/2] | Iterations: [583/1995] | Training loss: 0.098\n",
            "Epoch: [2/2] | Iterations: [584/1995] | Training loss: 0.057\n",
            "Epoch: [2/2] | Iterations: [585/1995] | Training loss: 0.092\n",
            "Epoch: [2/2] | Iterations: [586/1995] | Training loss: 0.087\n",
            "Epoch: [2/2] | Iterations: [587/1995] | Training loss: 0.141\n",
            "Epoch: [2/2] | Iterations: [588/1995] | Training loss: 0.106\n",
            "Epoch: [2/2] | Iterations: [589/1995] | Training loss: 0.093\n",
            "Epoch: [2/2] | Iterations: [590/1995] | Training loss: 0.081\n",
            "Epoch: [2/2] | Iterations: [591/1995] | Training loss: 0.148\n",
            "Epoch: [2/2] | Iterations: [592/1995] | Training loss: 0.092\n",
            "Epoch: [2/2] | Iterations: [593/1995] | Training loss: 0.066\n",
            "Epoch: [2/2] | Iterations: [594/1995] | Training loss: 0.048\n",
            "Epoch: [2/2] | Iterations: [595/1995] | Training loss: 0.071\n",
            "Epoch: [2/2] | Iterations: [596/1995] | Training loss: 0.092\n",
            "Epoch: [2/2] | Iterations: [597/1995] | Training loss: 0.061\n",
            "Epoch: [2/2] | Iterations: [598/1995] | Training loss: 0.067\n",
            "Epoch: [2/2] | Iterations: [599/1995] | Training loss: 0.075\n",
            "Epoch: [2/2] | Iterations: [600/1995] | Training loss: 0.105\n",
            "Epoch: [2/2] | Iterations: [601/1995] | Training loss: 0.081\n",
            "Epoch: [2/2] | Iterations: [602/1995] | Training loss: 0.091\n",
            "Epoch: [2/2] | Iterations: [603/1995] | Training loss: 0.074\n",
            "Epoch: [2/2] | Iterations: [604/1995] | Training loss: 0.054\n",
            "Epoch: [2/2] | Iterations: [605/1995] | Training loss: 0.100\n",
            "Epoch: [2/2] | Iterations: [606/1995] | Training loss: 0.072\n",
            "Epoch: [2/2] | Iterations: [607/1995] | Training loss: 0.048\n",
            "Epoch: [2/2] | Iterations: [608/1995] | Training loss: 0.087\n",
            "Epoch: [2/2] | Iterations: [609/1995] | Training loss: 0.127\n",
            "Epoch: [2/2] | Iterations: [610/1995] | Training loss: 0.179\n",
            "Epoch: [2/2] | Iterations: [611/1995] | Training loss: 0.076\n",
            "Epoch: [2/2] | Iterations: [612/1995] | Training loss: 0.102\n",
            "Epoch: [2/2] | Iterations: [613/1995] | Training loss: 0.062\n",
            "Epoch: [2/2] | Iterations: [614/1995] | Training loss: 0.119\n",
            "Epoch: [2/2] | Iterations: [615/1995] | Training loss: 0.129\n",
            "Epoch: [2/2] | Iterations: [616/1995] | Training loss: 0.159\n",
            "Epoch: [2/2] | Iterations: [617/1995] | Training loss: 0.122\n",
            "Epoch: [2/2] | Iterations: [618/1995] | Training loss: 0.139\n",
            "Epoch: [2/2] | Iterations: [619/1995] | Training loss: 0.083\n",
            "Epoch: [2/2] | Iterations: [620/1995] | Training loss: 0.081\n",
            "Epoch: [2/2] | Iterations: [621/1995] | Training loss: 0.161\n",
            "Epoch: [2/2] | Iterations: [622/1995] | Training loss: 0.090\n",
            "Epoch: [2/2] | Iterations: [623/1995] | Training loss: 0.122\n",
            "Epoch: [2/2] | Iterations: [624/1995] | Training loss: 0.129\n",
            "Epoch: [2/2] | Iterations: [625/1995] | Training loss: 0.105\n",
            "Epoch: [2/2] | Iterations: [626/1995] | Training loss: 0.069\n",
            "Epoch: [2/2] | Iterations: [627/1995] | Training loss: 0.051\n",
            "Epoch: [2/2] | Iterations: [628/1995] | Training loss: 0.125\n",
            "Epoch: [2/2] | Iterations: [629/1995] | Training loss: 0.094\n",
            "Epoch: [2/2] | Iterations: [630/1995] | Training loss: 0.137\n",
            "Epoch: [2/2] | Iterations: [631/1995] | Training loss: 0.058\n",
            "Epoch: [2/2] | Iterations: [632/1995] | Training loss: 0.055\n",
            "Epoch: [2/2] | Iterations: [633/1995] | Training loss: 0.055\n",
            "Epoch: [2/2] | Iterations: [634/1995] | Training loss: 0.058\n",
            "Epoch: [2/2] | Iterations: [635/1995] | Training loss: 0.131\n",
            "Epoch: [2/2] | Iterations: [636/1995] | Training loss: 0.118\n",
            "Epoch: [2/2] | Iterations: [637/1995] | Training loss: 0.092\n",
            "Epoch: [2/2] | Iterations: [638/1995] | Training loss: 0.055\n",
            "Epoch: [2/2] | Iterations: [639/1995] | Training loss: 0.172\n",
            "Epoch: [2/2] | Iterations: [640/1995] | Training loss: 0.090\n",
            "Epoch: [2/2] | Iterations: [641/1995] | Training loss: 0.092\n",
            "Epoch: [2/2] | Iterations: [642/1995] | Training loss: 0.084\n",
            "Epoch: [2/2] | Iterations: [643/1995] | Training loss: 0.096\n",
            "Epoch: [2/2] | Iterations: [644/1995] | Training loss: 0.067\n",
            "Epoch: [2/2] | Iterations: [645/1995] | Training loss: 0.102\n",
            "Epoch: [2/2] | Iterations: [646/1995] | Training loss: 0.199\n",
            "Epoch: [2/2] | Iterations: [647/1995] | Training loss: 0.121\n",
            "Epoch: [2/2] | Iterations: [648/1995] | Training loss: 0.094\n",
            "Epoch: [2/2] | Iterations: [649/1995] | Training loss: 0.062\n",
            "Epoch: [2/2] | Iterations: [650/1995] | Training loss: 0.103\n",
            "Epoch: [2/2] | Iterations: [651/1995] | Training loss: 0.086\n",
            "Epoch: [2/2] | Iterations: [652/1995] | Training loss: 0.047\n",
            "Epoch: [2/2] | Iterations: [653/1995] | Training loss: 0.199\n",
            "Epoch: [2/2] | Iterations: [654/1995] | Training loss: 0.046\n",
            "Epoch: [2/2] | Iterations: [655/1995] | Training loss: 0.121\n",
            "Epoch: [2/2] | Iterations: [656/1995] | Training loss: 0.100\n",
            "Epoch: [2/2] | Iterations: [657/1995] | Training loss: 0.180\n",
            "Epoch: [2/2] | Iterations: [658/1995] | Training loss: 0.093\n",
            "Epoch: [2/2] | Iterations: [659/1995] | Training loss: 0.137\n",
            "Epoch: [2/2] | Iterations: [660/1995] | Training loss: 0.091\n",
            "Epoch: [2/2] | Iterations: [661/1995] | Training loss: 0.186\n",
            "Epoch: [2/2] | Iterations: [662/1995] | Training loss: 0.068\n",
            "Epoch: [2/2] | Iterations: [663/1995] | Training loss: 0.135\n",
            "Epoch: [2/2] | Iterations: [664/1995] | Training loss: 0.116\n",
            "Epoch: [2/2] | Iterations: [665/1995] | Training loss: 0.116\n",
            "Epoch: [2/2] | Iterations: [666/1995] | Training loss: 0.124\n",
            "Epoch: [2/2] | Iterations: [667/1995] | Training loss: 0.129\n",
            "Epoch: [2/2] | Iterations: [668/1995] | Training loss: 0.081\n",
            "Epoch: [2/2] | Iterations: [669/1995] | Training loss: 0.091\n",
            "Epoch: [2/2] | Iterations: [670/1995] | Training loss: 0.150\n",
            "Epoch: [2/2] | Iterations: [671/1995] | Training loss: 0.099\n",
            "Epoch: [2/2] | Iterations: [672/1995] | Training loss: 0.099\n",
            "Epoch: [2/2] | Iterations: [673/1995] | Training loss: 0.092\n",
            "Epoch: [2/2] | Iterations: [674/1995] | Training loss: 0.124\n",
            "Epoch: [2/2] | Iterations: [675/1995] | Training loss: 0.094\n",
            "Epoch: [2/2] | Iterations: [676/1995] | Training loss: 0.096\n",
            "Epoch: [2/2] | Iterations: [677/1995] | Training loss: 0.136\n",
            "Epoch: [2/2] | Iterations: [678/1995] | Training loss: 0.090\n",
            "Epoch: [2/2] | Iterations: [679/1995] | Training loss: 0.110\n",
            "Epoch: [2/2] | Iterations: [680/1995] | Training loss: 0.078\n",
            "Epoch: [2/2] | Iterations: [681/1995] | Training loss: 0.071\n",
            "Epoch: [2/2] | Iterations: [682/1995] | Training loss: 0.068\n",
            "Epoch: [2/2] | Iterations: [683/1995] | Training loss: 0.091\n",
            "Epoch: [2/2] | Iterations: [684/1995] | Training loss: 0.054\n",
            "Epoch: [2/2] | Iterations: [685/1995] | Training loss: 0.131\n",
            "Epoch: [2/2] | Iterations: [686/1995] | Training loss: 0.103\n",
            "Epoch: [2/2] | Iterations: [687/1995] | Training loss: 0.100\n",
            "Epoch: [2/2] | Iterations: [688/1995] | Training loss: 0.104\n",
            "Epoch: [2/2] | Iterations: [689/1995] | Training loss: 0.129\n",
            "Epoch: [2/2] | Iterations: [690/1995] | Training loss: 0.078\n",
            "Epoch: [2/2] | Iterations: [691/1995] | Training loss: 0.113\n",
            "Epoch: [2/2] | Iterations: [692/1995] | Training loss: 0.154\n",
            "Epoch: [2/2] | Iterations: [693/1995] | Training loss: 0.114\n",
            "Epoch: [2/2] | Iterations: [694/1995] | Training loss: 0.130\n",
            "Epoch: [2/2] | Iterations: [695/1995] | Training loss: 0.044\n",
            "Epoch: [2/2] | Iterations: [696/1995] | Training loss: 0.088\n",
            "Epoch: [2/2] | Iterations: [697/1995] | Training loss: 0.079\n",
            "Epoch: [2/2] | Iterations: [698/1995] | Training loss: 0.124\n",
            "Epoch: [2/2] | Iterations: [699/1995] | Training loss: 0.147\n",
            "Epoch: [2/2] | Iterations: [700/1995] | Training loss: 0.053\n",
            "Epoch: [2/2] | Iterations: [701/1995] | Training loss: 0.082\n",
            "Epoch: [2/2] | Iterations: [702/1995] | Training loss: 0.079\n",
            "Epoch: [2/2] | Iterations: [703/1995] | Training loss: 0.111\n",
            "Epoch: [2/2] | Iterations: [704/1995] | Training loss: 0.094\n",
            "Epoch: [2/2] | Iterations: [705/1995] | Training loss: 0.100\n",
            "Epoch: [2/2] | Iterations: [706/1995] | Training loss: 0.083\n",
            "Epoch: [2/2] | Iterations: [707/1995] | Training loss: 0.092\n",
            "Epoch: [2/2] | Iterations: [708/1995] | Training loss: 0.068\n",
            "Epoch: [2/2] | Iterations: [709/1995] | Training loss: 0.086\n",
            "Epoch: [2/2] | Iterations: [710/1995] | Training loss: 0.121\n",
            "Epoch: [2/2] | Iterations: [711/1995] | Training loss: 0.095\n",
            "Epoch: [2/2] | Iterations: [712/1995] | Training loss: 0.059\n",
            "Epoch: [2/2] | Iterations: [713/1995] | Training loss: 0.052\n",
            "Epoch: [2/2] | Iterations: [714/1995] | Training loss: 0.091\n",
            "Epoch: [2/2] | Iterations: [715/1995] | Training loss: 0.116\n",
            "Epoch: [2/2] | Iterations: [716/1995] | Training loss: 0.091\n",
            "Epoch: [2/2] | Iterations: [717/1995] | Training loss: 0.098\n",
            "Epoch: [2/2] | Iterations: [718/1995] | Training loss: 0.126\n",
            "Epoch: [2/2] | Iterations: [719/1995] | Training loss: 0.100\n",
            "Epoch: [2/2] | Iterations: [720/1995] | Training loss: 0.077\n",
            "Epoch: [2/2] | Iterations: [721/1995] | Training loss: 0.142\n",
            "Epoch: [2/2] | Iterations: [722/1995] | Training loss: 0.094\n",
            "Epoch: [2/2] | Iterations: [723/1995] | Training loss: 0.149\n",
            "Epoch: [2/2] | Iterations: [724/1995] | Training loss: 0.072\n",
            "Epoch: [2/2] | Iterations: [725/1995] | Training loss: 0.125\n",
            "Epoch: [2/2] | Iterations: [726/1995] | Training loss: 0.141\n",
            "Epoch: [2/2] | Iterations: [727/1995] | Training loss: 0.100\n",
            "Epoch: [2/2] | Iterations: [728/1995] | Training loss: 0.073\n",
            "Epoch: [2/2] | Iterations: [729/1995] | Training loss: 0.101\n",
            "Epoch: [2/2] | Iterations: [730/1995] | Training loss: 0.129\n",
            "Epoch: [2/2] | Iterations: [731/1995] | Training loss: 0.110\n",
            "Epoch: [2/2] | Iterations: [732/1995] | Training loss: 0.152\n",
            "Epoch: [2/2] | Iterations: [733/1995] | Training loss: 0.070\n",
            "Epoch: [2/2] | Iterations: [734/1995] | Training loss: 0.107\n",
            "Epoch: [2/2] | Iterations: [735/1995] | Training loss: 0.087\n",
            "Epoch: [2/2] | Iterations: [736/1995] | Training loss: 0.113\n",
            "Epoch: [2/2] | Iterations: [737/1995] | Training loss: 0.067\n",
            "Epoch: [2/2] | Iterations: [738/1995] | Training loss: 0.096\n",
            "Epoch: [2/2] | Iterations: [739/1995] | Training loss: 0.067\n",
            "Epoch: [2/2] | Iterations: [740/1995] | Training loss: 0.107\n",
            "Epoch: [2/2] | Iterations: [741/1995] | Training loss: 0.057\n",
            "Epoch: [2/2] | Iterations: [742/1995] | Training loss: 0.078\n",
            "Epoch: [2/2] | Iterations: [743/1995] | Training loss: 0.060\n",
            "Epoch: [2/2] | Iterations: [744/1995] | Training loss: 0.168\n",
            "Epoch: [2/2] | Iterations: [745/1995] | Training loss: 0.076\n",
            "Epoch: [2/2] | Iterations: [746/1995] | Training loss: 0.071\n",
            "Epoch: [2/2] | Iterations: [747/1995] | Training loss: 0.083\n",
            "Epoch: [2/2] | Iterations: [748/1995] | Training loss: 0.092\n",
            "Epoch: [2/2] | Iterations: [749/1995] | Training loss: 0.103\n",
            "Epoch: [2/2] | Iterations: [750/1995] | Training loss: 0.053\n",
            "Epoch: [2/2] | Iterations: [751/1995] | Training loss: 0.137\n",
            "Epoch: [2/2] | Iterations: [752/1995] | Training loss: 0.130\n",
            "Epoch: [2/2] | Iterations: [753/1995] | Training loss: 0.048\n",
            "Epoch: [2/2] | Iterations: [754/1995] | Training loss: 0.108\n",
            "Epoch: [2/2] | Iterations: [755/1995] | Training loss: 0.098\n",
            "Epoch: [2/2] | Iterations: [756/1995] | Training loss: 0.104\n",
            "Epoch: [2/2] | Iterations: [757/1995] | Training loss: 0.139\n",
            "Epoch: [2/2] | Iterations: [758/1995] | Training loss: 0.118\n",
            "Epoch: [2/2] | Iterations: [759/1995] | Training loss: 0.111\n",
            "Epoch: [2/2] | Iterations: [760/1995] | Training loss: 0.072\n",
            "Epoch: [2/2] | Iterations: [761/1995] | Training loss: 0.083\n",
            "Epoch: [2/2] | Iterations: [762/1995] | Training loss: 0.131\n",
            "Epoch: [2/2] | Iterations: [763/1995] | Training loss: 0.112\n",
            "Epoch: [2/2] | Iterations: [764/1995] | Training loss: 0.075\n",
            "Epoch: [2/2] | Iterations: [765/1995] | Training loss: 0.158\n",
            "Epoch: [2/2] | Iterations: [766/1995] | Training loss: 0.070\n",
            "Epoch: [2/2] | Iterations: [767/1995] | Training loss: 0.094\n",
            "Epoch: [2/2] | Iterations: [768/1995] | Training loss: 0.110\n",
            "Epoch: [2/2] | Iterations: [769/1995] | Training loss: 0.230\n",
            "Epoch: [2/2] | Iterations: [770/1995] | Training loss: 0.085\n",
            "Epoch: [2/2] | Iterations: [771/1995] | Training loss: 0.178\n",
            "Epoch: [2/2] | Iterations: [772/1995] | Training loss: 0.101\n",
            "Epoch: [2/2] | Iterations: [773/1995] | Training loss: 0.071\n",
            "Epoch: [2/2] | Iterations: [774/1995] | Training loss: 0.063\n",
            "Epoch: [2/2] | Iterations: [775/1995] | Training loss: 0.060\n",
            "Epoch: [2/2] | Iterations: [776/1995] | Training loss: 0.111\n",
            "Epoch: [2/2] | Iterations: [777/1995] | Training loss: 0.112\n",
            "Epoch: [2/2] | Iterations: [778/1995] | Training loss: 0.067\n",
            "Epoch: [2/2] | Iterations: [779/1995] | Training loss: 0.145\n",
            "Epoch: [2/2] | Iterations: [780/1995] | Training loss: 0.066\n",
            "Epoch: [2/2] | Iterations: [781/1995] | Training loss: 0.079\n",
            "Epoch: [2/2] | Iterations: [782/1995] | Training loss: 0.043\n",
            "Epoch: [2/2] | Iterations: [783/1995] | Training loss: 0.049\n",
            "Epoch: [2/2] | Iterations: [784/1995] | Training loss: 0.108\n",
            "Epoch: [2/2] | Iterations: [785/1995] | Training loss: 0.217\n",
            "Epoch: [2/2] | Iterations: [786/1995] | Training loss: 0.089\n",
            "Epoch: [2/2] | Iterations: [787/1995] | Training loss: 0.095\n",
            "Epoch: [2/2] | Iterations: [788/1995] | Training loss: 0.072\n",
            "Epoch: [2/2] | Iterations: [789/1995] | Training loss: 0.129\n",
            "Epoch: [2/2] | Iterations: [790/1995] | Training loss: 0.129\n",
            "Epoch: [2/2] | Iterations: [791/1995] | Training loss: 0.044\n",
            "Epoch: [2/2] | Iterations: [792/1995] | Training loss: 0.102\n",
            "Epoch: [2/2] | Iterations: [793/1995] | Training loss: 0.120\n",
            "Epoch: [2/2] | Iterations: [794/1995] | Training loss: 0.085\n",
            "Epoch: [2/2] | Iterations: [795/1995] | Training loss: 0.103\n",
            "Epoch: [2/2] | Iterations: [796/1995] | Training loss: 0.107\n",
            "Epoch: [2/2] | Iterations: [797/1995] | Training loss: 0.048\n",
            "Epoch: [2/2] | Iterations: [798/1995] | Training loss: 0.098\n",
            "Epoch: [2/2] | Iterations: [799/1995] | Training loss: 0.177\n",
            "Epoch: [2/2] | Iterations: [800/1995] | Training loss: 0.119\n",
            "Epoch: [2/2] | Iterations: [801/1995] | Training loss: 0.152\n",
            "Epoch: [2/2] | Iterations: [802/1995] | Training loss: 0.103\n",
            "Epoch: [2/2] | Iterations: [803/1995] | Training loss: 0.077\n",
            "Epoch: [2/2] | Iterations: [804/1995] | Training loss: 0.090\n",
            "Epoch: [2/2] | Iterations: [805/1995] | Training loss: 0.060\n",
            "Epoch: [2/2] | Iterations: [806/1995] | Training loss: 0.191\n",
            "Epoch: [2/2] | Iterations: [807/1995] | Training loss: 0.098\n",
            "Epoch: [2/2] | Iterations: [808/1995] | Training loss: 0.129\n",
            "Epoch: [2/2] | Iterations: [809/1995] | Training loss: 0.082\n",
            "Epoch: [2/2] | Iterations: [810/1995] | Training loss: 0.091\n",
            "Epoch: [2/2] | Iterations: [811/1995] | Training loss: 0.085\n",
            "Epoch: [2/2] | Iterations: [812/1995] | Training loss: 0.116\n",
            "Epoch: [2/2] | Iterations: [813/1995] | Training loss: 0.144\n",
            "Epoch: [2/2] | Iterations: [814/1995] | Training loss: 0.065\n",
            "Epoch: [2/2] | Iterations: [815/1995] | Training loss: 0.091\n",
            "Epoch: [2/2] | Iterations: [816/1995] | Training loss: 0.143\n",
            "Epoch: [2/2] | Iterations: [817/1995] | Training loss: 0.100\n",
            "Epoch: [2/2] | Iterations: [818/1995] | Training loss: 0.177\n",
            "Epoch: [2/2] | Iterations: [819/1995] | Training loss: 0.076\n",
            "Epoch: [2/2] | Iterations: [820/1995] | Training loss: 0.040\n",
            "Epoch: [2/2] | Iterations: [821/1995] | Training loss: 0.165\n",
            "Epoch: [2/2] | Iterations: [822/1995] | Training loss: 0.054\n",
            "Epoch: [2/2] | Iterations: [823/1995] | Training loss: 0.054\n",
            "Epoch: [2/2] | Iterations: [824/1995] | Training loss: 0.151\n",
            "Epoch: [2/2] | Iterations: [825/1995] | Training loss: 0.092\n",
            "Epoch: [2/2] | Iterations: [826/1995] | Training loss: 0.088\n",
            "Epoch: [2/2] | Iterations: [827/1995] | Training loss: 0.097\n",
            "Epoch: [2/2] | Iterations: [828/1995] | Training loss: 0.062\n",
            "Epoch: [2/2] | Iterations: [829/1995] | Training loss: 0.038\n",
            "Epoch: [2/2] | Iterations: [830/1995] | Training loss: 0.073\n",
            "Epoch: [2/2] | Iterations: [831/1995] | Training loss: 0.107\n",
            "Epoch: [2/2] | Iterations: [832/1995] | Training loss: 0.104\n",
            "Epoch: [2/2] | Iterations: [833/1995] | Training loss: 0.138\n",
            "Epoch: [2/2] | Iterations: [834/1995] | Training loss: 0.106\n",
            "Epoch: [2/2] | Iterations: [835/1995] | Training loss: 0.049\n",
            "Epoch: [2/2] | Iterations: [836/1995] | Training loss: 0.099\n",
            "Epoch: [2/2] | Iterations: [837/1995] | Training loss: 0.132\n",
            "Epoch: [2/2] | Iterations: [838/1995] | Training loss: 0.096\n",
            "Epoch: [2/2] | Iterations: [839/1995] | Training loss: 0.115\n",
            "Epoch: [2/2] | Iterations: [840/1995] | Training loss: 0.113\n",
            "Epoch: [2/2] | Iterations: [841/1995] | Training loss: 0.155\n",
            "Epoch: [2/2] | Iterations: [842/1995] | Training loss: 0.094\n",
            "Epoch: [2/2] | Iterations: [843/1995] | Training loss: 0.034\n",
            "Epoch: [2/2] | Iterations: [844/1995] | Training loss: 0.124\n",
            "Epoch: [2/2] | Iterations: [845/1995] | Training loss: 0.164\n",
            "Epoch: [2/2] | Iterations: [846/1995] | Training loss: 0.071\n",
            "Epoch: [2/2] | Iterations: [847/1995] | Training loss: 0.122\n",
            "Epoch: [2/2] | Iterations: [848/1995] | Training loss: 0.076\n",
            "Epoch: [2/2] | Iterations: [849/1995] | Training loss: 0.158\n",
            "Epoch: [2/2] | Iterations: [850/1995] | Training loss: 0.058\n",
            "Epoch: [2/2] | Iterations: [851/1995] | Training loss: 0.170\n",
            "Epoch: [2/2] | Iterations: [852/1995] | Training loss: 0.088\n",
            "Epoch: [2/2] | Iterations: [853/1995] | Training loss: 0.054\n",
            "Epoch: [2/2] | Iterations: [854/1995] | Training loss: 0.141\n",
            "Epoch: [2/2] | Iterations: [855/1995] | Training loss: 0.130\n",
            "Epoch: [2/2] | Iterations: [856/1995] | Training loss: 0.110\n",
            "Epoch: [2/2] | Iterations: [857/1995] | Training loss: 0.060\n",
            "Epoch: [2/2] | Iterations: [858/1995] | Training loss: 0.104\n",
            "Epoch: [2/2] | Iterations: [859/1995] | Training loss: 0.103\n",
            "Epoch: [2/2] | Iterations: [860/1995] | Training loss: 0.071\n",
            "Epoch: [2/2] | Iterations: [861/1995] | Training loss: 0.096\n",
            "Epoch: [2/2] | Iterations: [862/1995] | Training loss: 0.116\n",
            "Epoch: [2/2] | Iterations: [863/1995] | Training loss: 0.111\n",
            "Epoch: [2/2] | Iterations: [864/1995] | Training loss: 0.116\n",
            "Epoch: [2/2] | Iterations: [865/1995] | Training loss: 0.096\n",
            "Epoch: [2/2] | Iterations: [866/1995] | Training loss: 0.069\n",
            "Epoch: [2/2] | Iterations: [867/1995] | Training loss: 0.090\n",
            "Epoch: [2/2] | Iterations: [868/1995] | Training loss: 0.094\n",
            "Epoch: [2/2] | Iterations: [869/1995] | Training loss: 0.092\n",
            "Epoch: [2/2] | Iterations: [870/1995] | Training loss: 0.147\n",
            "Epoch: [2/2] | Iterations: [871/1995] | Training loss: 0.071\n",
            "Epoch: [2/2] | Iterations: [872/1995] | Training loss: 0.052\n",
            "Epoch: [2/2] | Iterations: [873/1995] | Training loss: 0.091\n",
            "Epoch: [2/2] | Iterations: [874/1995] | Training loss: 0.102\n",
            "Epoch: [2/2] | Iterations: [875/1995] | Training loss: 0.169\n",
            "Epoch: [2/2] | Iterations: [876/1995] | Training loss: 0.097\n",
            "Epoch: [2/2] | Iterations: [877/1995] | Training loss: 0.067\n",
            "Epoch: [2/2] | Iterations: [878/1995] | Training loss: 0.092\n",
            "Epoch: [2/2] | Iterations: [879/1995] | Training loss: 0.088\n",
            "Epoch: [2/2] | Iterations: [880/1995] | Training loss: 0.060\n",
            "Epoch: [2/2] | Iterations: [881/1995] | Training loss: 0.133\n",
            "Epoch: [2/2] | Iterations: [882/1995] | Training loss: 0.070\n",
            "Epoch: [2/2] | Iterations: [883/1995] | Training loss: 0.131\n",
            "Epoch: [2/2] | Iterations: [884/1995] | Training loss: 0.118\n",
            "Epoch: [2/2] | Iterations: [885/1995] | Training loss: 0.086\n",
            "Epoch: [2/2] | Iterations: [886/1995] | Training loss: 0.158\n",
            "Epoch: [2/2] | Iterations: [887/1995] | Training loss: 0.110\n",
            "Epoch: [2/2] | Iterations: [888/1995] | Training loss: 0.093\n",
            "Epoch: [2/2] | Iterations: [889/1995] | Training loss: 0.087\n",
            "Epoch: [2/2] | Iterations: [890/1995] | Training loss: 0.078\n",
            "Epoch: [2/2] | Iterations: [891/1995] | Training loss: 0.107\n",
            "Epoch: [2/2] | Iterations: [892/1995] | Training loss: 0.135\n",
            "Epoch: [2/2] | Iterations: [893/1995] | Training loss: 0.152\n",
            "Epoch: [2/2] | Iterations: [894/1995] | Training loss: 0.099\n",
            "Epoch: [2/2] | Iterations: [895/1995] | Training loss: 0.095\n",
            "Epoch: [2/2] | Iterations: [896/1995] | Training loss: 0.102\n",
            "Epoch: [2/2] | Iterations: [897/1995] | Training loss: 0.094\n",
            "Epoch: [2/2] | Iterations: [898/1995] | Training loss: 0.068\n",
            "Epoch: [2/2] | Iterations: [899/1995] | Training loss: 0.050\n",
            "Epoch: [2/2] | Iterations: [900/1995] | Training loss: 0.091\n",
            "Epoch: [2/2] | Iterations: [901/1995] | Training loss: 0.093\n",
            "Epoch: [2/2] | Iterations: [902/1995] | Training loss: 0.123\n",
            "Epoch: [2/2] | Iterations: [903/1995] | Training loss: 0.117\n",
            "Epoch: [2/2] | Iterations: [904/1995] | Training loss: 0.068\n",
            "Epoch: [2/2] | Iterations: [905/1995] | Training loss: 0.049\n",
            "Epoch: [2/2] | Iterations: [906/1995] | Training loss: 0.082\n",
            "Epoch: [2/2] | Iterations: [907/1995] | Training loss: 0.126\n",
            "Epoch: [2/2] | Iterations: [908/1995] | Training loss: 0.074\n",
            "Epoch: [2/2] | Iterations: [909/1995] | Training loss: 0.058\n",
            "Epoch: [2/2] | Iterations: [910/1995] | Training loss: 0.144\n",
            "Epoch: [2/2] | Iterations: [911/1995] | Training loss: 0.076\n",
            "Epoch: [2/2] | Iterations: [912/1995] | Training loss: 0.101\n",
            "Epoch: [2/2] | Iterations: [913/1995] | Training loss: 0.066\n",
            "Epoch: [2/2] | Iterations: [914/1995] | Training loss: 0.091\n",
            "Epoch: [2/2] | Iterations: [915/1995] | Training loss: 0.134\n",
            "Epoch: [2/2] | Iterations: [916/1995] | Training loss: 0.055\n",
            "Epoch: [2/2] | Iterations: [917/1995] | Training loss: 0.084\n",
            "Epoch: [2/2] | Iterations: [918/1995] | Training loss: 0.072\n",
            "Epoch: [2/2] | Iterations: [919/1995] | Training loss: 0.112\n",
            "Epoch: [2/2] | Iterations: [920/1995] | Training loss: 0.080\n",
            "Epoch: [2/2] | Iterations: [921/1995] | Training loss: 0.071\n",
            "Epoch: [2/2] | Iterations: [922/1995] | Training loss: 0.114\n",
            "Epoch: [2/2] | Iterations: [923/1995] | Training loss: 0.119\n",
            "Epoch: [2/2] | Iterations: [924/1995] | Training loss: 0.125\n",
            "Epoch: [2/2] | Iterations: [925/1995] | Training loss: 0.079\n",
            "Epoch: [2/2] | Iterations: [926/1995] | Training loss: 0.072\n",
            "Epoch: [2/2] | Iterations: [927/1995] | Training loss: 0.084\n",
            "Epoch: [2/2] | Iterations: [928/1995] | Training loss: 0.134\n",
            "Epoch: [2/2] | Iterations: [929/1995] | Training loss: 0.116\n",
            "Epoch: [2/2] | Iterations: [930/1995] | Training loss: 0.101\n",
            "Epoch: [2/2] | Iterations: [931/1995] | Training loss: 0.087\n",
            "Epoch: [2/2] | Iterations: [932/1995] | Training loss: 0.072\n",
            "Epoch: [2/2] | Iterations: [933/1995] | Training loss: 0.107\n",
            "Epoch: [2/2] | Iterations: [934/1995] | Training loss: 0.063\n",
            "Epoch: [2/2] | Iterations: [935/1995] | Training loss: 0.102\n",
            "Epoch: [2/2] | Iterations: [936/1995] | Training loss: 0.111\n",
            "Epoch: [2/2] | Iterations: [937/1995] | Training loss: 0.096\n",
            "Epoch: [2/2] | Iterations: [938/1995] | Training loss: 0.149\n",
            "Epoch: [2/2] | Iterations: [939/1995] | Training loss: 0.100\n",
            "Epoch: [2/2] | Iterations: [940/1995] | Training loss: 0.060\n",
            "Epoch: [2/2] | Iterations: [941/1995] | Training loss: 0.093\n",
            "Epoch: [2/2] | Iterations: [942/1995] | Training loss: 0.106\n",
            "Epoch: [2/2] | Iterations: [943/1995] | Training loss: 0.068\n",
            "Epoch: [2/2] | Iterations: [944/1995] | Training loss: 0.119\n",
            "Epoch: [2/2] | Iterations: [945/1995] | Training loss: 0.072\n",
            "Epoch: [2/2] | Iterations: [946/1995] | Training loss: 0.066\n",
            "Epoch: [2/2] | Iterations: [947/1995] | Training loss: 0.120\n",
            "Epoch: [2/2] | Iterations: [948/1995] | Training loss: 0.096\n",
            "Epoch: [2/2] | Iterations: [949/1995] | Training loss: 0.090\n",
            "Epoch: [2/2] | Iterations: [950/1995] | Training loss: 0.068\n",
            "Epoch: [2/2] | Iterations: [951/1995] | Training loss: 0.187\n",
            "Epoch: [2/2] | Iterations: [952/1995] | Training loss: 0.108\n",
            "Epoch: [2/2] | Iterations: [953/1995] | Training loss: 0.046\n",
            "Epoch: [2/2] | Iterations: [954/1995] | Training loss: 0.093\n",
            "Epoch: [2/2] | Iterations: [955/1995] | Training loss: 0.090\n",
            "Epoch: [2/2] | Iterations: [956/1995] | Training loss: 0.113\n",
            "Epoch: [2/2] | Iterations: [957/1995] | Training loss: 0.111\n",
            "Epoch: [2/2] | Iterations: [958/1995] | Training loss: 0.098\n",
            "Epoch: [2/2] | Iterations: [959/1995] | Training loss: 0.138\n",
            "Epoch: [2/2] | Iterations: [960/1995] | Training loss: 0.083\n",
            "Epoch: [2/2] | Iterations: [961/1995] | Training loss: 0.077\n",
            "Epoch: [2/2] | Iterations: [962/1995] | Training loss: 0.138\n",
            "Epoch: [2/2] | Iterations: [963/1995] | Training loss: 0.113\n",
            "Epoch: [2/2] | Iterations: [964/1995] | Training loss: 0.070\n",
            "Epoch: [2/2] | Iterations: [965/1995] | Training loss: 0.059\n",
            "Epoch: [2/2] | Iterations: [966/1995] | Training loss: 0.047\n",
            "Epoch: [2/2] | Iterations: [967/1995] | Training loss: 0.105\n",
            "Epoch: [2/2] | Iterations: [968/1995] | Training loss: 0.116\n",
            "Epoch: [2/2] | Iterations: [969/1995] | Training loss: 0.144\n",
            "Epoch: [2/2] | Iterations: [970/1995] | Training loss: 0.218\n",
            "Epoch: [2/2] | Iterations: [971/1995] | Training loss: 0.057\n",
            "Epoch: [2/2] | Iterations: [972/1995] | Training loss: 0.087\n",
            "Epoch: [2/2] | Iterations: [973/1995] | Training loss: 0.103\n",
            "Epoch: [2/2] | Iterations: [974/1995] | Training loss: 0.128\n",
            "Epoch: [2/2] | Iterations: [975/1995] | Training loss: 0.099\n",
            "Epoch: [2/2] | Iterations: [976/1995] | Training loss: 0.082\n",
            "Epoch: [2/2] | Iterations: [977/1995] | Training loss: 0.118\n",
            "Epoch: [2/2] | Iterations: [978/1995] | Training loss: 0.059\n",
            "Epoch: [2/2] | Iterations: [979/1995] | Training loss: 0.097\n",
            "Epoch: [2/2] | Iterations: [980/1995] | Training loss: 0.151\n",
            "Epoch: [2/2] | Iterations: [981/1995] | Training loss: 0.107\n",
            "Epoch: [2/2] | Iterations: [982/1995] | Training loss: 0.076\n",
            "Epoch: [2/2] | Iterations: [983/1995] | Training loss: 0.062\n",
            "Epoch: [2/2] | Iterations: [984/1995] | Training loss: 0.067\n",
            "Epoch: [2/2] | Iterations: [985/1995] | Training loss: 0.123\n",
            "Epoch: [2/2] | Iterations: [986/1995] | Training loss: 0.092\n",
            "Epoch: [2/2] | Iterations: [987/1995] | Training loss: 0.166\n",
            "Epoch: [2/2] | Iterations: [988/1995] | Training loss: 0.084\n",
            "Epoch: [2/2] | Iterations: [989/1995] | Training loss: 0.111\n",
            "Epoch: [2/2] | Iterations: [990/1995] | Training loss: 0.079\n",
            "Epoch: [2/2] | Iterations: [991/1995] | Training loss: 0.147\n",
            "Epoch: [2/2] | Iterations: [992/1995] | Training loss: 0.044\n",
            "Epoch: [2/2] | Iterations: [993/1995] | Training loss: 0.148\n",
            "Epoch: [2/2] | Iterations: [994/1995] | Training loss: 0.120\n",
            "Epoch: [2/2] | Iterations: [995/1995] | Training loss: 0.058\n",
            "Epoch: [2/2] | Iterations: [996/1995] | Training loss: 0.110\n",
            "Epoch: [2/2] | Iterations: [997/1995] | Training loss: 0.117\n",
            "Epoch: [2/2] | Iterations: [998/1995] | Training loss: 0.097\n",
            "Epoch: [2/2] | Iterations: [999/1995] | Training loss: 0.093\n",
            "Epoch: [2/2] | Iterations: [1000/1995] | Training loss: 0.095\n",
            "Epoch: [2/2] | Iterations: [1001/1995] | Training loss: 0.071\n",
            "Epoch: [2/2] | Iterations: [1002/1995] | Training loss: 0.125\n",
            "Epoch: [2/2] | Iterations: [1003/1995] | Training loss: 0.099\n",
            "Epoch: [2/2] | Iterations: [1004/1995] | Training loss: 0.071\n",
            "Epoch: [2/2] | Iterations: [1005/1995] | Training loss: 0.118\n",
            "Epoch: [2/2] | Iterations: [1006/1995] | Training loss: 0.169\n",
            "Epoch: [2/2] | Iterations: [1007/1995] | Training loss: 0.094\n",
            "Epoch: [2/2] | Iterations: [1008/1995] | Training loss: 0.051\n",
            "Epoch: [2/2] | Iterations: [1009/1995] | Training loss: 0.108\n",
            "Epoch: [2/2] | Iterations: [1010/1995] | Training loss: 0.064\n",
            "Epoch: [2/2] | Iterations: [1011/1995] | Training loss: 0.046\n",
            "Epoch: [2/2] | Iterations: [1012/1995] | Training loss: 0.091\n",
            "Epoch: [2/2] | Iterations: [1013/1995] | Training loss: 0.087\n",
            "Epoch: [2/2] | Iterations: [1014/1995] | Training loss: 0.086\n",
            "Epoch: [2/2] | Iterations: [1015/1995] | Training loss: 0.095\n",
            "Epoch: [2/2] | Iterations: [1016/1995] | Training loss: 0.133\n",
            "Epoch: [2/2] | Iterations: [1017/1995] | Training loss: 0.118\n",
            "Epoch: [2/2] | Iterations: [1018/1995] | Training loss: 0.098\n",
            "Epoch: [2/2] | Iterations: [1019/1995] | Training loss: 0.067\n",
            "Epoch: [2/2] | Iterations: [1020/1995] | Training loss: 0.133\n",
            "Epoch: [2/2] | Iterations: [1021/1995] | Training loss: 0.105\n",
            "Epoch: [2/2] | Iterations: [1022/1995] | Training loss: 0.125\n",
            "Epoch: [2/2] | Iterations: [1023/1995] | Training loss: 0.125\n",
            "Epoch: [2/2] | Iterations: [1024/1995] | Training loss: 0.121\n",
            "Epoch: [2/2] | Iterations: [1025/1995] | Training loss: 0.112\n",
            "Epoch: [2/2] | Iterations: [1026/1995] | Training loss: 0.066\n",
            "Epoch: [2/2] | Iterations: [1027/1995] | Training loss: 0.125\n",
            "Epoch: [2/2] | Iterations: [1028/1995] | Training loss: 0.153\n",
            "Epoch: [2/2] | Iterations: [1029/1995] | Training loss: 0.063\n",
            "Epoch: [2/2] | Iterations: [1030/1995] | Training loss: 0.049\n",
            "Epoch: [2/2] | Iterations: [1031/1995] | Training loss: 0.083\n",
            "Epoch: [2/2] | Iterations: [1032/1995] | Training loss: 0.104\n",
            "Epoch: [2/2] | Iterations: [1033/1995] | Training loss: 0.053\n",
            "Epoch: [2/2] | Iterations: [1034/1995] | Training loss: 0.053\n",
            "Epoch: [2/2] | Iterations: [1035/1995] | Training loss: 0.116\n",
            "Epoch: [2/2] | Iterations: [1036/1995] | Training loss: 0.087\n",
            "Epoch: [2/2] | Iterations: [1037/1995] | Training loss: 0.076\n",
            "Epoch: [2/2] | Iterations: [1038/1995] | Training loss: 0.112\n",
            "Epoch: [2/2] | Iterations: [1039/1995] | Training loss: 0.153\n",
            "Epoch: [2/2] | Iterations: [1040/1995] | Training loss: 0.166\n",
            "Epoch: [2/2] | Iterations: [1041/1995] | Training loss: 0.041\n",
            "Epoch: [2/2] | Iterations: [1042/1995] | Training loss: 0.090\n",
            "Epoch: [2/2] | Iterations: [1043/1995] | Training loss: 0.121\n",
            "Epoch: [2/2] | Iterations: [1044/1995] | Training loss: 0.099\n",
            "Epoch: [2/2] | Iterations: [1045/1995] | Training loss: 0.176\n",
            "Epoch: [2/2] | Iterations: [1046/1995] | Training loss: 0.064\n",
            "Epoch: [2/2] | Iterations: [1047/1995] | Training loss: 0.138\n",
            "Epoch: [2/2] | Iterations: [1048/1995] | Training loss: 0.068\n",
            "Epoch: [2/2] | Iterations: [1049/1995] | Training loss: 0.091\n",
            "Epoch: [2/2] | Iterations: [1050/1995] | Training loss: 0.089\n",
            "Epoch: [2/2] | Iterations: [1051/1995] | Training loss: 0.108\n",
            "Epoch: [2/2] | Iterations: [1052/1995] | Training loss: 0.067\n",
            "Epoch: [2/2] | Iterations: [1053/1995] | Training loss: 0.073\n",
            "Epoch: [2/2] | Iterations: [1054/1995] | Training loss: 0.078\n",
            "Epoch: [2/2] | Iterations: [1055/1995] | Training loss: 0.073\n",
            "Epoch: [2/2] | Iterations: [1056/1995] | Training loss: 0.090\n",
            "Epoch: [2/2] | Iterations: [1057/1995] | Training loss: 0.098\n",
            "Epoch: [2/2] | Iterations: [1058/1995] | Training loss: 0.084\n",
            "Epoch: [2/2] | Iterations: [1059/1995] | Training loss: 0.082\n",
            "Epoch: [2/2] | Iterations: [1060/1995] | Training loss: 0.147\n",
            "Epoch: [2/2] | Iterations: [1061/1995] | Training loss: 0.101\n",
            "Epoch: [2/2] | Iterations: [1062/1995] | Training loss: 0.070\n",
            "Epoch: [2/2] | Iterations: [1063/1995] | Training loss: 0.132\n",
            "Epoch: [2/2] | Iterations: [1064/1995] | Training loss: 0.072\n",
            "Epoch: [2/2] | Iterations: [1065/1995] | Training loss: 0.064\n",
            "Epoch: [2/2] | Iterations: [1066/1995] | Training loss: 0.075\n",
            "Epoch: [2/2] | Iterations: [1067/1995] | Training loss: 0.072\n",
            "Epoch: [2/2] | Iterations: [1068/1995] | Training loss: 0.100\n",
            "Epoch: [2/2] | Iterations: [1069/1995] | Training loss: 0.057\n",
            "Epoch: [2/2] | Iterations: [1070/1995] | Training loss: 0.089\n",
            "Epoch: [2/2] | Iterations: [1071/1995] | Training loss: 0.095\n",
            "Epoch: [2/2] | Iterations: [1072/1995] | Training loss: 0.032\n",
            "Epoch: [2/2] | Iterations: [1073/1995] | Training loss: 0.109\n",
            "Epoch: [2/2] | Iterations: [1074/1995] | Training loss: 0.092\n",
            "Epoch: [2/2] | Iterations: [1075/1995] | Training loss: 0.119\n",
            "Epoch: [2/2] | Iterations: [1076/1995] | Training loss: 0.088\n",
            "Epoch: [2/2] | Iterations: [1077/1995] | Training loss: 0.102\n",
            "Epoch: [2/2] | Iterations: [1078/1995] | Training loss: 0.113\n",
            "Epoch: [2/2] | Iterations: [1079/1995] | Training loss: 0.107\n",
            "Epoch: [2/2] | Iterations: [1080/1995] | Training loss: 0.054\n",
            "Epoch: [2/2] | Iterations: [1081/1995] | Training loss: 0.057\n",
            "Epoch: [2/2] | Iterations: [1082/1995] | Training loss: 0.061\n",
            "Epoch: [2/2] | Iterations: [1083/1995] | Training loss: 0.102\n",
            "Epoch: [2/2] | Iterations: [1084/1995] | Training loss: 0.157\n",
            "Epoch: [2/2] | Iterations: [1085/1995] | Training loss: 0.144\n",
            "Epoch: [2/2] | Iterations: [1086/1995] | Training loss: 0.094\n",
            "Epoch: [2/2] | Iterations: [1087/1995] | Training loss: 0.060\n",
            "Epoch: [2/2] | Iterations: [1088/1995] | Training loss: 0.078\n",
            "Epoch: [2/2] | Iterations: [1089/1995] | Training loss: 0.102\n",
            "Epoch: [2/2] | Iterations: [1090/1995] | Training loss: 0.090\n",
            "Epoch: [2/2] | Iterations: [1091/1995] | Training loss: 0.076\n",
            "Epoch: [2/2] | Iterations: [1092/1995] | Training loss: 0.071\n",
            "Epoch: [2/2] | Iterations: [1093/1995] | Training loss: 0.125\n",
            "Epoch: [2/2] | Iterations: [1094/1995] | Training loss: 0.066\n",
            "Epoch: [2/2] | Iterations: [1095/1995] | Training loss: 0.119\n",
            "Epoch: [2/2] | Iterations: [1096/1995] | Training loss: 0.110\n",
            "Epoch: [2/2] | Iterations: [1097/1995] | Training loss: 0.068\n",
            "Epoch: [2/2] | Iterations: [1098/1995] | Training loss: 0.120\n",
            "Epoch: [2/2] | Iterations: [1099/1995] | Training loss: 0.050\n",
            "Epoch: [2/2] | Iterations: [1100/1995] | Training loss: 0.074\n",
            "Epoch: [2/2] | Iterations: [1101/1995] | Training loss: 0.152\n",
            "Epoch: [2/2] | Iterations: [1102/1995] | Training loss: 0.132\n",
            "Epoch: [2/2] | Iterations: [1103/1995] | Training loss: 0.108\n",
            "Epoch: [2/2] | Iterations: [1104/1995] | Training loss: 0.102\n",
            "Epoch: [2/2] | Iterations: [1105/1995] | Training loss: 0.132\n",
            "Epoch: [2/2] | Iterations: [1106/1995] | Training loss: 0.108\n",
            "Epoch: [2/2] | Iterations: [1107/1995] | Training loss: 0.051\n",
            "Epoch: [2/2] | Iterations: [1108/1995] | Training loss: 0.097\n",
            "Epoch: [2/2] | Iterations: [1109/1995] | Training loss: 0.076\n",
            "Epoch: [2/2] | Iterations: [1110/1995] | Training loss: 0.052\n",
            "Epoch: [2/2] | Iterations: [1111/1995] | Training loss: 0.067\n",
            "Epoch: [2/2] | Iterations: [1112/1995] | Training loss: 0.057\n",
            "Epoch: [2/2] | Iterations: [1113/1995] | Training loss: 0.096\n",
            "Epoch: [2/2] | Iterations: [1114/1995] | Training loss: 0.106\n",
            "Epoch: [2/2] | Iterations: [1115/1995] | Training loss: 0.103\n",
            "Epoch: [2/2] | Iterations: [1116/1995] | Training loss: 0.101\n",
            "Epoch: [2/2] | Iterations: [1117/1995] | Training loss: 0.103\n",
            "Epoch: [2/2] | Iterations: [1118/1995] | Training loss: 0.060\n",
            "Epoch: [2/2] | Iterations: [1119/1995] | Training loss: 0.095\n",
            "Epoch: [2/2] | Iterations: [1120/1995] | Training loss: 0.060\n",
            "Epoch: [2/2] | Iterations: [1121/1995] | Training loss: 0.108\n",
            "Epoch: [2/2] | Iterations: [1122/1995] | Training loss: 0.152\n",
            "Epoch: [2/2] | Iterations: [1123/1995] | Training loss: 0.064\n",
            "Epoch: [2/2] | Iterations: [1124/1995] | Training loss: 0.117\n",
            "Epoch: [2/2] | Iterations: [1125/1995] | Training loss: 0.092\n",
            "Epoch: [2/2] | Iterations: [1126/1995] | Training loss: 0.135\n",
            "Epoch: [2/2] | Iterations: [1127/1995] | Training loss: 0.098\n",
            "Epoch: [2/2] | Iterations: [1128/1995] | Training loss: 0.114\n",
            "Epoch: [2/2] | Iterations: [1129/1995] | Training loss: 0.126\n",
            "Epoch: [2/2] | Iterations: [1130/1995] | Training loss: 0.106\n",
            "Epoch: [2/2] | Iterations: [1131/1995] | Training loss: 0.072\n",
            "Epoch: [2/2] | Iterations: [1132/1995] | Training loss: 0.106\n",
            "Epoch: [2/2] | Iterations: [1133/1995] | Training loss: 0.068\n",
            "Epoch: [2/2] | Iterations: [1134/1995] | Training loss: 0.090\n",
            "Epoch: [2/2] | Iterations: [1135/1995] | Training loss: 0.073\n",
            "Epoch: [2/2] | Iterations: [1136/1995] | Training loss: 0.106\n",
            "Epoch: [2/2] | Iterations: [1137/1995] | Training loss: 0.075\n",
            "Epoch: [2/2] | Iterations: [1138/1995] | Training loss: 0.112\n",
            "Epoch: [2/2] | Iterations: [1139/1995] | Training loss: 0.098\n",
            "Epoch: [2/2] | Iterations: [1140/1995] | Training loss: 0.119\n",
            "Epoch: [2/2] | Iterations: [1141/1995] | Training loss: 0.063\n",
            "Epoch: [2/2] | Iterations: [1142/1995] | Training loss: 0.066\n",
            "Epoch: [2/2] | Iterations: [1143/1995] | Training loss: 0.088\n",
            "Epoch: [2/2] | Iterations: [1144/1995] | Training loss: 0.160\n",
            "Epoch: [2/2] | Iterations: [1145/1995] | Training loss: 0.113\n",
            "Epoch: [2/2] | Iterations: [1146/1995] | Training loss: 0.051\n",
            "Epoch: [2/2] | Iterations: [1147/1995] | Training loss: 0.084\n",
            "Epoch: [2/2] | Iterations: [1148/1995] | Training loss: 0.087\n",
            "Epoch: [2/2] | Iterations: [1149/1995] | Training loss: 0.115\n",
            "Epoch: [2/2] | Iterations: [1150/1995] | Training loss: 0.073\n",
            "Epoch: [2/2] | Iterations: [1151/1995] | Training loss: 0.136\n",
            "Epoch: [2/2] | Iterations: [1152/1995] | Training loss: 0.059\n",
            "Epoch: [2/2] | Iterations: [1153/1995] | Training loss: 0.082\n",
            "Epoch: [2/2] | Iterations: [1154/1995] | Training loss: 0.073\n",
            "Epoch: [2/2] | Iterations: [1155/1995] | Training loss: 0.075\n",
            "Epoch: [2/2] | Iterations: [1156/1995] | Training loss: 0.047\n",
            "Epoch: [2/2] | Iterations: [1157/1995] | Training loss: 0.092\n",
            "Epoch: [2/2] | Iterations: [1158/1995] | Training loss: 0.045\n",
            "Epoch: [2/2] | Iterations: [1159/1995] | Training loss: 0.082\n",
            "Epoch: [2/2] | Iterations: [1160/1995] | Training loss: 0.087\n",
            "Epoch: [2/2] | Iterations: [1161/1995] | Training loss: 0.152\n",
            "Epoch: [2/2] | Iterations: [1162/1995] | Training loss: 0.225\n",
            "Epoch: [2/2] | Iterations: [1163/1995] | Training loss: 0.144\n",
            "Epoch: [2/2] | Iterations: [1164/1995] | Training loss: 0.084\n",
            "Epoch: [2/2] | Iterations: [1165/1995] | Training loss: 0.099\n",
            "Epoch: [2/2] | Iterations: [1166/1995] | Training loss: 0.112\n",
            "Epoch: [2/2] | Iterations: [1167/1995] | Training loss: 0.076\n",
            "Epoch: [2/2] | Iterations: [1168/1995] | Training loss: 0.100\n",
            "Epoch: [2/2] | Iterations: [1169/1995] | Training loss: 0.050\n",
            "Epoch: [2/2] | Iterations: [1170/1995] | Training loss: 0.100\n",
            "Epoch: [2/2] | Iterations: [1171/1995] | Training loss: 0.120\n",
            "Epoch: [2/2] | Iterations: [1172/1995] | Training loss: 0.106\n",
            "Epoch: [2/2] | Iterations: [1173/1995] | Training loss: 0.049\n",
            "Epoch: [2/2] | Iterations: [1174/1995] | Training loss: 0.142\n",
            "Epoch: [2/2] | Iterations: [1175/1995] | Training loss: 0.094\n",
            "Epoch: [2/2] | Iterations: [1176/1995] | Training loss: 0.109\n",
            "Epoch: [2/2] | Iterations: [1177/1995] | Training loss: 0.082\n",
            "Epoch: [2/2] | Iterations: [1178/1995] | Training loss: 0.102\n",
            "Epoch: [2/2] | Iterations: [1179/1995] | Training loss: 0.076\n",
            "Epoch: [2/2] | Iterations: [1180/1995] | Training loss: 0.100\n",
            "Epoch: [2/2] | Iterations: [1181/1995] | Training loss: 0.110\n",
            "Epoch: [2/2] | Iterations: [1182/1995] | Training loss: 0.062\n",
            "Epoch: [2/2] | Iterations: [1183/1995] | Training loss: 0.099\n",
            "Epoch: [2/2] | Iterations: [1184/1995] | Training loss: 0.076\n",
            "Epoch: [2/2] | Iterations: [1185/1995] | Training loss: 0.116\n",
            "Epoch: [2/2] | Iterations: [1186/1995] | Training loss: 0.108\n",
            "Epoch: [2/2] | Iterations: [1187/1995] | Training loss: 0.087\n",
            "Epoch: [2/2] | Iterations: [1188/1995] | Training loss: 0.047\n",
            "Epoch: [2/2] | Iterations: [1189/1995] | Training loss: 0.076\n",
            "Epoch: [2/2] | Iterations: [1190/1995] | Training loss: 0.129\n",
            "Epoch: [2/2] | Iterations: [1191/1995] | Training loss: 0.141\n",
            "Epoch: [2/2] | Iterations: [1192/1995] | Training loss: 0.141\n",
            "Epoch: [2/2] | Iterations: [1193/1995] | Training loss: 0.179\n",
            "Epoch: [2/2] | Iterations: [1194/1995] | Training loss: 0.081\n",
            "Epoch: [2/2] | Iterations: [1195/1995] | Training loss: 0.106\n",
            "Epoch: [2/2] | Iterations: [1196/1995] | Training loss: 0.176\n",
            "Epoch: [2/2] | Iterations: [1197/1995] | Training loss: 0.106\n",
            "Epoch: [2/2] | Iterations: [1198/1995] | Training loss: 0.105\n",
            "Epoch: [2/2] | Iterations: [1199/1995] | Training loss: 0.078\n",
            "Epoch: [2/2] | Iterations: [1200/1995] | Training loss: 0.047\n",
            "Epoch: [2/2] | Iterations: [1201/1995] | Training loss: 0.069\n",
            "Epoch: [2/2] | Iterations: [1202/1995] | Training loss: 0.117\n",
            "Epoch: [2/2] | Iterations: [1203/1995] | Training loss: 0.079\n",
            "Epoch: [2/2] | Iterations: [1204/1995] | Training loss: 0.094\n",
            "Epoch: [2/2] | Iterations: [1205/1995] | Training loss: 0.091\n",
            "Epoch: [2/2] | Iterations: [1206/1995] | Training loss: 0.051\n",
            "Epoch: [2/2] | Iterations: [1207/1995] | Training loss: 0.112\n",
            "Epoch: [2/2] | Iterations: [1208/1995] | Training loss: 0.202\n",
            "Epoch: [2/2] | Iterations: [1209/1995] | Training loss: 0.094\n",
            "Epoch: [2/2] | Iterations: [1210/1995] | Training loss: 0.129\n",
            "Epoch: [2/2] | Iterations: [1211/1995] | Training loss: 0.048\n",
            "Epoch: [2/2] | Iterations: [1212/1995] | Training loss: 0.109\n",
            "Epoch: [2/2] | Iterations: [1213/1995] | Training loss: 0.095\n",
            "Epoch: [2/2] | Iterations: [1214/1995] | Training loss: 0.088\n",
            "Epoch: [2/2] | Iterations: [1215/1995] | Training loss: 0.055\n",
            "Epoch: [2/2] | Iterations: [1216/1995] | Training loss: 0.070\n",
            "Epoch: [2/2] | Iterations: [1217/1995] | Training loss: 0.092\n",
            "Epoch: [2/2] | Iterations: [1218/1995] | Training loss: 0.098\n",
            "Epoch: [2/2] | Iterations: [1219/1995] | Training loss: 0.115\n",
            "Epoch: [2/2] | Iterations: [1220/1995] | Training loss: 0.121\n",
            "Epoch: [2/2] | Iterations: [1221/1995] | Training loss: 0.083\n",
            "Epoch: [2/2] | Iterations: [1222/1995] | Training loss: 0.064\n",
            "Epoch: [2/2] | Iterations: [1223/1995] | Training loss: 0.109\n",
            "Epoch: [2/2] | Iterations: [1224/1995] | Training loss: 0.067\n",
            "Epoch: [2/2] | Iterations: [1225/1995] | Training loss: 0.120\n",
            "Epoch: [2/2] | Iterations: [1226/1995] | Training loss: 0.069\n",
            "Epoch: [2/2] | Iterations: [1227/1995] | Training loss: 0.100\n",
            "Epoch: [2/2] | Iterations: [1228/1995] | Training loss: 0.086\n",
            "Epoch: [2/2] | Iterations: [1229/1995] | Training loss: 0.080\n",
            "Epoch: [2/2] | Iterations: [1230/1995] | Training loss: 0.111\n",
            "Epoch: [2/2] | Iterations: [1231/1995] | Training loss: 0.047\n",
            "Epoch: [2/2] | Iterations: [1232/1995] | Training loss: 0.100\n",
            "Epoch: [2/2] | Iterations: [1233/1995] | Training loss: 0.103\n",
            "Epoch: [2/2] | Iterations: [1234/1995] | Training loss: 0.081\n",
            "Epoch: [2/2] | Iterations: [1235/1995] | Training loss: 0.091\n",
            "Epoch: [2/2] | Iterations: [1236/1995] | Training loss: 0.073\n",
            "Epoch: [2/2] | Iterations: [1237/1995] | Training loss: 0.072\n",
            "Epoch: [2/2] | Iterations: [1238/1995] | Training loss: 0.146\n",
            "Epoch: [2/2] | Iterations: [1239/1995] | Training loss: 0.067\n",
            "Epoch: [2/2] | Iterations: [1240/1995] | Training loss: 0.070\n",
            "Epoch: [2/2] | Iterations: [1241/1995] | Training loss: 0.060\n",
            "Epoch: [2/2] | Iterations: [1242/1995] | Training loss: 0.138\n",
            "Epoch: [2/2] | Iterations: [1243/1995] | Training loss: 0.088\n",
            "Epoch: [2/2] | Iterations: [1244/1995] | Training loss: 0.110\n",
            "Epoch: [2/2] | Iterations: [1245/1995] | Training loss: 0.077\n",
            "Epoch: [2/2] | Iterations: [1246/1995] | Training loss: 0.081\n",
            "Epoch: [2/2] | Iterations: [1247/1995] | Training loss: 0.095\n",
            "Epoch: [2/2] | Iterations: [1248/1995] | Training loss: 0.081\n",
            "Epoch: [2/2] | Iterations: [1249/1995] | Training loss: 0.086\n",
            "Epoch: [2/2] | Iterations: [1250/1995] | Training loss: 0.102\n",
            "Epoch: [2/2] | Iterations: [1251/1995] | Training loss: 0.125\n",
            "Epoch: [2/2] | Iterations: [1252/1995] | Training loss: 0.072\n",
            "Epoch: [2/2] | Iterations: [1253/1995] | Training loss: 0.080\n",
            "Epoch: [2/2] | Iterations: [1254/1995] | Training loss: 0.138\n",
            "Epoch: [2/2] | Iterations: [1255/1995] | Training loss: 0.195\n",
            "Epoch: [2/2] | Iterations: [1256/1995] | Training loss: 0.064\n",
            "Epoch: [2/2] | Iterations: [1257/1995] | Training loss: 0.082\n",
            "Epoch: [2/2] | Iterations: [1258/1995] | Training loss: 0.080\n",
            "Epoch: [2/2] | Iterations: [1259/1995] | Training loss: 0.066\n",
            "Epoch: [2/2] | Iterations: [1260/1995] | Training loss: 0.211\n",
            "Epoch: [2/2] | Iterations: [1261/1995] | Training loss: 0.128\n",
            "Epoch: [2/2] | Iterations: [1262/1995] | Training loss: 0.151\n",
            "Epoch: [2/2] | Iterations: [1263/1995] | Training loss: 0.046\n",
            "Epoch: [2/2] | Iterations: [1264/1995] | Training loss: 0.052\n",
            "Epoch: [2/2] | Iterations: [1265/1995] | Training loss: 0.102\n",
            "Epoch: [2/2] | Iterations: [1266/1995] | Training loss: 0.158\n",
            "Epoch: [2/2] | Iterations: [1267/1995] | Training loss: 0.092\n",
            "Epoch: [2/2] | Iterations: [1268/1995] | Training loss: 0.101\n",
            "Epoch: [2/2] | Iterations: [1269/1995] | Training loss: 0.075\n",
            "Epoch: [2/2] | Iterations: [1270/1995] | Training loss: 0.126\n",
            "Epoch: [2/2] | Iterations: [1271/1995] | Training loss: 0.136\n",
            "Epoch: [2/2] | Iterations: [1272/1995] | Training loss: 0.050\n",
            "Epoch: [2/2] | Iterations: [1273/1995] | Training loss: 0.062\n",
            "Epoch: [2/2] | Iterations: [1274/1995] | Training loss: 0.088\n",
            "Epoch: [2/2] | Iterations: [1275/1995] | Training loss: 0.066\n",
            "Epoch: [2/2] | Iterations: [1276/1995] | Training loss: 0.072\n",
            "Epoch: [2/2] | Iterations: [1277/1995] | Training loss: 0.117\n",
            "Epoch: [2/2] | Iterations: [1278/1995] | Training loss: 0.062\n",
            "Epoch: [2/2] | Iterations: [1279/1995] | Training loss: 0.142\n",
            "Epoch: [2/2] | Iterations: [1280/1995] | Training loss: 0.152\n",
            "Epoch: [2/2] | Iterations: [1281/1995] | Training loss: 0.114\n",
            "Epoch: [2/2] | Iterations: [1282/1995] | Training loss: 0.095\n",
            "Epoch: [2/2] | Iterations: [1283/1995] | Training loss: 0.081\n",
            "Epoch: [2/2] | Iterations: [1284/1995] | Training loss: 0.109\n",
            "Epoch: [2/2] | Iterations: [1285/1995] | Training loss: 0.096\n",
            "Epoch: [2/2] | Iterations: [1286/1995] | Training loss: 0.079\n",
            "Epoch: [2/2] | Iterations: [1287/1995] | Training loss: 0.076\n",
            "Epoch: [2/2] | Iterations: [1288/1995] | Training loss: 0.067\n",
            "Epoch: [2/2] | Iterations: [1289/1995] | Training loss: 0.082\n",
            "Epoch: [2/2] | Iterations: [1290/1995] | Training loss: 0.115\n",
            "Epoch: [2/2] | Iterations: [1291/1995] | Training loss: 0.072\n",
            "Epoch: [2/2] | Iterations: [1292/1995] | Training loss: 0.100\n",
            "Epoch: [2/2] | Iterations: [1293/1995] | Training loss: 0.132\n",
            "Epoch: [2/2] | Iterations: [1294/1995] | Training loss: 0.071\n",
            "Epoch: [2/2] | Iterations: [1295/1995] | Training loss: 0.125\n",
            "Epoch: [2/2] | Iterations: [1296/1995] | Training loss: 0.081\n",
            "Epoch: [2/2] | Iterations: [1297/1995] | Training loss: 0.068\n",
            "Epoch: [2/2] | Iterations: [1298/1995] | Training loss: 0.149\n",
            "Epoch: [2/2] | Iterations: [1299/1995] | Training loss: 0.103\n",
            "Epoch: [2/2] | Iterations: [1300/1995] | Training loss: 0.069\n",
            "Epoch: [2/2] | Iterations: [1301/1995] | Training loss: 0.084\n",
            "Epoch: [2/2] | Iterations: [1302/1995] | Training loss: 0.087\n",
            "Epoch: [2/2] | Iterations: [1303/1995] | Training loss: 0.118\n",
            "Epoch: [2/2] | Iterations: [1304/1995] | Training loss: 0.054\n",
            "Epoch: [2/2] | Iterations: [1305/1995] | Training loss: 0.060\n",
            "Epoch: [2/2] | Iterations: [1306/1995] | Training loss: 0.100\n",
            "Epoch: [2/2] | Iterations: [1307/1995] | Training loss: 0.126\n",
            "Epoch: [2/2] | Iterations: [1308/1995] | Training loss: 0.048\n",
            "Epoch: [2/2] | Iterations: [1309/1995] | Training loss: 0.146\n",
            "Epoch: [2/2] | Iterations: [1310/1995] | Training loss: 0.103\n",
            "Epoch: [2/2] | Iterations: [1311/1995] | Training loss: 0.043\n",
            "Epoch: [2/2] | Iterations: [1312/1995] | Training loss: 0.107\n",
            "Epoch: [2/2] | Iterations: [1313/1995] | Training loss: 0.068\n",
            "Epoch: [2/2] | Iterations: [1314/1995] | Training loss: 0.121\n",
            "Epoch: [2/2] | Iterations: [1315/1995] | Training loss: 0.084\n",
            "Epoch: [2/2] | Iterations: [1316/1995] | Training loss: 0.054\n",
            "Epoch: [2/2] | Iterations: [1317/1995] | Training loss: 0.063\n",
            "Epoch: [2/2] | Iterations: [1318/1995] | Training loss: 0.139\n",
            "Epoch: [2/2] | Iterations: [1319/1995] | Training loss: 0.080\n",
            "Epoch: [2/2] | Iterations: [1320/1995] | Training loss: 0.039\n",
            "Epoch: [2/2] | Iterations: [1321/1995] | Training loss: 0.086\n",
            "Epoch: [2/2] | Iterations: [1322/1995] | Training loss: 0.048\n",
            "Epoch: [2/2] | Iterations: [1323/1995] | Training loss: 0.056\n",
            "Epoch: [2/2] | Iterations: [1324/1995] | Training loss: 0.128\n",
            "Epoch: [2/2] | Iterations: [1325/1995] | Training loss: 0.111\n",
            "Epoch: [2/2] | Iterations: [1326/1995] | Training loss: 0.082\n",
            "Epoch: [2/2] | Iterations: [1327/1995] | Training loss: 0.076\n",
            "Epoch: [2/2] | Iterations: [1328/1995] | Training loss: 0.118\n",
            "Epoch: [2/2] | Iterations: [1329/1995] | Training loss: 0.033\n",
            "Epoch: [2/2] | Iterations: [1330/1995] | Training loss: 0.095\n",
            "Epoch: [2/2] | Iterations: [1331/1995] | Training loss: 0.112\n",
            "Epoch: [2/2] | Iterations: [1332/1995] | Training loss: 0.100\n",
            "Epoch: [2/2] | Iterations: [1333/1995] | Training loss: 0.111\n",
            "Epoch: [2/2] | Iterations: [1334/1995] | Training loss: 0.052\n",
            "Epoch: [2/2] | Iterations: [1335/1995] | Training loss: 0.160\n",
            "Epoch: [2/2] | Iterations: [1336/1995] | Training loss: 0.095\n",
            "Epoch: [2/2] | Iterations: [1337/1995] | Training loss: 0.116\n",
            "Epoch: [2/2] | Iterations: [1338/1995] | Training loss: 0.175\n",
            "Epoch: [2/2] | Iterations: [1339/1995] | Training loss: 0.126\n",
            "Epoch: [2/2] | Iterations: [1340/1995] | Training loss: 0.065\n",
            "Epoch: [2/2] | Iterations: [1341/1995] | Training loss: 0.117\n",
            "Epoch: [2/2] | Iterations: [1342/1995] | Training loss: 0.090\n",
            "Epoch: [2/2] | Iterations: [1343/1995] | Training loss: 0.066\n",
            "Epoch: [2/2] | Iterations: [1344/1995] | Training loss: 0.050\n",
            "Epoch: [2/2] | Iterations: [1345/1995] | Training loss: 0.078\n",
            "Epoch: [2/2] | Iterations: [1346/1995] | Training loss: 0.089\n",
            "Epoch: [2/2] | Iterations: [1347/1995] | Training loss: 0.137\n",
            "Epoch: [2/2] | Iterations: [1348/1995] | Training loss: 0.086\n",
            "Epoch: [2/2] | Iterations: [1349/1995] | Training loss: 0.069\n",
            "Epoch: [2/2] | Iterations: [1350/1995] | Training loss: 0.137\n",
            "Epoch: [2/2] | Iterations: [1351/1995] | Training loss: 0.083\n",
            "Epoch: [2/2] | Iterations: [1352/1995] | Training loss: 0.129\n",
            "Epoch: [2/2] | Iterations: [1353/1995] | Training loss: 0.093\n",
            "Epoch: [2/2] | Iterations: [1354/1995] | Training loss: 0.104\n",
            "Epoch: [2/2] | Iterations: [1355/1995] | Training loss: 0.163\n",
            "Epoch: [2/2] | Iterations: [1356/1995] | Training loss: 0.043\n",
            "Epoch: [2/2] | Iterations: [1357/1995] | Training loss: 0.068\n",
            "Epoch: [2/2] | Iterations: [1358/1995] | Training loss: 0.125\n",
            "Epoch: [2/2] | Iterations: [1359/1995] | Training loss: 0.107\n",
            "Epoch: [2/2] | Iterations: [1360/1995] | Training loss: 0.050\n",
            "Epoch: [2/2] | Iterations: [1361/1995] | Training loss: 0.059\n",
            "Epoch: [2/2] | Iterations: [1362/1995] | Training loss: 0.055\n",
            "Epoch: [2/2] | Iterations: [1363/1995] | Training loss: 0.107\n",
            "Epoch: [2/2] | Iterations: [1364/1995] | Training loss: 0.098\n",
            "Epoch: [2/2] | Iterations: [1365/1995] | Training loss: 0.139\n",
            "Epoch: [2/2] | Iterations: [1366/1995] | Training loss: 0.085\n",
            "Epoch: [2/2] | Iterations: [1367/1995] | Training loss: 0.063\n",
            "Epoch: [2/2] | Iterations: [1368/1995] | Training loss: 0.095\n",
            "Epoch: [2/2] | Iterations: [1369/1995] | Training loss: 0.060\n",
            "Epoch: [2/2] | Iterations: [1370/1995] | Training loss: 0.061\n",
            "Epoch: [2/2] | Iterations: [1371/1995] | Training loss: 0.068\n",
            "Epoch: [2/2] | Iterations: [1372/1995] | Training loss: 0.077\n",
            "Epoch: [2/2] | Iterations: [1373/1995] | Training loss: 0.050\n",
            "Epoch: [2/2] | Iterations: [1374/1995] | Training loss: 0.056\n",
            "Epoch: [2/2] | Iterations: [1375/1995] | Training loss: 0.072\n",
            "Epoch: [2/2] | Iterations: [1376/1995] | Training loss: 0.128\n",
            "Epoch: [2/2] | Iterations: [1377/1995] | Training loss: 0.077\n",
            "Epoch: [2/2] | Iterations: [1378/1995] | Training loss: 0.127\n",
            "Epoch: [2/2] | Iterations: [1379/1995] | Training loss: 0.103\n",
            "Epoch: [2/2] | Iterations: [1380/1995] | Training loss: 0.065\n",
            "Epoch: [2/2] | Iterations: [1381/1995] | Training loss: 0.122\n",
            "Epoch: [2/2] | Iterations: [1382/1995] | Training loss: 0.052\n",
            "Epoch: [2/2] | Iterations: [1383/1995] | Training loss: 0.106\n",
            "Epoch: [2/2] | Iterations: [1384/1995] | Training loss: 0.084\n",
            "Epoch: [2/2] | Iterations: [1385/1995] | Training loss: 0.030\n",
            "Epoch: [2/2] | Iterations: [1386/1995] | Training loss: 0.123\n",
            "Epoch: [2/2] | Iterations: [1387/1995] | Training loss: 0.058\n",
            "Epoch: [2/2] | Iterations: [1388/1995] | Training loss: 0.084\n",
            "Epoch: [2/2] | Iterations: [1389/1995] | Training loss: 0.078\n",
            "Epoch: [2/2] | Iterations: [1390/1995] | Training loss: 0.070\n",
            "Epoch: [2/2] | Iterations: [1391/1995] | Training loss: 0.078\n",
            "Epoch: [2/2] | Iterations: [1392/1995] | Training loss: 0.093\n",
            "Epoch: [2/2] | Iterations: [1393/1995] | Training loss: 0.050\n",
            "Epoch: [2/2] | Iterations: [1394/1995] | Training loss: 0.087\n",
            "Epoch: [2/2] | Iterations: [1395/1995] | Training loss: 0.096\n",
            "Epoch: [2/2] | Iterations: [1396/1995] | Training loss: 0.083\n",
            "Epoch: [2/2] | Iterations: [1397/1995] | Training loss: 0.089\n",
            "Epoch: [2/2] | Iterations: [1398/1995] | Training loss: 0.149\n",
            "Epoch: [2/2] | Iterations: [1399/1995] | Training loss: 0.044\n",
            "Epoch: [2/2] | Iterations: [1400/1995] | Training loss: 0.065\n",
            "Epoch: [2/2] | Iterations: [1401/1995] | Training loss: 0.080\n",
            "Epoch: [2/2] | Iterations: [1402/1995] | Training loss: 0.100\n",
            "Epoch: [2/2] | Iterations: [1403/1995] | Training loss: 0.118\n",
            "Epoch: [2/2] | Iterations: [1404/1995] | Training loss: 0.068\n",
            "Epoch: [2/2] | Iterations: [1405/1995] | Training loss: 0.083\n",
            "Epoch: [2/2] | Iterations: [1406/1995] | Training loss: 0.134\n",
            "Epoch: [2/2] | Iterations: [1407/1995] | Training loss: 0.045\n",
            "Epoch: [2/2] | Iterations: [1408/1995] | Training loss: 0.051\n",
            "Epoch: [2/2] | Iterations: [1409/1995] | Training loss: 0.102\n",
            "Epoch: [2/2] | Iterations: [1410/1995] | Training loss: 0.132\n",
            "Epoch: [2/2] | Iterations: [1411/1995] | Training loss: 0.096\n",
            "Epoch: [2/2] | Iterations: [1412/1995] | Training loss: 0.074\n",
            "Epoch: [2/2] | Iterations: [1413/1995] | Training loss: 0.062\n",
            "Epoch: [2/2] | Iterations: [1414/1995] | Training loss: 0.112\n",
            "Epoch: [2/2] | Iterations: [1415/1995] | Training loss: 0.079\n",
            "Epoch: [2/2] | Iterations: [1416/1995] | Training loss: 0.095\n",
            "Epoch: [2/2] | Iterations: [1417/1995] | Training loss: 0.107\n",
            "Epoch: [2/2] | Iterations: [1418/1995] | Training loss: 0.107\n",
            "Epoch: [2/2] | Iterations: [1419/1995] | Training loss: 0.114\n",
            "Epoch: [2/2] | Iterations: [1420/1995] | Training loss: 0.043\n",
            "Epoch: [2/2] | Iterations: [1421/1995] | Training loss: 0.080\n",
            "Epoch: [2/2] | Iterations: [1422/1995] | Training loss: 0.056\n",
            "Epoch: [2/2] | Iterations: [1423/1995] | Training loss: 0.162\n",
            "Epoch: [2/2] | Iterations: [1424/1995] | Training loss: 0.124\n",
            "Epoch: [2/2] | Iterations: [1425/1995] | Training loss: 0.097\n",
            "Epoch: [2/2] | Iterations: [1426/1995] | Training loss: 0.129\n",
            "Epoch: [2/2] | Iterations: [1427/1995] | Training loss: 0.057\n",
            "Epoch: [2/2] | Iterations: [1428/1995] | Training loss: 0.084\n",
            "Epoch: [2/2] | Iterations: [1429/1995] | Training loss: 0.140\n",
            "Epoch: [2/2] | Iterations: [1430/1995] | Training loss: 0.055\n",
            "Epoch: [2/2] | Iterations: [1431/1995] | Training loss: 0.100\n",
            "Epoch: [2/2] | Iterations: [1432/1995] | Training loss: 0.089\n",
            "Epoch: [2/2] | Iterations: [1433/1995] | Training loss: 0.063\n",
            "Epoch: [2/2] | Iterations: [1434/1995] | Training loss: 0.065\n",
            "Epoch: [2/2] | Iterations: [1435/1995] | Training loss: 0.047\n",
            "Epoch: [2/2] | Iterations: [1436/1995] | Training loss: 0.112\n",
            "Epoch: [2/2] | Iterations: [1437/1995] | Training loss: 0.133\n",
            "Epoch: [2/2] | Iterations: [1438/1995] | Training loss: 0.118\n",
            "Epoch: [2/2] | Iterations: [1439/1995] | Training loss: 0.126\n",
            "Epoch: [2/2] | Iterations: [1440/1995] | Training loss: 0.119\n",
            "Epoch: [2/2] | Iterations: [1441/1995] | Training loss: 0.051\n",
            "Epoch: [2/2] | Iterations: [1442/1995] | Training loss: 0.038\n",
            "Epoch: [2/2] | Iterations: [1443/1995] | Training loss: 0.098\n",
            "Epoch: [2/2] | Iterations: [1444/1995] | Training loss: 0.082\n",
            "Epoch: [2/2] | Iterations: [1445/1995] | Training loss: 0.086\n",
            "Epoch: [2/2] | Iterations: [1446/1995] | Training loss: 0.092\n",
            "Epoch: [2/2] | Iterations: [1447/1995] | Training loss: 0.092\n",
            "Epoch: [2/2] | Iterations: [1448/1995] | Training loss: 0.080\n",
            "Epoch: [2/2] | Iterations: [1449/1995] | Training loss: 0.118\n",
            "Epoch: [2/2] | Iterations: [1450/1995] | Training loss: 0.120\n",
            "Epoch: [2/2] | Iterations: [1451/1995] | Training loss: 0.056\n",
            "Epoch: [2/2] | Iterations: [1452/1995] | Training loss: 0.160\n",
            "Epoch: [2/2] | Iterations: [1453/1995] | Training loss: 0.073\n",
            "Epoch: [2/2] | Iterations: [1454/1995] | Training loss: 0.075\n",
            "Epoch: [2/2] | Iterations: [1455/1995] | Training loss: 0.136\n",
            "Epoch: [2/2] | Iterations: [1456/1995] | Training loss: 0.079\n",
            "Epoch: [2/2] | Iterations: [1457/1995] | Training loss: 0.108\n",
            "Epoch: [2/2] | Iterations: [1458/1995] | Training loss: 0.082\n",
            "Epoch: [2/2] | Iterations: [1459/1995] | Training loss: 0.060\n",
            "Epoch: [2/2] | Iterations: [1460/1995] | Training loss: 0.111\n",
            "Epoch: [2/2] | Iterations: [1461/1995] | Training loss: 0.185\n",
            "Epoch: [2/2] | Iterations: [1462/1995] | Training loss: 0.166\n",
            "Epoch: [2/2] | Iterations: [1463/1995] | Training loss: 0.062\n",
            "Epoch: [2/2] | Iterations: [1464/1995] | Training loss: 0.116\n",
            "Epoch: [2/2] | Iterations: [1465/1995] | Training loss: 0.077\n",
            "Epoch: [2/2] | Iterations: [1466/1995] | Training loss: 0.120\n",
            "Epoch: [2/2] | Iterations: [1467/1995] | Training loss: 0.081\n",
            "Epoch: [2/2] | Iterations: [1468/1995] | Training loss: 0.130\n",
            "Epoch: [2/2] | Iterations: [1469/1995] | Training loss: 0.141\n",
            "Epoch: [2/2] | Iterations: [1470/1995] | Training loss: 0.129\n",
            "Epoch: [2/2] | Iterations: [1471/1995] | Training loss: 0.079\n",
            "Epoch: [2/2] | Iterations: [1472/1995] | Training loss: 0.100\n",
            "Epoch: [2/2] | Iterations: [1473/1995] | Training loss: 0.081\n",
            "Epoch: [2/2] | Iterations: [1474/1995] | Training loss: 0.056\n",
            "Epoch: [2/2] | Iterations: [1475/1995] | Training loss: 0.136\n",
            "Epoch: [2/2] | Iterations: [1476/1995] | Training loss: 0.099\n",
            "Epoch: [2/2] | Iterations: [1477/1995] | Training loss: 0.144\n",
            "Epoch: [2/2] | Iterations: [1478/1995] | Training loss: 0.053\n",
            "Epoch: [2/2] | Iterations: [1479/1995] | Training loss: 0.080\n",
            "Epoch: [2/2] | Iterations: [1480/1995] | Training loss: 0.073\n",
            "Epoch: [2/2] | Iterations: [1481/1995] | Training loss: 0.082\n",
            "Epoch: [2/2] | Iterations: [1482/1995] | Training loss: 0.088\n",
            "Epoch: [2/2] | Iterations: [1483/1995] | Training loss: 0.055\n",
            "Epoch: [2/2] | Iterations: [1484/1995] | Training loss: 0.098\n",
            "Epoch: [2/2] | Iterations: [1485/1995] | Training loss: 0.093\n",
            "Epoch: [2/2] | Iterations: [1486/1995] | Training loss: 0.084\n",
            "Epoch: [2/2] | Iterations: [1487/1995] | Training loss: 0.054\n",
            "Epoch: [2/2] | Iterations: [1488/1995] | Training loss: 0.108\n",
            "Epoch: [2/2] | Iterations: [1489/1995] | Training loss: 0.077\n",
            "Epoch: [2/2] | Iterations: [1490/1995] | Training loss: 0.123\n",
            "Epoch: [2/2] | Iterations: [1491/1995] | Training loss: 0.087\n",
            "Epoch: [2/2] | Iterations: [1492/1995] | Training loss: 0.061\n",
            "Epoch: [2/2] | Iterations: [1493/1995] | Training loss: 0.057\n",
            "Epoch: [2/2] | Iterations: [1494/1995] | Training loss: 0.118\n",
            "Epoch: [2/2] | Iterations: [1495/1995] | Training loss: 0.074\n",
            "Epoch: [2/2] | Iterations: [1496/1995] | Training loss: 0.047\n",
            "Epoch: [2/2] | Iterations: [1497/1995] | Training loss: 0.102\n",
            "Epoch: [2/2] | Iterations: [1498/1995] | Training loss: 0.072\n",
            "Epoch: [2/2] | Iterations: [1499/1995] | Training loss: 0.074\n",
            "Epoch: [2/2] | Iterations: [1500/1995] | Training loss: 0.066\n",
            "Epoch: [2/2] | Iterations: [1501/1995] | Training loss: 0.107\n",
            "Epoch: [2/2] | Iterations: [1502/1995] | Training loss: 0.045\n",
            "Epoch: [2/2] | Iterations: [1503/1995] | Training loss: 0.065\n",
            "Epoch: [2/2] | Iterations: [1504/1995] | Training loss: 0.073\n",
            "Epoch: [2/2] | Iterations: [1505/1995] | Training loss: 0.085\n",
            "Epoch: [2/2] | Iterations: [1506/1995] | Training loss: 0.048\n",
            "Epoch: [2/2] | Iterations: [1507/1995] | Training loss: 0.083\n",
            "Epoch: [2/2] | Iterations: [1508/1995] | Training loss: 0.060\n",
            "Epoch: [2/2] | Iterations: [1509/1995] | Training loss: 0.138\n",
            "Epoch: [2/2] | Iterations: [1510/1995] | Training loss: 0.062\n",
            "Epoch: [2/2] | Iterations: [1511/1995] | Training loss: 0.042\n",
            "Epoch: [2/2] | Iterations: [1512/1995] | Training loss: 0.079\n",
            "Epoch: [2/2] | Iterations: [1513/1995] | Training loss: 0.114\n",
            "Epoch: [2/2] | Iterations: [1514/1995] | Training loss: 0.068\n",
            "Epoch: [2/2] | Iterations: [1515/1995] | Training loss: 0.079\n",
            "Epoch: [2/2] | Iterations: [1516/1995] | Training loss: 0.066\n",
            "Epoch: [2/2] | Iterations: [1517/1995] | Training loss: 0.109\n",
            "Epoch: [2/2] | Iterations: [1518/1995] | Training loss: 0.117\n",
            "Epoch: [2/2] | Iterations: [1519/1995] | Training loss: 0.079\n",
            "Epoch: [2/2] | Iterations: [1520/1995] | Training loss: 0.091\n",
            "Epoch: [2/2] | Iterations: [1521/1995] | Training loss: 0.059\n",
            "Epoch: [2/2] | Iterations: [1522/1995] | Training loss: 0.071\n",
            "Epoch: [2/2] | Iterations: [1523/1995] | Training loss: 0.068\n",
            "Epoch: [2/2] | Iterations: [1524/1995] | Training loss: 0.075\n",
            "Epoch: [2/2] | Iterations: [1525/1995] | Training loss: 0.141\n",
            "Epoch: [2/2] | Iterations: [1526/1995] | Training loss: 0.162\n",
            "Epoch: [2/2] | Iterations: [1527/1995] | Training loss: 0.123\n",
            "Epoch: [2/2] | Iterations: [1528/1995] | Training loss: 0.071\n",
            "Epoch: [2/2] | Iterations: [1529/1995] | Training loss: 0.105\n",
            "Epoch: [2/2] | Iterations: [1530/1995] | Training loss: 0.149\n",
            "Epoch: [2/2] | Iterations: [1531/1995] | Training loss: 0.075\n",
            "Epoch: [2/2] | Iterations: [1532/1995] | Training loss: 0.100\n",
            "Epoch: [2/2] | Iterations: [1533/1995] | Training loss: 0.060\n",
            "Epoch: [2/2] | Iterations: [1534/1995] | Training loss: 0.047\n",
            "Epoch: [2/2] | Iterations: [1535/1995] | Training loss: 0.099\n",
            "Epoch: [2/2] | Iterations: [1536/1995] | Training loss: 0.037\n",
            "Epoch: [2/2] | Iterations: [1537/1995] | Training loss: 0.084\n",
            "Epoch: [2/2] | Iterations: [1538/1995] | Training loss: 0.091\n",
            "Epoch: [2/2] | Iterations: [1539/1995] | Training loss: 0.103\n",
            "Epoch: [2/2] | Iterations: [1540/1995] | Training loss: 0.096\n",
            "Epoch: [2/2] | Iterations: [1541/1995] | Training loss: 0.059\n",
            "Epoch: [2/2] | Iterations: [1542/1995] | Training loss: 0.136\n",
            "Epoch: [2/2] | Iterations: [1543/1995] | Training loss: 0.071\n",
            "Epoch: [2/2] | Iterations: [1544/1995] | Training loss: 0.097\n",
            "Epoch: [2/2] | Iterations: [1545/1995] | Training loss: 0.091\n",
            "Epoch: [2/2] | Iterations: [1546/1995] | Training loss: 0.052\n",
            "Epoch: [2/2] | Iterations: [1547/1995] | Training loss: 0.085\n",
            "Epoch: [2/2] | Iterations: [1548/1995] | Training loss: 0.091\n",
            "Epoch: [2/2] | Iterations: [1549/1995] | Training loss: 0.088\n",
            "Epoch: [2/2] | Iterations: [1550/1995] | Training loss: 0.068\n",
            "Epoch: [2/2] | Iterations: [1551/1995] | Training loss: 0.063\n",
            "Epoch: [2/2] | Iterations: [1552/1995] | Training loss: 0.079\n",
            "Epoch: [2/2] | Iterations: [1553/1995] | Training loss: 0.101\n",
            "Epoch: [2/2] | Iterations: [1554/1995] | Training loss: 0.051\n",
            "Epoch: [2/2] | Iterations: [1555/1995] | Training loss: 0.098\n",
            "Epoch: [2/2] | Iterations: [1556/1995] | Training loss: 0.073\n",
            "Epoch: [2/2] | Iterations: [1557/1995] | Training loss: 0.086\n",
            "Epoch: [2/2] | Iterations: [1558/1995] | Training loss: 0.188\n",
            "Epoch: [2/2] | Iterations: [1559/1995] | Training loss: 0.098\n",
            "Epoch: [2/2] | Iterations: [1560/1995] | Training loss: 0.141\n",
            "Epoch: [2/2] | Iterations: [1561/1995] | Training loss: 0.070\n",
            "Epoch: [2/2] | Iterations: [1562/1995] | Training loss: 0.074\n",
            "Epoch: [2/2] | Iterations: [1563/1995] | Training loss: 0.094\n",
            "Epoch: [2/2] | Iterations: [1564/1995] | Training loss: 0.098\n",
            "Epoch: [2/2] | Iterations: [1565/1995] | Training loss: 0.113\n",
            "Epoch: [2/2] | Iterations: [1566/1995] | Training loss: 0.129\n",
            "Epoch: [2/2] | Iterations: [1567/1995] | Training loss: 0.143\n",
            "Epoch: [2/2] | Iterations: [1568/1995] | Training loss: 0.091\n",
            "Epoch: [2/2] | Iterations: [1569/1995] | Training loss: 0.064\n",
            "Epoch: [2/2] | Iterations: [1570/1995] | Training loss: 0.097\n",
            "Epoch: [2/2] | Iterations: [1571/1995] | Training loss: 0.114\n",
            "Epoch: [2/2] | Iterations: [1572/1995] | Training loss: 0.097\n",
            "Epoch: [2/2] | Iterations: [1573/1995] | Training loss: 0.155\n",
            "Epoch: [2/2] | Iterations: [1574/1995] | Training loss: 0.064\n",
            "Epoch: [2/2] | Iterations: [1575/1995] | Training loss: 0.032\n",
            "Epoch: [2/2] | Iterations: [1576/1995] | Training loss: 0.104\n",
            "Epoch: [2/2] | Iterations: [1577/1995] | Training loss: 0.089\n",
            "Epoch: [2/2] | Iterations: [1578/1995] | Training loss: 0.099\n",
            "Epoch: [2/2] | Iterations: [1579/1995] | Training loss: 0.139\n",
            "Epoch: [2/2] | Iterations: [1580/1995] | Training loss: 0.090\n",
            "Epoch: [2/2] | Iterations: [1581/1995] | Training loss: 0.122\n",
            "Epoch: [2/2] | Iterations: [1582/1995] | Training loss: 0.111\n",
            "Epoch: [2/2] | Iterations: [1583/1995] | Training loss: 0.100\n",
            "Epoch: [2/2] | Iterations: [1584/1995] | Training loss: 0.118\n",
            "Epoch: [2/2] | Iterations: [1585/1995] | Training loss: 0.050\n",
            "Epoch: [2/2] | Iterations: [1586/1995] | Training loss: 0.068\n",
            "Epoch: [2/2] | Iterations: [1587/1995] | Training loss: 0.041\n",
            "Epoch: [2/2] | Iterations: [1588/1995] | Training loss: 0.155\n",
            "Epoch: [2/2] | Iterations: [1589/1995] | Training loss: 0.087\n",
            "Epoch: [2/2] | Iterations: [1590/1995] | Training loss: 0.060\n",
            "Epoch: [2/2] | Iterations: [1591/1995] | Training loss: 0.117\n",
            "Epoch: [2/2] | Iterations: [1592/1995] | Training loss: 0.074\n",
            "Epoch: [2/2] | Iterations: [1593/1995] | Training loss: 0.104\n",
            "Epoch: [2/2] | Iterations: [1594/1995] | Training loss: 0.111\n",
            "Epoch: [2/2] | Iterations: [1595/1995] | Training loss: 0.114\n",
            "Epoch: [2/2] | Iterations: [1596/1995] | Training loss: 0.087\n",
            "Epoch: [2/2] | Iterations: [1597/1995] | Training loss: 0.070\n",
            "Epoch: [2/2] | Iterations: [1598/1995] | Training loss: 0.062\n",
            "Epoch: [2/2] | Iterations: [1599/1995] | Training loss: 0.149\n",
            "Epoch: [2/2] | Iterations: [1600/1995] | Training loss: 0.093\n",
            "Epoch: [2/2] | Iterations: [1601/1995] | Training loss: 0.099\n",
            "Epoch: [2/2] | Iterations: [1602/1995] | Training loss: 0.095\n",
            "Epoch: [2/2] | Iterations: [1603/1995] | Training loss: 0.076\n",
            "Epoch: [2/2] | Iterations: [1604/1995] | Training loss: 0.043\n",
            "Epoch: [2/2] | Iterations: [1605/1995] | Training loss: 0.085\n",
            "Epoch: [2/2] | Iterations: [1606/1995] | Training loss: 0.072\n",
            "Epoch: [2/2] | Iterations: [1607/1995] | Training loss: 0.054\n",
            "Epoch: [2/2] | Iterations: [1608/1995] | Training loss: 0.047\n",
            "Epoch: [2/2] | Iterations: [1609/1995] | Training loss: 0.085\n",
            "Epoch: [2/2] | Iterations: [1610/1995] | Training loss: 0.134\n",
            "Epoch: [2/2] | Iterations: [1611/1995] | Training loss: 0.080\n",
            "Epoch: [2/2] | Iterations: [1612/1995] | Training loss: 0.053\n",
            "Epoch: [2/2] | Iterations: [1613/1995] | Training loss: 0.069\n",
            "Epoch: [2/2] | Iterations: [1614/1995] | Training loss: 0.054\n",
            "Epoch: [2/2] | Iterations: [1615/1995] | Training loss: 0.075\n",
            "Epoch: [2/2] | Iterations: [1616/1995] | Training loss: 0.057\n",
            "Epoch: [2/2] | Iterations: [1617/1995] | Training loss: 0.141\n",
            "Epoch: [2/2] | Iterations: [1618/1995] | Training loss: 0.053\n",
            "Epoch: [2/2] | Iterations: [1619/1995] | Training loss: 0.076\n",
            "Epoch: [2/2] | Iterations: [1620/1995] | Training loss: 0.051\n",
            "Epoch: [2/2] | Iterations: [1621/1995] | Training loss: 0.076\n",
            "Epoch: [2/2] | Iterations: [1622/1995] | Training loss: 0.077\n",
            "Epoch: [2/2] | Iterations: [1623/1995] | Training loss: 0.088\n",
            "Epoch: [2/2] | Iterations: [1624/1995] | Training loss: 0.146\n",
            "Epoch: [2/2] | Iterations: [1625/1995] | Training loss: 0.076\n",
            "Epoch: [2/2] | Iterations: [1626/1995] | Training loss: 0.071\n",
            "Epoch: [2/2] | Iterations: [1627/1995] | Training loss: 0.077\n",
            "Epoch: [2/2] | Iterations: [1628/1995] | Training loss: 0.099\n",
            "Epoch: [2/2] | Iterations: [1629/1995] | Training loss: 0.067\n",
            "Epoch: [2/2] | Iterations: [1630/1995] | Training loss: 0.109\n",
            "Epoch: [2/2] | Iterations: [1631/1995] | Training loss: 0.108\n",
            "Epoch: [2/2] | Iterations: [1632/1995] | Training loss: 0.055\n",
            "Epoch: [2/2] | Iterations: [1633/1995] | Training loss: 0.141\n",
            "Epoch: [2/2] | Iterations: [1634/1995] | Training loss: 0.130\n",
            "Epoch: [2/2] | Iterations: [1635/1995] | Training loss: 0.117\n",
            "Epoch: [2/2] | Iterations: [1636/1995] | Training loss: 0.145\n",
            "Epoch: [2/2] | Iterations: [1637/1995] | Training loss: 0.078\n",
            "Epoch: [2/2] | Iterations: [1638/1995] | Training loss: 0.044\n",
            "Epoch: [2/2] | Iterations: [1639/1995] | Training loss: 0.054\n",
            "Epoch: [2/2] | Iterations: [1640/1995] | Training loss: 0.078\n",
            "Epoch: [2/2] | Iterations: [1641/1995] | Training loss: 0.048\n",
            "Epoch: [2/2] | Iterations: [1642/1995] | Training loss: 0.051\n",
            "Epoch: [2/2] | Iterations: [1643/1995] | Training loss: 0.124\n",
            "Epoch: [2/2] | Iterations: [1644/1995] | Training loss: 0.086\n",
            "Epoch: [2/2] | Iterations: [1645/1995] | Training loss: 0.121\n",
            "Epoch: [2/2] | Iterations: [1646/1995] | Training loss: 0.048\n",
            "Epoch: [2/2] | Iterations: [1647/1995] | Training loss: 0.117\n",
            "Epoch: [2/2] | Iterations: [1648/1995] | Training loss: 0.113\n",
            "Epoch: [2/2] | Iterations: [1649/1995] | Training loss: 0.077\n",
            "Epoch: [2/2] | Iterations: [1650/1995] | Training loss: 0.120\n",
            "Epoch: [2/2] | Iterations: [1651/1995] | Training loss: 0.090\n",
            "Epoch: [2/2] | Iterations: [1652/1995] | Training loss: 0.158\n",
            "Epoch: [2/2] | Iterations: [1653/1995] | Training loss: 0.082\n",
            "Epoch: [2/2] | Iterations: [1654/1995] | Training loss: 0.143\n",
            "Epoch: [2/2] | Iterations: [1655/1995] | Training loss: 0.092\n",
            "Epoch: [2/2] | Iterations: [1656/1995] | Training loss: 0.128\n",
            "Epoch: [2/2] | Iterations: [1657/1995] | Training loss: 0.089\n",
            "Epoch: [2/2] | Iterations: [1658/1995] | Training loss: 0.076\n",
            "Epoch: [2/2] | Iterations: [1659/1995] | Training loss: 0.092\n",
            "Epoch: [2/2] | Iterations: [1660/1995] | Training loss: 0.067\n",
            "Epoch: [2/2] | Iterations: [1661/1995] | Training loss: 0.112\n",
            "Epoch: [2/2] | Iterations: [1662/1995] | Training loss: 0.091\n",
            "Epoch: [2/2] | Iterations: [1663/1995] | Training loss: 0.095\n",
            "Epoch: [2/2] | Iterations: [1664/1995] | Training loss: 0.142\n",
            "Epoch: [2/2] | Iterations: [1665/1995] | Training loss: 0.070\n",
            "Epoch: [2/2] | Iterations: [1666/1995] | Training loss: 0.153\n",
            "Epoch: [2/2] | Iterations: [1667/1995] | Training loss: 0.088\n",
            "Epoch: [2/2] | Iterations: [1668/1995] | Training loss: 0.134\n",
            "Epoch: [2/2] | Iterations: [1669/1995] | Training loss: 0.092\n",
            "Epoch: [2/2] | Iterations: [1670/1995] | Training loss: 0.050\n",
            "Epoch: [2/2] | Iterations: [1671/1995] | Training loss: 0.116\n",
            "Epoch: [2/2] | Iterations: [1672/1995] | Training loss: 0.100\n",
            "Epoch: [2/2] | Iterations: [1673/1995] | Training loss: 0.083\n",
            "Epoch: [2/2] | Iterations: [1674/1995] | Training loss: 0.071\n",
            "Epoch: [2/2] | Iterations: [1675/1995] | Training loss: 0.096\n",
            "Epoch: [2/2] | Iterations: [1676/1995] | Training loss: 0.062\n",
            "Epoch: [2/2] | Iterations: [1677/1995] | Training loss: 0.065\n",
            "Epoch: [2/2] | Iterations: [1678/1995] | Training loss: 0.072\n",
            "Epoch: [2/2] | Iterations: [1679/1995] | Training loss: 0.081\n",
            "Epoch: [2/2] | Iterations: [1680/1995] | Training loss: 0.046\n",
            "Epoch: [2/2] | Iterations: [1681/1995] | Training loss: 0.082\n",
            "Epoch: [2/2] | Iterations: [1682/1995] | Training loss: 0.065\n",
            "Epoch: [2/2] | Iterations: [1683/1995] | Training loss: 0.124\n",
            "Epoch: [2/2] | Iterations: [1684/1995] | Training loss: 0.077\n",
            "Epoch: [2/2] | Iterations: [1685/1995] | Training loss: 0.096\n",
            "Epoch: [2/2] | Iterations: [1686/1995] | Training loss: 0.066\n",
            "Epoch: [2/2] | Iterations: [1687/1995] | Training loss: 0.076\n",
            "Epoch: [2/2] | Iterations: [1688/1995] | Training loss: 0.137\n",
            "Epoch: [2/2] | Iterations: [1689/1995] | Training loss: 0.037\n",
            "Epoch: [2/2] | Iterations: [1690/1995] | Training loss: 0.102\n",
            "Epoch: [2/2] | Iterations: [1691/1995] | Training loss: 0.130\n",
            "Epoch: [2/2] | Iterations: [1692/1995] | Training loss: 0.117\n",
            "Epoch: [2/2] | Iterations: [1693/1995] | Training loss: 0.059\n",
            "Epoch: [2/2] | Iterations: [1694/1995] | Training loss: 0.063\n",
            "Epoch: [2/2] | Iterations: [1695/1995] | Training loss: 0.069\n",
            "Epoch: [2/2] | Iterations: [1696/1995] | Training loss: 0.066\n",
            "Epoch: [2/2] | Iterations: [1697/1995] | Training loss: 0.067\n",
            "Epoch: [2/2] | Iterations: [1698/1995] | Training loss: 0.105\n",
            "Epoch: [2/2] | Iterations: [1699/1995] | Training loss: 0.097\n",
            "Epoch: [2/2] | Iterations: [1700/1995] | Training loss: 0.051\n",
            "Epoch: [2/2] | Iterations: [1701/1995] | Training loss: 0.082\n",
            "Epoch: [2/2] | Iterations: [1702/1995] | Training loss: 0.039\n",
            "Epoch: [2/2] | Iterations: [1703/1995] | Training loss: 0.081\n",
            "Epoch: [2/2] | Iterations: [1704/1995] | Training loss: 0.072\n",
            "Epoch: [2/2] | Iterations: [1705/1995] | Training loss: 0.052\n",
            "Epoch: [2/2] | Iterations: [1706/1995] | Training loss: 0.047\n",
            "Epoch: [2/2] | Iterations: [1707/1995] | Training loss: 0.083\n",
            "Epoch: [2/2] | Iterations: [1708/1995] | Training loss: 0.056\n",
            "Epoch: [2/2] | Iterations: [1709/1995] | Training loss: 0.104\n",
            "Epoch: [2/2] | Iterations: [1710/1995] | Training loss: 0.055\n",
            "Epoch: [2/2] | Iterations: [1711/1995] | Training loss: 0.069\n",
            "Epoch: [2/2] | Iterations: [1712/1995] | Training loss: 0.132\n",
            "Epoch: [2/2] | Iterations: [1713/1995] | Training loss: 0.062\n",
            "Epoch: [2/2] | Iterations: [1714/1995] | Training loss: 0.145\n",
            "Epoch: [2/2] | Iterations: [1715/1995] | Training loss: 0.111\n",
            "Epoch: [2/2] | Iterations: [1716/1995] | Training loss: 0.111\n",
            "Epoch: [2/2] | Iterations: [1717/1995] | Training loss: 0.035\n",
            "Epoch: [2/2] | Iterations: [1718/1995] | Training loss: 0.148\n",
            "Epoch: [2/2] | Iterations: [1719/1995] | Training loss: 0.124\n",
            "Epoch: [2/2] | Iterations: [1720/1995] | Training loss: 0.139\n",
            "Epoch: [2/2] | Iterations: [1721/1995] | Training loss: 0.061\n",
            "Epoch: [2/2] | Iterations: [1722/1995] | Training loss: 0.094\n",
            "Epoch: [2/2] | Iterations: [1723/1995] | Training loss: 0.063\n",
            "Epoch: [2/2] | Iterations: [1724/1995] | Training loss: 0.089\n",
            "Epoch: [2/2] | Iterations: [1725/1995] | Training loss: 0.097\n",
            "Epoch: [2/2] | Iterations: [1726/1995] | Training loss: 0.052\n",
            "Epoch: [2/2] | Iterations: [1727/1995] | Training loss: 0.115\n",
            "Epoch: [2/2] | Iterations: [1728/1995] | Training loss: 0.071\n",
            "Epoch: [2/2] | Iterations: [1729/1995] | Training loss: 0.047\n",
            "Epoch: [2/2] | Iterations: [1730/1995] | Training loss: 0.119\n",
            "Epoch: [2/2] | Iterations: [1731/1995] | Training loss: 0.077\n",
            "Epoch: [2/2] | Iterations: [1732/1995] | Training loss: 0.136\n",
            "Epoch: [2/2] | Iterations: [1733/1995] | Training loss: 0.085\n",
            "Epoch: [2/2] | Iterations: [1734/1995] | Training loss: 0.092\n",
            "Epoch: [2/2] | Iterations: [1735/1995] | Training loss: 0.098\n",
            "Epoch: [2/2] | Iterations: [1736/1995] | Training loss: 0.101\n",
            "Epoch: [2/2] | Iterations: [1737/1995] | Training loss: 0.091\n",
            "Epoch: [2/2] | Iterations: [1738/1995] | Training loss: 0.129\n",
            "Epoch: [2/2] | Iterations: [1739/1995] | Training loss: 0.101\n",
            "Epoch: [2/2] | Iterations: [1740/1995] | Training loss: 0.111\n",
            "Epoch: [2/2] | Iterations: [1741/1995] | Training loss: 0.107\n",
            "Epoch: [2/2] | Iterations: [1742/1995] | Training loss: 0.103\n",
            "Epoch: [2/2] | Iterations: [1743/1995] | Training loss: 0.120\n",
            "Epoch: [2/2] | Iterations: [1744/1995] | Training loss: 0.110\n",
            "Epoch: [2/2] | Iterations: [1745/1995] | Training loss: 0.147\n",
            "Epoch: [2/2] | Iterations: [1746/1995] | Training loss: 0.104\n",
            "Epoch: [2/2] | Iterations: [1747/1995] | Training loss: 0.071\n",
            "Epoch: [2/2] | Iterations: [1748/1995] | Training loss: 0.182\n",
            "Epoch: [2/2] | Iterations: [1749/1995] | Training loss: 0.134\n",
            "Epoch: [2/2] | Iterations: [1750/1995] | Training loss: 0.126\n",
            "Epoch: [2/2] | Iterations: [1751/1995] | Training loss: 0.051\n",
            "Epoch: [2/2] | Iterations: [1752/1995] | Training loss: 0.038\n",
            "Epoch: [2/2] | Iterations: [1753/1995] | Training loss: 0.076\n",
            "Epoch: [2/2] | Iterations: [1754/1995] | Training loss: 0.051\n",
            "Epoch: [2/2] | Iterations: [1755/1995] | Training loss: 0.093\n",
            "Epoch: [2/2] | Iterations: [1756/1995] | Training loss: 0.073\n",
            "Epoch: [2/2] | Iterations: [1757/1995] | Training loss: 0.138\n",
            "Epoch: [2/2] | Iterations: [1758/1995] | Training loss: 0.092\n",
            "Epoch: [2/2] | Iterations: [1759/1995] | Training loss: 0.119\n",
            "Epoch: [2/2] | Iterations: [1760/1995] | Training loss: 0.055\n",
            "Epoch: [2/2] | Iterations: [1761/1995] | Training loss: 0.063\n",
            "Epoch: [2/2] | Iterations: [1762/1995] | Training loss: 0.090\n",
            "Epoch: [2/2] | Iterations: [1763/1995] | Training loss: 0.093\n",
            "Epoch: [2/2] | Iterations: [1764/1995] | Training loss: 0.106\n",
            "Epoch: [2/2] | Iterations: [1765/1995] | Training loss: 0.063\n",
            "Epoch: [2/2] | Iterations: [1766/1995] | Training loss: 0.054\n",
            "Epoch: [2/2] | Iterations: [1767/1995] | Training loss: 0.081\n",
            "Epoch: [2/2] | Iterations: [1768/1995] | Training loss: 0.087\n",
            "Epoch: [2/2] | Iterations: [1769/1995] | Training loss: 0.086\n",
            "Epoch: [2/2] | Iterations: [1770/1995] | Training loss: 0.111\n",
            "Epoch: [2/2] | Iterations: [1771/1995] | Training loss: 0.119\n",
            "Epoch: [2/2] | Iterations: [1772/1995] | Training loss: 0.079\n",
            "Epoch: [2/2] | Iterations: [1773/1995] | Training loss: 0.101\n",
            "Epoch: [2/2] | Iterations: [1774/1995] | Training loss: 0.111\n",
            "Epoch: [2/2] | Iterations: [1775/1995] | Training loss: 0.038\n",
            "Epoch: [2/2] | Iterations: [1776/1995] | Training loss: 0.057\n",
            "Epoch: [2/2] | Iterations: [1777/1995] | Training loss: 0.153\n",
            "Epoch: [2/2] | Iterations: [1778/1995] | Training loss: 0.152\n",
            "Epoch: [2/2] | Iterations: [1779/1995] | Training loss: 0.088\n",
            "Epoch: [2/2] | Iterations: [1780/1995] | Training loss: 0.095\n",
            "Epoch: [2/2] | Iterations: [1781/1995] | Training loss: 0.121\n",
            "Epoch: [2/2] | Iterations: [1782/1995] | Training loss: 0.075\n",
            "Epoch: [2/2] | Iterations: [1783/1995] | Training loss: 0.038\n",
            "Epoch: [2/2] | Iterations: [1784/1995] | Training loss: 0.070\n",
            "Epoch: [2/2] | Iterations: [1785/1995] | Training loss: 0.081\n",
            "Epoch: [2/2] | Iterations: [1786/1995] | Training loss: 0.074\n",
            "Epoch: [2/2] | Iterations: [1787/1995] | Training loss: 0.090\n",
            "Epoch: [2/2] | Iterations: [1788/1995] | Training loss: 0.075\n",
            "Epoch: [2/2] | Iterations: [1789/1995] | Training loss: 0.122\n",
            "Epoch: [2/2] | Iterations: [1790/1995] | Training loss: 0.075\n",
            "Epoch: [2/2] | Iterations: [1791/1995] | Training loss: 0.143\n",
            "Epoch: [2/2] | Iterations: [1792/1995] | Training loss: 0.104\n",
            "Epoch: [2/2] | Iterations: [1793/1995] | Training loss: 0.076\n",
            "Epoch: [2/2] | Iterations: [1794/1995] | Training loss: 0.120\n",
            "Epoch: [2/2] | Iterations: [1795/1995] | Training loss: 0.062\n",
            "Epoch: [2/2] | Iterations: [1796/1995] | Training loss: 0.103\n",
            "Epoch: [2/2] | Iterations: [1797/1995] | Training loss: 0.061\n",
            "Epoch: [2/2] | Iterations: [1798/1995] | Training loss: 0.067\n",
            "Epoch: [2/2] | Iterations: [1799/1995] | Training loss: 0.129\n",
            "Epoch: [2/2] | Iterations: [1800/1995] | Training loss: 0.119\n",
            "Epoch: [2/2] | Iterations: [1801/1995] | Training loss: 0.097\n",
            "Epoch: [2/2] | Iterations: [1802/1995] | Training loss: 0.085\n",
            "Epoch: [2/2] | Iterations: [1803/1995] | Training loss: 0.047\n",
            "Epoch: [2/2] | Iterations: [1804/1995] | Training loss: 0.072\n",
            "Epoch: [2/2] | Iterations: [1805/1995] | Training loss: 0.054\n",
            "Epoch: [2/2] | Iterations: [1806/1995] | Training loss: 0.080\n",
            "Epoch: [2/2] | Iterations: [1807/1995] | Training loss: 0.065\n",
            "Epoch: [2/2] | Iterations: [1808/1995] | Training loss: 0.064\n",
            "Epoch: [2/2] | Iterations: [1809/1995] | Training loss: 0.032\n",
            "Epoch: [2/2] | Iterations: [1810/1995] | Training loss: 0.052\n",
            "Epoch: [2/2] | Iterations: [1811/1995] | Training loss: 0.073\n",
            "Epoch: [2/2] | Iterations: [1812/1995] | Training loss: 0.093\n",
            "Epoch: [2/2] | Iterations: [1813/1995] | Training loss: 0.120\n",
            "Epoch: [2/2] | Iterations: [1814/1995] | Training loss: 0.072\n",
            "Epoch: [2/2] | Iterations: [1815/1995] | Training loss: 0.093\n",
            "Epoch: [2/2] | Iterations: [1816/1995] | Training loss: 0.072\n",
            "Epoch: [2/2] | Iterations: [1817/1995] | Training loss: 0.045\n",
            "Epoch: [2/2] | Iterations: [1818/1995] | Training loss: 0.119\n",
            "Epoch: [2/2] | Iterations: [1819/1995] | Training loss: 0.120\n",
            "Epoch: [2/2] | Iterations: [1820/1995] | Training loss: 0.063\n",
            "Epoch: [2/2] | Iterations: [1821/1995] | Training loss: 0.088\n",
            "Epoch: [2/2] | Iterations: [1822/1995] | Training loss: 0.147\n",
            "Epoch: [2/2] | Iterations: [1823/1995] | Training loss: 0.065\n",
            "Epoch: [2/2] | Iterations: [1824/1995] | Training loss: 0.050\n",
            "Epoch: [2/2] | Iterations: [1825/1995] | Training loss: 0.042\n",
            "Epoch: [2/2] | Iterations: [1826/1995] | Training loss: 0.056\n",
            "Epoch: [2/2] | Iterations: [1827/1995] | Training loss: 0.066\n",
            "Epoch: [2/2] | Iterations: [1828/1995] | Training loss: 0.062\n",
            "Epoch: [2/2] | Iterations: [1829/1995] | Training loss: 0.101\n",
            "Epoch: [2/2] | Iterations: [1830/1995] | Training loss: 0.062\n",
            "Epoch: [2/2] | Iterations: [1831/1995] | Training loss: 0.073\n",
            "Epoch: [2/2] | Iterations: [1832/1995] | Training loss: 0.073\n",
            "Epoch: [2/2] | Iterations: [1833/1995] | Training loss: 0.071\n",
            "Epoch: [2/2] | Iterations: [1834/1995] | Training loss: 0.060\n",
            "Epoch: [2/2] | Iterations: [1835/1995] | Training loss: 0.115\n",
            "Epoch: [2/2] | Iterations: [1836/1995] | Training loss: 0.070\n",
            "Epoch: [2/2] | Iterations: [1837/1995] | Training loss: 0.116\n",
            "Epoch: [2/2] | Iterations: [1838/1995] | Training loss: 0.086\n",
            "Epoch: [2/2] | Iterations: [1839/1995] | Training loss: 0.072\n",
            "Epoch: [2/2] | Iterations: [1840/1995] | Training loss: 0.075\n",
            "Epoch: [2/2] | Iterations: [1841/1995] | Training loss: 0.086\n",
            "Epoch: [2/2] | Iterations: [1842/1995] | Training loss: 0.060\n",
            "Epoch: [2/2] | Iterations: [1843/1995] | Training loss: 0.119\n",
            "Epoch: [2/2] | Iterations: [1844/1995] | Training loss: 0.065\n",
            "Epoch: [2/2] | Iterations: [1845/1995] | Training loss: 0.070\n",
            "Epoch: [2/2] | Iterations: [1846/1995] | Training loss: 0.077\n",
            "Epoch: [2/2] | Iterations: [1847/1995] | Training loss: 0.074\n",
            "Epoch: [2/2] | Iterations: [1848/1995] | Training loss: 0.107\n",
            "Epoch: [2/2] | Iterations: [1849/1995] | Training loss: 0.068\n",
            "Epoch: [2/2] | Iterations: [1850/1995] | Training loss: 0.094\n",
            "Epoch: [2/2] | Iterations: [1851/1995] | Training loss: 0.059\n",
            "Epoch: [2/2] | Iterations: [1852/1995] | Training loss: 0.079\n",
            "Epoch: [2/2] | Iterations: [1853/1995] | Training loss: 0.075\n",
            "Epoch: [2/2] | Iterations: [1854/1995] | Training loss: 0.077\n",
            "Epoch: [2/2] | Iterations: [1855/1995] | Training loss: 0.071\n",
            "Epoch: [2/2] | Iterations: [1856/1995] | Training loss: 0.142\n",
            "Epoch: [2/2] | Iterations: [1857/1995] | Training loss: 0.189\n",
            "Epoch: [2/2] | Iterations: [1858/1995] | Training loss: 0.077\n",
            "Epoch: [2/2] | Iterations: [1859/1995] | Training loss: 0.086\n",
            "Epoch: [2/2] | Iterations: [1860/1995] | Training loss: 0.064\n",
            "Epoch: [2/2] | Iterations: [1861/1995] | Training loss: 0.056\n",
            "Epoch: [2/2] | Iterations: [1862/1995] | Training loss: 0.192\n",
            "Epoch: [2/2] | Iterations: [1863/1995] | Training loss: 0.076\n",
            "Epoch: [2/2] | Iterations: [1864/1995] | Training loss: 0.056\n",
            "Epoch: [2/2] | Iterations: [1865/1995] | Training loss: 0.121\n",
            "Epoch: [2/2] | Iterations: [1866/1995] | Training loss: 0.106\n",
            "Epoch: [2/2] | Iterations: [1867/1995] | Training loss: 0.060\n",
            "Epoch: [2/2] | Iterations: [1868/1995] | Training loss: 0.034\n",
            "Epoch: [2/2] | Iterations: [1869/1995] | Training loss: 0.038\n",
            "Epoch: [2/2] | Iterations: [1870/1995] | Training loss: 0.114\n",
            "Epoch: [2/2] | Iterations: [1871/1995] | Training loss: 0.098\n",
            "Epoch: [2/2] | Iterations: [1872/1995] | Training loss: 0.088\n",
            "Epoch: [2/2] | Iterations: [1873/1995] | Training loss: 0.146\n",
            "Epoch: [2/2] | Iterations: [1874/1995] | Training loss: 0.077\n",
            "Epoch: [2/2] | Iterations: [1875/1995] | Training loss: 0.071\n",
            "Epoch: [2/2] | Iterations: [1876/1995] | Training loss: 0.095\n",
            "Epoch: [2/2] | Iterations: [1877/1995] | Training loss: 0.078\n",
            "Epoch: [2/2] | Iterations: [1878/1995] | Training loss: 0.108\n",
            "Epoch: [2/2] | Iterations: [1879/1995] | Training loss: 0.068\n",
            "Epoch: [2/2] | Iterations: [1880/1995] | Training loss: 0.072\n",
            "Epoch: [2/2] | Iterations: [1881/1995] | Training loss: 0.096\n",
            "Epoch: [2/2] | Iterations: [1882/1995] | Training loss: 0.098\n",
            "Epoch: [2/2] | Iterations: [1883/1995] | Training loss: 0.096\n",
            "Epoch: [2/2] | Iterations: [1884/1995] | Training loss: 0.100\n",
            "Epoch: [2/2] | Iterations: [1885/1995] | Training loss: 0.096\n",
            "Epoch: [2/2] | Iterations: [1886/1995] | Training loss: 0.165\n",
            "Epoch: [2/2] | Iterations: [1887/1995] | Training loss: 0.048\n",
            "Epoch: [2/2] | Iterations: [1888/1995] | Training loss: 0.040\n",
            "Epoch: [2/2] | Iterations: [1889/1995] | Training loss: 0.131\n",
            "Epoch: [2/2] | Iterations: [1890/1995] | Training loss: 0.095\n",
            "Epoch: [2/2] | Iterations: [1891/1995] | Training loss: 0.090\n",
            "Epoch: [2/2] | Iterations: [1892/1995] | Training loss: 0.121\n",
            "Epoch: [2/2] | Iterations: [1893/1995] | Training loss: 0.176\n",
            "Epoch: [2/2] | Iterations: [1894/1995] | Training loss: 0.066\n",
            "Epoch: [2/2] | Iterations: [1895/1995] | Training loss: 0.142\n",
            "Epoch: [2/2] | Iterations: [1896/1995] | Training loss: 0.114\n",
            "Epoch: [2/2] | Iterations: [1897/1995] | Training loss: 0.096\n",
            "Epoch: [2/2] | Iterations: [1898/1995] | Training loss: 0.101\n",
            "Epoch: [2/2] | Iterations: [1899/1995] | Training loss: 0.054\n",
            "Epoch: [2/2] | Iterations: [1900/1995] | Training loss: 0.136\n",
            "Epoch: [2/2] | Iterations: [1901/1995] | Training loss: 0.055\n",
            "Epoch: [2/2] | Iterations: [1902/1995] | Training loss: 0.074\n",
            "Epoch: [2/2] | Iterations: [1903/1995] | Training loss: 0.108\n",
            "Epoch: [2/2] | Iterations: [1904/1995] | Training loss: 0.101\n",
            "Epoch: [2/2] | Iterations: [1905/1995] | Training loss: 0.082\n",
            "Epoch: [2/2] | Iterations: [1906/1995] | Training loss: 0.097\n",
            "Epoch: [2/2] | Iterations: [1907/1995] | Training loss: 0.043\n",
            "Epoch: [2/2] | Iterations: [1908/1995] | Training loss: 0.150\n",
            "Epoch: [2/2] | Iterations: [1909/1995] | Training loss: 0.114\n",
            "Epoch: [2/2] | Iterations: [1910/1995] | Training loss: 0.078\n",
            "Epoch: [2/2] | Iterations: [1911/1995] | Training loss: 0.097\n",
            "Epoch: [2/2] | Iterations: [1912/1995] | Training loss: 0.082\n",
            "Epoch: [2/2] | Iterations: [1913/1995] | Training loss: 0.095\n",
            "Epoch: [2/2] | Iterations: [1914/1995] | Training loss: 0.075\n",
            "Epoch: [2/2] | Iterations: [1915/1995] | Training loss: 0.117\n",
            "Epoch: [2/2] | Iterations: [1916/1995] | Training loss: 0.103\n",
            "Epoch: [2/2] | Iterations: [1917/1995] | Training loss: 0.088\n",
            "Epoch: [2/2] | Iterations: [1918/1995] | Training loss: 0.096\n",
            "Epoch: [2/2] | Iterations: [1919/1995] | Training loss: 0.079\n",
            "Epoch: [2/2] | Iterations: [1920/1995] | Training loss: 0.088\n",
            "Epoch: [2/2] | Iterations: [1921/1995] | Training loss: 0.074\n",
            "Epoch: [2/2] | Iterations: [1922/1995] | Training loss: 0.070\n",
            "Epoch: [2/2] | Iterations: [1923/1995] | Training loss: 0.081\n",
            "Epoch: [2/2] | Iterations: [1924/1995] | Training loss: 0.134\n",
            "Epoch: [2/2] | Iterations: [1925/1995] | Training loss: 0.060\n",
            "Epoch: [2/2] | Iterations: [1926/1995] | Training loss: 0.083\n",
            "Epoch: [2/2] | Iterations: [1927/1995] | Training loss: 0.068\n",
            "Epoch: [2/2] | Iterations: [1928/1995] | Training loss: 0.082\n",
            "Epoch: [2/2] | Iterations: [1929/1995] | Training loss: 0.067\n",
            "Epoch: [2/2] | Iterations: [1930/1995] | Training loss: 0.086\n",
            "Epoch: [2/2] | Iterations: [1931/1995] | Training loss: 0.067\n",
            "Epoch: [2/2] | Iterations: [1932/1995] | Training loss: 0.122\n",
            "Epoch: [2/2] | Iterations: [1933/1995] | Training loss: 0.082\n",
            "Epoch: [2/2] | Iterations: [1934/1995] | Training loss: 0.095\n",
            "Epoch: [2/2] | Iterations: [1935/1995] | Training loss: 0.060\n",
            "Epoch: [2/2] | Iterations: [1936/1995] | Training loss: 0.129\n",
            "Epoch: [2/2] | Iterations: [1937/1995] | Training loss: 0.053\n",
            "Epoch: [2/2] | Iterations: [1938/1995] | Training loss: 0.091\n",
            "Epoch: [2/2] | Iterations: [1939/1995] | Training loss: 0.038\n",
            "Epoch: [2/2] | Iterations: [1940/1995] | Training loss: 0.045\n",
            "Epoch: [2/2] | Iterations: [1941/1995] | Training loss: 0.053\n",
            "Epoch: [2/2] | Iterations: [1942/1995] | Training loss: 0.051\n",
            "Epoch: [2/2] | Iterations: [1943/1995] | Training loss: 0.082\n",
            "Epoch: [2/2] | Iterations: [1944/1995] | Training loss: 0.142\n",
            "Epoch: [2/2] | Iterations: [1945/1995] | Training loss: 0.081\n",
            "Epoch: [2/2] | Iterations: [1946/1995] | Training loss: 0.053\n",
            "Epoch: [2/2] | Iterations: [1947/1995] | Training loss: 0.131\n",
            "Epoch: [2/2] | Iterations: [1948/1995] | Training loss: 0.071\n",
            "Epoch: [2/2] | Iterations: [1949/1995] | Training loss: 0.055\n",
            "Epoch: [2/2] | Iterations: [1950/1995] | Training loss: 0.082\n",
            "Epoch: [2/2] | Iterations: [1951/1995] | Training loss: 0.076\n",
            "Epoch: [2/2] | Iterations: [1952/1995] | Training loss: 0.052\n",
            "Epoch: [2/2] | Iterations: [1953/1995] | Training loss: 0.044\n",
            "Epoch: [2/2] | Iterations: [1954/1995] | Training loss: 0.084\n",
            "Epoch: [2/2] | Iterations: [1955/1995] | Training loss: 0.072\n",
            "Epoch: [2/2] | Iterations: [1956/1995] | Training loss: 0.062\n",
            "Epoch: [2/2] | Iterations: [1957/1995] | Training loss: 0.124\n",
            "Epoch: [2/2] | Iterations: [1958/1995] | Training loss: 0.127\n",
            "Epoch: [2/2] | Iterations: [1959/1995] | Training loss: 0.137\n",
            "Epoch: [2/2] | Iterations: [1960/1995] | Training loss: 0.081\n",
            "Epoch: [2/2] | Iterations: [1961/1995] | Training loss: 0.092\n",
            "Epoch: [2/2] | Iterations: [1962/1995] | Training loss: 0.101\n",
            "Epoch: [2/2] | Iterations: [1963/1995] | Training loss: 0.066\n",
            "Epoch: [2/2] | Iterations: [1964/1995] | Training loss: 0.061\n",
            "Epoch: [2/2] | Iterations: [1965/1995] | Training loss: 0.074\n",
            "Epoch: [2/2] | Iterations: [1966/1995] | Training loss: 0.045\n",
            "Epoch: [2/2] | Iterations: [1967/1995] | Training loss: 0.084\n",
            "Epoch: [2/2] | Iterations: [1968/1995] | Training loss: 0.107\n",
            "Epoch: [2/2] | Iterations: [1969/1995] | Training loss: 0.078\n",
            "Epoch: [2/2] | Iterations: [1970/1995] | Training loss: 0.098\n",
            "Epoch: [2/2] | Iterations: [1971/1995] | Training loss: 0.064\n",
            "Epoch: [2/2] | Iterations: [1972/1995] | Training loss: 0.071\n",
            "Epoch: [2/2] | Iterations: [1973/1995] | Training loss: 0.066\n",
            "Epoch: [2/2] | Iterations: [1974/1995] | Training loss: 0.082\n",
            "Epoch: [2/2] | Iterations: [1975/1995] | Training loss: 0.114\n",
            "Epoch: [2/2] | Iterations: [1976/1995] | Training loss: 0.083\n",
            "Epoch: [2/2] | Iterations: [1977/1995] | Training loss: 0.085\n",
            "Epoch: [2/2] | Iterations: [1978/1995] | Training loss: 0.071\n",
            "Epoch: [2/2] | Iterations: [1979/1995] | Training loss: 0.099\n",
            "Epoch: [2/2] | Iterations: [1980/1995] | Training loss: 0.135\n",
            "Epoch: [2/2] | Iterations: [1981/1995] | Training loss: 0.071\n",
            "Epoch: [2/2] | Iterations: [1982/1995] | Training loss: 0.096\n",
            "Epoch: [2/2] | Iterations: [1983/1995] | Training loss: 0.063\n",
            "Epoch: [2/2] | Iterations: [1984/1995] | Training loss: 0.076\n",
            "Epoch: [2/2] | Iterations: [1985/1995] | Training loss: 0.073\n",
            "Epoch: [2/2] | Iterations: [1986/1995] | Training loss: 0.084\n",
            "Epoch: [2/2] | Iterations: [1987/1995] | Training loss: 0.049\n",
            "Epoch: [2/2] | Iterations: [1988/1995] | Training loss: 0.062\n",
            "Epoch: [2/2] | Iterations: [1989/1995] | Training loss: 0.054\n",
            "Epoch: [2/2] | Iterations: [1990/1995] | Training loss: 0.064\n",
            "Epoch: [2/2] | Iterations: [1991/1995] | Training loss: 0.065\n",
            "Epoch: [2/2] | Iterations: [1992/1995] | Training loss: 0.074\n",
            "Epoch: [2/2] | Iterations: [1993/1995] | Training loss: 0.088\n",
            "Epoch: [2/2] | Iterations: [1994/1995] | Training loss: 0.096\n",
            "Epoch: [2/2] | Iterations: [1995/1995] | Training loss: 0.081\n",
            "Training Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZVzWrbLH7KU"
      },
      "source": [
        "#Change train_new_data value to 0, if you want to load previously saved model.\n",
        "if not train_new_data:\n",
        "    model.load_state_dict(torch.load(\"model.pt\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wua3jD_PH9Vt"
      },
      "source": [
        "#Predicts toxicity level of all test case comments.\n",
        "def predict_test_cases(model, test_iterator):\n",
        "    result = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_iterator):\n",
        "            batch_size = len(batch)\n",
        "            text = batch.text.view(batch_size,-1).long()\n",
        "            ids = batch.id.squeeze().cpu()\n",
        "            output = model(text)\n",
        "            output = torch.sigmoid(output).cpu()\n",
        "            for i,j in zip(ids,output):\n",
        "                result.append([ID2.vocab.itos[i.numpy()],j.numpy()])\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGPhL_sIH_eS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8c5eb528-81c6-4759-e229-fc47830c515e"
      },
      "source": [
        "result = predict_test_cases(model, test_iterator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2394/2394 [11:13<00:00,  3.55it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQrs2QMBzPFA"
      },
      "source": [
        "# **Exploration**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnPJgUrJIEci"
      },
      "source": [
        "#Gotten from https://github.com/bentrevett/pytorch-sentiment-analysis/issues/40\n",
        "#You feed in a text string and the function returns a tensor showing the toxicty level of the comments. Ranging from 0 - 1.\n",
        "def sentiment_prediction(model, sentence, min_len = 5):\n",
        "    model.eval()\n",
        "    tokenized = [i.text for i in nlp.tokenizer(sentence)]\n",
        "    if len(tokenized) < min_len:\n",
        "        tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
        "    indexed = [TEXT.vocab.stoi[w] for w in tokenized]\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(0)\n",
        "    prediction = torch.sigmoid(model(tensor))\n",
        "    return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaxR18mikHu1"
      },
      "source": [
        "label_list = ['toxic', 'severe toxic', 'obscene', 'threat', 'insult', 'identity hate']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8yxeJP1mN1s"
      },
      "source": [
        "def output_results(tensor_results, label_list):\n",
        "\n",
        "  print(\"Here are the results!\")\n",
        "  print(\"This comment is \", (tensor_results.tolist()[0][0])*100, \"%\", label_list[0],'.')\n",
        "  print(\"This comment is \", (tensor_results.tolist()[0][1])*100, \"%\", label_list[1], '.')\n",
        "  print(\"This comment is \", (tensor_results.tolist()[0][2])*100, \"%\", label_list[2], '.')\n",
        "  print(\"This comment is \", (tensor_results.tolist()[0][3])*100, \"%\", label_list[3], '.')\n",
        "  print(\"This comment is \", (tensor_results.tolist()[0][4])*100, \"%\", label_list[4], '.')\n",
        "  print(\"This comment is \", (tensor_results.tolist()[0][5])*100, \"%\", label_list[5], '.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gj51N1Tasa_J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "077ce9fc-5395-4e4a-8690-92d5ba0a42e6"
      },
      "source": [
        "output_results(sentiment_prediction(model,text2), label_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Here are the results!\n",
            "This comment is  97.2859799861908 % toxic .\n",
            "This comment is  46.15640044212341 % severe toxic .\n",
            "This comment is  93.64231824874878 % obscene .\n",
            "This comment is  11.011741310358047 % threat .\n",
            "This comment is  90.4722511768341 % insult .\n",
            "This comment is  24.513758718967438 % identity hate .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CV5eINO3yg17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "c551186d-6e66-48a3-af1e-b948ba82a651"
      },
      "source": [
        "text2 = processing('stupid bitch')\n",
        "output_results(sentiment_prediction(model,text2), label_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Here are the results!\n",
            "This comment is  97.2859799861908 % toxic .\n",
            "This comment is  46.15640044212341 % severe toxic .\n",
            "This comment is  93.64231824874878 % obscene .\n",
            "This comment is  11.011741310358047 % threat .\n",
            "This comment is  90.4722511768341 % insult .\n",
            "This comment is  24.513758718967438 % identity hate .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V49euKJvysbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "44e5278b-929e-4ab6-9e09-69186f6f35cd"
      },
      "source": [
        "text3 = processing('Hello how are you')\n",
        "output_results(sentiment_prediction(model,text3), label_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Here are the results!\n",
            "This comment is  36.656081676483154 % toxic .\n",
            "This comment is  15.772013366222382 % severe toxic .\n",
            "This comment is  30.28900921344757 % obscene .\n",
            "This comment is  10.665873438119888 % threat .\n",
            "This comment is  30.298712849617004 % insult .\n",
            "This comment is  16.324447095394135 % identity hate .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsDwImg2B6YT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "51f4c1bb-669b-4121-d0c0-65ad11017c4e"
      },
      "source": [
        "text4 = processing('Fuck Donald trump')\n",
        "output_results(sentiment_prediction(model,text4), label_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Here are the results!\n",
            "This comment is  77.93609499931335 % toxic .\n",
            "This comment is  21.43966108560562 % severe toxic .\n",
            "This comment is  67.56911277770996 % obscene .\n",
            "This comment is  11.928174644708633 % threat .\n",
            "This comment is  67.50600337982178 % insult .\n",
            "This comment is  17.962075769901276 % identity hate .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7qMunINyizH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "4582f70f-3640-4e48-963e-e5067ee155fb"
      },
      "source": [
        "text5 = processing('i love you')\n",
        "output_results(sentiment_prediction(model,text5), label_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Here are the results!\n",
            "This comment is  23.88479709625244 % toxic .\n",
            "This comment is  8.818437159061432 % severe toxic .\n",
            "This comment is  14.886708557605743 % obscene .\n",
            "This comment is  5.9532638639211655 % threat .\n",
            "This comment is  16.656996309757233 % insult .\n",
            "This comment is  10.665958374738693 % identity hate .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0krQZnR3GuO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEB3frdXX2wG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}