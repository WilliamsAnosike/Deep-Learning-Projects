# -*- coding: utf-8 -*-
"""Credit Card Fraud Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jn8FT0jC9iefmuy2iEkYRtGI3n2sREYs

# DATA 690 FINAL PROJECT
"""

os.chdir('Colab Notebooks')

os.listdir(os.getcwd())

os.chdir('DATA 690')

os.listdir(os.getcwd())

"""# DATA EXPLORATION"""

df = pd.read_csv('creditcard.csv')

df.head(5)

print(df.shape)

print(df.describe())

df.isnull().values.any()

df.Class.value_counts()

count_classes = pd.value_counts(df.Class,sort=True)
count_classes.plot(kind='bar',rot=0, color="r")
plt.title("Normal vs Fraudulant Transactions")
plt.xticks(range(2), LABELS)
plt.xlabel("Transaction Class")
plt.ylabel("Frequency");

Fdf = df[df.Class == 1 ]
Ndf = df[df.Class == 0 ]
print(Fdf.shape)
print(Ndf.shape)

print(Fdf.Amount.describe())
print("")
print(Ndf.Amount.describe())

f, (ax1, ax2) = plt.subplots(2, 1, sharex=True)
f.suptitle('Time of transaction vs Amount by class')

ax1.scatter(Fdf.Time, Fdf.Amount, color="r")
ax1.set_title('Fraud')

ax2.scatter(Ndf.Time, Ndf.Amount, color='g')
ax2.set_title('Normal')

plt.xlabel('Time (in Seconds)')
plt.ylabel('Amount')
plt.show()

transactions = df.drop(['Time'],axis = 1)

transactions.Amount = StandardScaler().fit_transform(
transactions.Amount.values.reshape(-1,1)
)

X_train, X_test = train_test_split(transactions, test_size=0.2, random_state=RANDOM_SEED)
X_train = X_train[X_train.Class == 0]
X_train = X_train.drop(['Class'], axis=1)
print(type(X_train))
y_test = X_test['Class']
X_test = X_test.drop(['Class'], axis=1)

X_train = X_train.values
print(type(X_train))
X_test = X_test.values
y_test = y_test.values
print(y_test.size)

"""Here we set up our Autoencoding model."""

class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(29,14),
            nn.Tanh(),
            nn.Linear(14,14),
            nn.Tanh(),
            nn.Linear(14,7),
            nn.LeakyReLU()
            )
        self.decoder = nn.Sequential(
            nn.Linear(7, 10),
            nn.Tanh(),
            nn.Linear(10,10),
            nn.Tanh(),
            nn.Linear(10, 29),
            nn.LeakyReLU()
            )
    def forward(self , x):
        x = self.encoder(x)
        x = self.decoder(x)
        return(x)

model = Autoencoder().double().cpu()

#Hyperparameters
num_epochs = 150
batch_size = 32
lr = 0.0001

train_loader = data_utils.DataLoader(X_train,batch_size=batch_size,shuffle=True)
test_loader = data_utils.DataLoader(X_test, batch_size=1, shuffle=False)

criterion = nn.MSELoss()
optimizer = torch.optim.Adam(
model.parameters(), lr=lr, weight_decay=10e-05)

history = {}
history['train_loss'] = []
history['test_loss'] = []

"""I then proceed with training."""

for epoch in range(num_epochs):
    h = np.array([])
    for data in train_loader:
        #print(type(data))
        #data = Variable(data).cpu()
        #print(type(data))
        # ===================forward=====================
        output = model(data)
        loss = criterion(output, data)
        h = np.append(h, loss.item())
        
        # ===================backward====================
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    # ===================log========================
    mean_loss = np.mean(h)
    print('epoch [{}/{}], loss:{:.4f}'
          .format(epoch + 1, num_epochs, mean_loss))
    history['train_loss'].append(mean_loss)
    

torch.save(model.state_dict(), './credit_card_model.pth')

plt.plot(range(num_epochs),history['train_loss'],'ro',linewidth=2.0)
plt.plot(history['train_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.axis([0,100,0.69,0.80])
plt.legend(['train', 'test'], loc='upper right');
plt.show()

pred_losses = { 'pred_loss' : []}
model.eval()
with torch.no_grad():
    for data in test_loader:
        inputs = data
        outputs = model(inputs)
        loss = criterion(outputs, inputs).data.item()
        pred_losses['pred_loss'].append(loss)
reconstructionErrorDF = pd.DataFrame(pred_losses)
reconstructionErrorDF['Class'] = y_test

reconstructionErrorDF.head(5)

fig = plt.figure()
ax = fig.add_subplot(111)
normal_error_df = reconstructionErrorDF[(reconstructionErrorDF['Class']== 0) & (reconstructionErrorDF['pred_loss'] < 10)]
_ = ax.hist(normal_error_df.pred_loss.values, bins=10,color='g')

fig = plt.figure()
ax = fig.add_subplot(111)
fraud_error_df = reconstructionErrorDF[(reconstructionErrorDF['Class']== 1)]
_ = ax.hist(fraud_error_df.pred_loss.values, bins=10,color='r')

fpr, tpr, thresholds = roc_curve(reconstructionErrorDF.Class, reconstructionErrorDF.pred_loss)
roc_auc = auc(fpr, tpr)

plt.title('Receiver Operating Characteristic')
plt.plot(fpr, tpr, label='AUC = %0.4f'% roc_auc)
plt.legend(loc='lower right')
plt.plot([0,1],[0,1],'r--')
plt.xlim([-0.001, 1])
plt.ylim([0, 1.001])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show();

precision, recall, th = precision_recall_curve(
    reconstructionErrorDF.Class, 
    reconstructionErrorDF.pred_loss)

plt.plot(recall, precision, 'b', label='Precision-Recall curve')
plt.title('Recall vs Precision')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.show()

plt.plot(th, precision[1:], 'b', label='Threshold-Precision curve')
plt.title('Precision for different threshold values')
plt.xlabel('Threshold')
plt.ylabel('Precision')
plt.show()

plt.plot(th, recall[1:], 'b', label='Threshold-Recall curve')
plt.title('Recall for different threshold values')
plt.xlabel('Reconstruction error')
plt.ylabel('Recall')
plt.show()

"""Here we use this trained model to then predict future transactions."""

threshold = 3

groups = reconstructionErrorDF.groupby('Class')
fig, ax = plt.subplots()

for name, group in groups:
    ax.plot(group.index, group.pred_loss, marker='o', ms=3.5, linestyle='',
            label= "Fraud" if name == 1 else "Normal")
ax.hlines(threshold, ax.get_xlim()[0], ax.get_xlim()[1], colors="r", zorder=100, label='Threshold')
ax.legend()
plt.title("Reconstruction error for different classes")
plt.ylabel("Reconstruction error")
plt.xlabel("Data point index")
plt.show()

y_pred = [1 if e > threshold else 0 for e in reconstructionErrorDF.pred_loss.values]

conf_matrix = confusion_matrix(reconstructionErrorDF.Class, y_pred)
plt.figure(figsize=(12, 12))
sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt="d", 
            cmap=plt.cm.get_cmap('Blues'));
plt.title("Confusion matrix")
plt.ylabel('True class')
plt.xlabel('Predicted class')
plt.show()

